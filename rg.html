<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="">
    <title>Temporal Graph Learning Reading Group</title>
    <link href="css/bootstrap.min.css" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Merriweather&display=swap" rel="stylesheet">
    <link href="css/scrolling-nav.css" rel="stylesheet">
    <link rel="stylesheet" type="text/css" href="css/plain-style.css">
    <link rel="stylesheet" type="text/css" href="css/bibbase_css.css">
</head>

<body id="page-top" data-spy="scroll" data-target=".navbar-fixed-top" >
    <!-- Navigation -->
    <nav class="navbar navbar-default navbar-fixed-top" role="navigation">
      <div class="container">
        <div class="navbar-header page-scroll">
          <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-ex1-collapse">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <a class="navbar-brand page-scroll" href="#page-top"></a>
        </div>
  
<div class="collapse navbar-collapse navbar-ex1-collapse">
    <ul class="nav navbar-nav">
      <!-- Hidden li included to remove active class from research link when scrolled up past research section -->
      <li class="hidden">
        <a class="page-scroll" href="#page-top"></a>
      </li>

      <li>
        <a class="page-scroll" href="#schedule"> Upcoming Talks </a>
      </li>

      <li>
        <a class="page-scroll" href="#summer2025"> Summer 2025 </a>
      </li>

      <li>
        <a class="page-scroll" href="#winter2025"> Winter 2025 </a>
      </li>

      <li>
        <a class="page-scroll" href="#fall2024"> Fall 2024 </a>
      </li>

      <li>
        <a class="page-scroll" href="#winter2024"> Winter 2024 </a>
      </li>

      <li>
        <a class="page-scroll" href="#fall2023"> Fall 2023 </a>
      </li>

      <li>
        <a class="page-scroll" href="#summer2023"> Summer 2023 </a>
      </li>


      <li>
        <a class="page-scroll" href="#winter2023"> Winter 2023 </a>
      </li>

      <!-- <li>
        <a class="page-scroll" href="#past"> Past Talks </a>
      </li> -->

      <li>
        <a class="page-scroll" href="#organizers"> Organizers </a>
      </li>

      <li>
        <a href="https://shenyanghuang.github.io/"> Back </a>
      </li>

    </ul>
  </div>
</div>
</nav>
<br/>
<br/>
<br/>
<br/>

<h1 style="text-align:center">Temporal Graph Reading Group</h1>
<!-- <img src="images/tgl_logo.png" class="rounded mx-auto d-block" alt="TGL logo"> -->
<div class="text-center">
  <!-- <img src="images/tgl_logo.png" class="img-fluid" alt="TGL logo" />   -->
  <!-- <img src="images/tgl_logo.png" class="img-thumbnail" alt="TGL logo" width="10%"/>   -->
  <img src="images/TGL_logo_notxt.png" class="img-thumbnail" alt="TGL logo" width="10%"/>  

</div>
<h4 style="text-align:center">Every Thursday at 11am-12pm EDT </h4>
<h4 style="text-align:center">Join us via <a href="https://mcgill.zoom.us/j/86223832499?pwd=Mk9EZTJzKzRCM0JRSU1JNHlsQlpXUT09">Zoom</a> </h4>
<h5 style="text-align:center">Follow us on twitter <a href="https://twitter.com/tempgraph_rg">@tempgraph_rg</a></h5>
<h5 style="text-align:center">Follow us on Bluesky <a href="https://bsky.app/profile/tempgraphrg.bsky.social">@tempgraphrg.bsky.social</a></h5>
<h5 style="text-align:center">Sign up <a href="https://forms.gle/8AEJQB1xSdoNUNDo6">here</a> to receive email communications about the reading group</h5>
<h5 style="text-align:center"> Visit our Youtube Channel for Past Recordings <a href="https://www.youtube.com/@TGL_RG"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a> </h5>
<h5 style="text-align:center"> Join the TGL slack to discuss with the TG community: <a href="https://join.slack.com/t/tglworkshop/shared_invite/zt-2rq5gd143-kdBS1pywP2OGC__SUEO89g">here</a>.<br> Contact <a href="shenyang.huang@mail.mcgill.ca">here</a> if there is any issues with the invite link. </h5>
<h5 style="text-align:center">Register the reading group in your <a href="https://calendar.google.com/calendar/event?action=TEMPLATE&tmeid=Nm9rNHU5MjBzOWtyM2puaXFzamRmMW9hNThfMjAyNDEwMTdUMTUwMDAwWiA4MGMwZTQ3ODkwMGEyNTc2MjliMTQ0MjA0MmEyYjkyMmNmMmJjNzg3YWU4MDBmZDE3MDE0YjQ4ZmNmM2E2NTc4QGc&tmsrc=80c0e478900a257629b1442042a2b922cf2bc787ae800fd17014b48fcf3a6578%40group.calendar.google.com&scp=ALL">google calendar</a> to follow us each week.</h5>
<!-- 
<center>
  <a target="_blank" href="https://calendar.google.com/calendar/event?action=TEMPLATE&amp;tmeid=Nm9rNHU5MjBzOWtyM2puaXFzamRmMW9hNThfMjAyNDEwMTdUMTUwMDAwWiA4MGMwZTQ3ODkwMGEyNTc2MjliMTQ0MjA0MmEyYjkyMmNmMmJjNzg3YWU4MDBmZDE3MDE0YjQ4ZmNmM2E2NTc4QGc&amp;tmsrc=80c0e478900a257629b1442042a2b922cf2bc787ae800fd17014b48fcf3a6578%40group.calendar.google.com&amp;scp=ALL"><img border="0" src="https://www.google.com/calendar/images/ext/gc_button1_en.gif"></a>
</center> -->

<!-- <a target="_blank" href="https://calendar.google.com/calendar/event?action=TEMPLATE&amp;tmeid=Nm9rNHU5MjBzOWtyM2puaXFzamRmMW9hNThfMjAyMzExMDlUMTYwMDAwWiA4MGMwZTQ3ODkwMGEyNTc2MjliMTQ0MjA0MmEyYjkyMmNmMmJjNzg3YWU4MDBmZDE3MDE0YjQ4ZmNmM2E2NTc4QGc&amp;tmsrc=80c0e478900a257629b1442042a2b922cf2bc787ae800fd17014b48fcf3a6578%40group.calendar.google.com"><img border="0" src="https://www.google.com/calendar/images/ext/gc_button1_en.gif"></a> -->



<!-- <center> 
  <a target="_blank" href="https://calendar.google.com/calendar/event?action=TEMPLATE&amp;tmeid=Nm9rNHU5MjBzOWtyM2puaXFzamRmMW9hNThfMjAyMzA5MjhUMTUwMDAwWiA4MGMwZTQ3ODkwMGEyNTc2MjliMTQ0MjA0MmEyYjkyMmNmMmJjNzg3YWU4MDBmZDE3MDE0YjQ4ZmNmM2E2NTc4QGc&amp;tmsrc=80c0e478900a257629b1442042a2b922cf2bc787ae800fd17014b48fcf3a6578%40group.calendar.google.com&amp;scp=ALL"><img border="0" src="https://www.google.com/calendar/images/ext/gc_button1_en.gif"></a>  
</center> -->

<!-- <a href="downloads/tgl_rg.ics">Outlook Calendar</a> -->


<section id="schedule" class="some-section">
    <div class="container">
      <div class="row">
    <div class="col-sm-2"></div>
    <div class="col-sm-8">
    <div class="listing" style="clear:both;">
      <div class="left">
        <h3 style="text-align:center">Upcoming Talks</h3>

      <!-- <h3>[Summer Reading Group Session begins on July 24th]</h4> -->


        <h4>[October 9th, 2025]</h4>
          <li>
            <b>
                <a href="https://arxiv.org/abs/2509.00975"> Self-Exploring Language Models for Explainable Link Forecasting on Temporal Graphs via Reinforcement Learning </a> 
            </b>
            <br> Presenter: <u>Zifeng Ding</u> University of Cambridge
            <a class="btn btn-info btn-xs" data-toggle="collapse" href="#25oct9bio" role="button" aria-expanded="false" aria-controls="collapseExample">
              Speaker Bio
            </a>
            <div class="collapse" id="25oct9bio">
              <div class="card card-body">
                <u>Zifeng Ding</u> is a Research Associate (Postdoctoral Researcher) in the Cambridge NLIP Group at the University of Cambridge. His current research interests include but are not limited to agentic AI, reasoning with LLMs (in particualr temporal reasoning), synthetic data generation, and LLM hallucination detection/mitigation.
              </div>
            </div>
            <br> 
            <a href="https://arxiv.org/abs/2509.00975"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
            <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#25oct9" role="button" aria-expanded="false" aria-controls="collapseExample">
                Abstract
              </a>
          <div class="collapse" id="25oct9">
          <div class="card card-body">
            Forecasting future links is a central task in temporal graph (TG) reasoning, requiring models to leverage historical interactions to predict upcoming ones. Traditional neural approaches, such as temporal graph neural networks, achieve strong performance but lack explainability and cannot be applied to unseen graphs without retraining. Recent studies have begun to explore using large language models (LLMs) for graph reasoning, but most of them are constrained to static graphs or small synthetic TGs and lack the evaluation of the quality of reasoning traces generated by LLMs. In this work, we present Reasoning-Enhanced Learning for Temporal Graphs (ReaL-TG), a reinforcement learning framework that fine-tunes LLMs to perform explainable link forecasting on real-world TGs. ReaL-TG uses outcome-based reward to encourage models to self-explore reasoning strategies from graph structure and to produce explanations that directly justify their predictions. To enable evaluation on LLM-generated reasoning traces, we propose a new evaluation protocol combining ranking metrics with an LLM-as-a-Judge system that assesses both the quality of reasoning and the impact of hallucinations. Experiments with ReaL-TG-4B, obtained by fine-tuning Qwen3-4B under our framework, show that it outperforms much larger frontier LLMs, including GPT-5 mini, on ranking metrics, while producing high-quality explanations confirmed by both the LLM judge and human evaluation.
          </div>
        </li>


        <h4>[October 16th, 2025]</h4>
          <li>
            <b>
                <a href="https://www.esann.org/sites/default/files/proceedings/2025/ES2025-87.pdf"> Tensor Decomposition for Temporal Knowledge Graph Reasoning: From Completion to Forecasting </a> 
            </b>
            <br> Presenter: <u>Manuel Dileo </u> University of Milan
            <a class="btn btn-info btn-xs" data-toggle="collapse" href="#25oct16bio" role="button" aria-expanded="false" aria-controls="collapseExample">
              Speaker Bio
            </a>
            <div class="collapse" id="25oct16bio">
              <div class="card card-body">
                <u>Manuel Dileo</u> is a Ph.D. candidate at the University of Milan, working in the Connets Lab. His research focuses on the intersection between network science and graph machine learning, with a particular emphasis on temporal and heterogeneous graph reasoning. He has been a visiting researcher at the University of Edinburgh where he worked on temporal knowledge graph reasoning. His homepage is manuel-dileo.github.io.
              </div>
            </div>
            <br> 
            <a href="https://www.esann.org/sites/default/files/proceedings/2025/ES2025-87.pdf"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
            <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#25oct16" role="button" aria-expanded="false" aria-controls="collapseExample">
                Abstract
              </a>
          <div class="collapse" id="25oct16">
          <div class="card card-body">
            Temporal knowledge graphs (TKGs) are an expressive framework for representing dynamic relational data. In this talk, I will present two lines of work on tensor-decomposition models for TKG reasoning. First, I will discuss how temporal regularization can enhance neural link predictors for knowledge base completion, showing that properly tuned and regularized TNTComplEx can rival more recent state-of-the-art methods. Second, I will present recent results on knowledge graph forecasting, where carefully tuned tensor-based models achieve comparable or superior performance to graph and recurrent neural network approaches, while being significantly faster. Together, these results highlight that tensor-decomposition methods, despite their simplicity, remain highly competitive for TKG reasoning tasks.
          </div>
        </li>


        <h4>[October 23rd, 2025]</h4>
          <li>
            <b>
                <a href="https://arxiv.org/abs/2505.18728"> Message-Passing State-Space Models: Improving Graph Learning with Modern Sequence Modeling </a> 
            </b>
            <br> Presenter: <u>Andrea Ceni</u> University of Pisa
            <a class="btn btn-info btn-xs" data-toggle="collapse" href="#25oct23bio" role="button" aria-expanded="false" aria-controls="collapseExample">
              Speaker Bio
            </a>
            <div class="collapse" id="25oct23bio">
              <div class="card card-body">
                <u>Andrea Ceni</u> received his Ph.D. in Computer Science from the University of Exeter, UK, in 2021. He subsequently worked as a Postdoctoral Research Associate at CEMPS. He is currently an Assistant Professor in the Department of Computer Science at the University of Pisa, Italy. His research focuses at tthe intersection of machine learning and neuroscience, approached through the lens of dynamical systems theory, with particular emphasis on recurrent neural networks.
              </div>
            </div>
            <br> 
            <a href="https://arxiv.org/abs/2505.18728"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
            <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#25oct23" role="button" aria-expanded="false" aria-controls="collapseExample">
                Abstract
              </a>
          <div class="collapse" id="25oct23">
          <div class="card card-body">
            The recent success of State-Space Models (SSMs) in sequence modeling has motivated their adaptation to graph learning, giving rise to Graph State-Space Models (GSSMs). However, existing GSSMs operate by applying SSM modules to sequences extracted from graphs, often compromising core properties such as permutation equivariance, message-passing compatibility, and computational efficiency. In this paper, we introduce a new perspective by embedding the key principles of modern SSM computation directly into the Message-Passing Neural Network framework, resulting in a unified methodology for both static and temporal graphs. Our approach, MP-SSM, enables efficient, permutation-equivariant, and long-range information propagation while preserving the architectural simplicity of message passing. Crucially, MP-SSM enables an exact sensitivity analysis, which we use to theoretically characterize information flow and evaluate issues like vanishing gradients and over-squashing in the deep regime. Furthermore, our design choices allow for a highly optimized parallel implementation akin to modern SSMs. We validate MP-SSM across a wide range of tasks, including node classification, graph property prediction, long-range benchmarks, and spatiotemporal forecasting, demonstrating both its versatility and strong empirical performance.
          </div>
        </li>


        <h4>[October 30th, 2025]</h4>
          <li>
            <b>
                <a href="https://arxiv.org/abs/2505.20882"> Fedivertex: a Graph Dataset based on Decentralized Social Networks for Trustworthy Machine Learning </a> 
            </b>
            <br> Presenter: <u>Edwige Cyffer</u> Institute of Science and Technology Austria, Klosterneuburg, Austria
            <a class="btn btn-info btn-xs" data-toggle="collapse" href="#25oct30bio" role="button" aria-expanded="false" aria-controls="collapseExample">
              Speaker Bio
            </a>
            <div class="collapse" id="25oct30bio">
              <div class="card card-body">
                <u>Edwige Cyffers</u> is a postdoctoral researcher at ISTA in Vienna and will join CNRS at Université Paris Dauphine in 2026 as a Researcher. Her PhD focused on differential privacy in fully decentralized learning, and she has published at leading venues such as NeurIPS, ICML, and AISTATS. She received the L'Oréal-UNESCO For Women in Science Young Talents Award and is committed to promoting the role of women in science.
              </div>
            </div>
            <br> 
            <a href="https://arxiv.org/abs/2505.20882"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
            <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#25oct30" role="button" aria-expanded="false" aria-controls="collapseExample">
                Abstract
              </a>
          <div class="collapse" id="25oct30">
          <div class="card card-body">
            Decentralized machine learning - where each client keeps its own data locally and uses its own computational resources to collaboratively train a model by exchanging peer-to-peer messages - is increasingly popular, as it enables better scalability and control over the data. A major challenge in this setting is that learning dynamics depend on the topology of the communication graph, which motivates the use of real graph datasets for benchmarking decentralized algorithms. Unfortunately, existing graph datasets are largely limited to for-profit social networks crawled at a fixed point in time and often collected at the user scale, where links are heavily influenced by the platform and its recommendation algorithms. The Fediverse, which includes several free and open-source decentralized social media platforms such as Mastodon, Misskey, and Lemmy, offers an interesting real-world alternative. We introduce Fedivertex, a new dataset of 182 graphs, covering seven social networks from the Fediverse, crawled weekly over 14 weeks. We release the dataset along with a Python package to facilitate its use, and illustrate its utility on several tasks, including a new defederation task, which captures a process of link deletion observed on these networks.
          </div>
        </li>

        <h4>[Nov 6th, 2025]</h4>
          <li>
            <b>
                <a href="https://arxiv.org/pdf/2503.02859"> Unsupervised Attributed Dynamic Network Embedding with Stability Guarantees </a> 
            </b>
            <br> Presenter: <u>Emma Ceccherini</u> University of Bristol
            <a class="btn btn-info btn-xs" data-toggle="collapse" href="#25sept18bio" role="button" aria-expanded="false" aria-controls="collapseExample">
              Speaker Bio
            </a>
            <div class="collapse" id="25sept18bio">
              <div class="card card-body">
                <u>Emma Ceccherini</u> is a PhD student in computational statistics at the University of Bristol, advised by Ian Gallagher and Dan Lawson. Her research focuses on dynamic network embeddings and generative models for networks.
              </div>
            </div>
            <br> 
            <a href="https://arxiv.org/pdf/2503.02859"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
            <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#25sept18" role="button" aria-expanded="false" aria-controls="collapseExample">
                Abstract
              </a>
          <div class="collapse" id="25sept18">
          <div class="card card-body">
            Stability for dynamic network embeddings ensures that nodes behaving the same at different times receive the same embedding, allowing comparison of nodes in the network across time. We present attributed unfolded adjacency spectral embedding (AUASE), a stable unsupervised representation learning framework for dynamic networks in which nodes are attributed with time-varying covariate information. To establish stability, we prove uniform convergence to an associated latent position model. We quantify the benefits of our dynamic embedding by comparing with state-of-the-art network representation learning methods on four real attributed networks. To the best of our knowledge, AUASE is the only attributed dynamic embedding that satisfies stability guarantees without the need for ground truth labels, which we demonstrate provides significant improvements for link prediction and node classification.
          </div>
        </li>







        



    <!-- <h4>[Time zone shift, we are now in Eastern Daylight Saving Time]</h4> -->
  
    </div>
  </div>
</section>


<section id="summer2025" class="some-section">
  <div class="container">
    <div class="row">
      <div class="col-sm-2"></div>
      <div class="col-sm-8">
        <div class="listing" style="clear:both;">
        <div class="left">
      
        <h3 style="text-align:center">Past Talks, Summer 2025</h3>

        <h4>[July 24th, 2025]</h4>
        <li>
          <b>
              <a href="https://escholarship.org/content/qt46s96557/qt46s96557_noSplash_7b6100d7e3d42f25f8a46f88a3ee4d56.pdf"> Neural Dynamics for Science: The Symbiosis of Deep Graph Learning and Differential Equations </a> 
          </b>
          <br> Presenter: <u>Zijie Huang</u> Google DeepMind
          <a class="btn btn-info btn-xs" data-toggle="collapse" href="#25july24bio" role="button" aria-expanded="false" aria-controls="collapseExample">
            Speaker Bio
          </a>
          <div class="collapse" id="25july24bio">
            <div class="card card-body">
              <u>Zijie Huang</u> is a research scientist at Google DeepMind, building Gemini. Her research interest lies in generative AI, AI4Science in general, with a special focus on LLMs, dynamical system modeling, knowledge graph reasoning, and diffusion models. She obtained her Ph.D. in computer science from UCLA, where she was co-advised by Prof. Yizhou Sun and Prof. Wei Wang. Her research was generously supported by Amazon Ph.D. Fellowship. Zijie Huang was selected as EECS rising star 2023.
            </div>
          </div>
          <br> 
          <a href="https://youtu.be/HJOYlygXHCs"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a>
          <a href="https://escholarship.org/content/qt46s96557/qt46s96557_noSplash_7b6100d7e3d42f25f8a46f88a3ee4d56.pdf"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
          <a href="https://github.com/Emory-Melody/Awesome-Graph-Neural-Differential-Equations"><img src="https://img.shields.io/badge/Github-link-lightgrey"></a>

          <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#25jan23" role="button" aria-expanded="false" aria-controls="collapseExample">
              Abstract
            </a>
        <div class="collapse" id="25jan23">
        <div class="card card-body">
          Many scientific problems require a deep understanding of internal structures and complex dynamics, spanning physical interactions within molecules, brain networks, and beyond. These problems can be formulated as modeling interacting dynamical systems using graphs, which represent entities as nodes and their relationship as edges. Traditionally, the dynamics of interacting systems are described by ordinary differential equations (ODEs), offering continuous and interpretable solutions but requiring significant domain expertise. Recent data-driven approaches such as Graph Neural Networks (GNNs) learn system dynamics from observational data, which however, struggle with long-term predictions and irregular observations due to their discrete dynamics. 
          In this talk, I will introduce GraphODE, a novel framework that combines the learning power of graph neural networks (GNNs) with the symbolic knowledge encoded in ODEs. In contrast with discrete models, GraphODE provides a principled approach to model continuous dynamical systems, from synthetic simulations to real-world scenarios like brain network analysis and COVID-19 prediction. I have further strengthened its power in three key areas: 1.) integrating data-driven inductive biases like energy conservation law; 2.) enhancing generalization ability; 3.) enabling causal decision-making. By merging deep graph learning with differential equations, I believe my research will pave the way for breakthroughs in symbolic deep learning for scientific discovery.
        </div>
      </li>


      <h4>[July 31st, 2025]</h4>
            <li>
              <b>
                  <a href="https://arxiv.org/abs/2505.11930"> The Logical Expressiveness of Temporal GNNs via Two-Dimensional Product Logics </a> 
              </b>
              <br> Presenter: <u>Marco Sälzer</u> RPTU Kaiserslautern-Landau Kaiserslautern, Germany
              <a class="btn btn-info btn-xs" data-toggle="collapse" href="#25july31bio" role="button" aria-expanded="false" aria-controls="collapseExample">
                Speaker Bio
              </a>
              <div class="collapse" id="25july31bio">
                <div class="card card-body">
                  <u>Marco Sälzer</u> is a postdoc at the Automated Reasoning Group, led by Anthony W. Lin, at the Rheinland-Pfälzische Technische Universität (RPTU) in Kaiserslautern, Germany.
                  Previously, he completed his PhD at the University of Kassel under the supervision of Martin Lange. His research lies at the intersection of formal methods and machine learning,
                  with a focus on the computational complexity of formal reasoning tasks for neural network models such as feedforward networks, graph neural networks (GNNs), transformers, and temporal GNNs,
                  which often goes hand in hand with efforts to rigorously characterise the expressive power of these models.
                </div>
              </div>
              <br> 
              <a href="https://youtu.be/Ez4_n_ABTMs"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a>
              <a href="https://arxiv.org/abs/2505.11930"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
              <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#25july31" role="button" aria-expanded="false" aria-controls="collapseExample">
                  Abstract
                </a>
            <div class="collapse" id="25july31">
            <div class="card card-body">
              In recent years, the expressive power of various neural architectures—including graph neural networks (GNNs), transformers, and recurrent neural networks—has been characterised using tools from logic and formal language theory. As the capabilities of basic architectures are becoming well understood, increasing attention is turning to models that combine multiple architectural paradigms. Among them particularly important, and challenging to analyse, are temporal extensions of GNNs, which integrate both spatial (graph-structure) and temporal (evolution over time) dimensions. In this paper, we initiate the study of logical characterisation of temporal GNNs by connecting them to two-dimensional product logics. We show that the expressive power of temporal GNNs depends on how graph and temporal components are combined. In particular, temporal GNNs that apply static GNNs recursively over time can capture all properties definable in the product logic of (past) propositional temporal logic PTL and the modal logic K. In contrast, architectures such as graph-and-time TGNNs and global TGNNs can only express restricted fragments of this logic, where the interaction between temporal and spatial operators is syntactically constrained. These results yield the first logical characterisations of temporal GNNs and establish new relative expressiveness results for temporal GNNs
            </div>
          </li>


          <h4>[August 7th, 2025] Skipped due to Attending KDD 2025</h4>

          <h4>[August 14th, 2025]</h4>
          <li>
            <b>
                <a href="https://arxiv.org/abs/2506.05393"> Are Large Language Models Good Temporal Graph Learners? </a> 
            </b>
            <br> Presenter: <u>Shenyang Huang</u> University of Oxford and <u>Emma Kondrup</u> Mila / McGill University
            <a class="btn btn-info btn-xs" data-toggle="collapse" href="#25aug14bio" role="button" aria-expanded="false" aria-controls="collapseExample">
              Speaker Bio
            </a>
            <div class="collapse" id="25aug14bio">
              <div class="card card-body">
                <u>Shenyang Huang</u> (he/him) is a postdoctoral scholar at University of Oxford. He obtained his PhD from McGill University and Mila, focusing on temporal graph learning (supervised by Prof. Reihaneh Rabbany and Prof. Guillaume Rabusseau). 
                  He is interested in representation learning on temporal graphs, anomaly detection and graph representation learning. He was the Organization Chair for the Temporal Graph Learning Workshop @ NeurIPS 2022.
                  His previous research includes change point detection on temporal graphs, COVID-19 disease modeling with temporal contact graphs and link prediction on temporal graphs. He also enjoys writing <a href="https://medium.com/@shenyanghuang1996">medium blog posts</a> about temporal graph learning. 
                <br> 
                <u>Emma Kondrup</u> (she/her) is a research intern at Mila - Quebec AI Institute supervised by Prof. Reihaneh Rabbany, and a research assistant at CeBIL (University of Copenhagen). Her research interests lies at the intersection of AI and law, particularly in health. On the technical side, she focuses on graph machine learning, with a special interest for temporal graph ML and applications of ML for misinformation detection.
                </div>
            </div>
            <br> 
            <a href="https://youtu.be/jmCwOQX9Ank"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a>
            <a href="https://arxiv.org/abs/2506.05393"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
            <a href="https://github.com/shenyangHuang/TGTalker"><img src="https://img.shields.io/badge/Github-link-lightgrey"></a>
            <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#25aug14" role="button" aria-expanded="false" aria-controls="collapseExample">
                Abstract
              </a>
          <div class="collapse" id="25aug14">
          <div class="card card-body">
            Large Language Models (LLMs) have recently driven significant advancements in Natural Language Processing and various other applications. While a broad range of literature has explored the graph-reasoning capabilities of LLMs, including their use of predictors on graphs, the application of LLMs to dynamic graphs -- real world evolving networks -- remains relatively unexplored. Recent work studies synthetic temporal graphs generated by random graph models, but applying LLMs to real-world temporal graphs remains an open question. To address this gap, we introduce Temporal Graph Talker (TGTalker), a novel temporal graph learning framework designed for LLMs. TGTalker utilizes the recency bias in temporal graphs to extract relevant structural information, converted to natural language for LLMs, while leveraging temporal neighbors as additional information for prediction. TGTalker demonstrates competitive link prediction capabilities compared to existing Temporal Graph Neural Network (TGNN) models. Across five real-world networks, TGTalker performs competitively with state-of-the-art temporal graph methods while consistently outperforming popular models such as TGN and HTGN. Furthermore, TGTalker generates textual explanations for each prediction, thus opening up exciting new directions in explainability and interpretability for temporal link prediction. The code is publicly available at this https URL.
          </div>
        </li>


          <h4>[August 21st, 2025]</h4>
          <li>
            <b>
                <a href="https://arxiv.org/pdf/2506.05725"> Large Language Models are Good Relational Learners  </a> 
            </b>
            <br> Presenter: <u>Fang Wu</u> and <u>Vijay Prakash Dwivedi</u> Stanford University
            <a class="btn btn-info btn-xs" data-toggle="collapse" href="#25aug21bio" role="button" aria-expanded="false" aria-controls="collapseExample">
              Speaker Bio
            </a>
            <div class="collapse" id="25aug21bio">
              <div class="card card-body">
                <u>Fang Wu</u> is a CS PhD student at Stanford University, advised by Yejin Choi and Jure Leskovec. His research interests lie in LLMs, GNNs, and some AI4Science applications.
                <br>
                <u>Vijay Prakash Dwivedi</u> is a postdoctoral scholar at Stanford University advised by Jure Leskovec. His research focuses on improving deep learning methods for graphs and relational structured data.
              </div>
            </div>
            <br> 
            <a href="https://youtu.be/zCzEAfWiKk4"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a>
            <a href="https://arxiv.org/abs/2506.05725"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
            <a href="https://github.com/smiles724/Rel-LLM"><img src="https://img.shields.io/badge/Github-link-lightgrey"></a>
            <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#25aug21" role="button" aria-expanded="false" aria-controls="collapseExample">
                Abstract
              </a>
          <div class="collapse" id="25aug21">
          <div class="card card-body">
            Large language models (LLMs) have demonstrated remarkable capabilities across various domains, yet their application to relational deep learning (RDL) remains underexplored. Existing approaches adapt LLMs by traversing relational links between entities in a database and converting the structured data into flat text documents. Still, this text-based serialization disregards critical relational structures, introduces redundancy, and often exceeds standard LLM context lengths. We introduce Rel-LLM, a novel architecture that utilizes a graph neural network (GNN)- based encoder to generate structured relational prompts for LLMs within a retrieval-augmented generation (RAG) framework. Unlike traditional text-based serialization approaches, our method preserves the inherent relational structure of databases while enabling LLMs to effectively process and reason over complex entity relationships. Specifically, the GNN encoder extracts a local subgraph around an entity to build feature representations that contain relevant entity relationships and temporal dependencies. These representations are transformed into structured prompts using a denormalization process, effectively allowing the LLM to reason over relational structures. Through extensive experiments, we demonstrate that Rel-LLM outperforms existing methods on key RDL tasks, offering a scalable and efficient approach to integrating LLMs with structured data sources. Code is available at this https URL.
          </div>
        </li>


        <h4>[August 28th, 2025]</h4>
          <li>
            <b>
                <a href="https://arxiv.org/abs/2406.10426"> MiNT: Multi-Network Training for Transfer Learning on Temporal Graphs</a> 
            </b>
            <br> Presenter: <u>Kiarash Shamsi</u> Department of Computer Science, University of Manitoba 
            <a class="btn btn-info btn-xs" data-toggle="collapse" href="#25aug28bio" role="button" aria-expanded="false" aria-controls="collapseExample">
              Speaker Bio
            </a>
            <div class="collapse" id="25aug28bio">
              <div class="card card-body">
                <u> Kiarash Shamsi </u> is currently a Ph.D. student at the University of Manitoba, under the supervision of Dr. Cuneyt Akcora. He has published as a first author in reputable conferences such as NeurIPS, ICLR, and ICBC. His research interests encompass a wide range of topics, including temporal graph learning, graph learning, topological data analysis, and blockchain data analysis and systems.
              </div>
            </div>
            <br> 
            <a href="https://youtu.be/4GX8CcBSEzs"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a>
            <a href="https://arxiv.org/abs/2406.10426"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
            <a href="https://github.com/benjaminnNgo/ScalingTGNs"><img src="https://img.shields.io/badge/Github-link-lightgrey"></a>
            <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#25aug28" role="button" aria-expanded="false" aria-controls="collapseExample">
                Abstract
              </a>
          <div class="collapse" id="25aug28">
          <div class="card card-body">
            Temporal Graph Learning (TGL) has become a robust framework for discovering patterns in dynamic networks and predicting future interactions. While existing research has largely concentrated on learning from individual networks, this study explores the potential of learning from multiple temporal networks and its ability to transfer to unobserved networks. To achieve this, we introduce Temporal Multi-network Training MiNT, a novel pre-training approach that learns from multiple temporal networks. With a novel collection of 84 temporal transaction networks, we pre-train TGL models on up to 64 networks and assess their transferability to 20 unseen networks. Remarkably, MiNT achieves state-of-the-art results in zero-shot inference, surpassing models individually trained on each network. Our findings further demonstrate that increasing the number of pre-training networks significantly improves transfer performance. This work lays the groundwork for developing Temporal Graph Foundation Models, highlighting the significant potential of multi-network pre-training in TGL.          
          </div>
        </li>

        <h4>[September 11th, 2025]</h4>
        <li>
          <b>
              <a href="https://www.nature.com/articles/s42003-025-07764-y"> A large-scale benchmark for network inference from single-cell perturbation data </a> 
          </b>
          <br> Presenter: <u>Mathieu Chevalley</u> ETH Zurich and GSK.ai
          <a class="btn btn-info btn-xs" data-toggle="collapse" href="#25sept11bio" role="button" aria-expanded="false" aria-controls="collapseExample">
            Speaker Bio
          </a>
          <div class="collapse" id="25sept11bio">
            <div class="card card-body">
              <u>Mathieu Chevalley</u> is a PhD candidate at ETH Zurich and GSK.ai (supervisors: Prof. Nicolai Meinshausen, Dr. Patrick Schwab), developing scalable machine-learning methods for causal discovery from large-scale biological data
            </div>
          </div>
          <br> 
          <a href="https://www.nature.com/articles/s42003-025-07764-y"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
          <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#25sept11" role="button" aria-expanded="false" aria-controls="collapseExample">
              Abstract
            </a>
        <div class="collapse" id="25sept11">
        <div class="card card-body">
          Mapping biological mechanisms in cellular systems is a fundamental step in early-stage drug discovery that serves to generate hypotheses on what disease-relevant molecular targets may effectively be modulated by pharmacological interventions. With the advent of high-throughput methods for measuring single-cell gene expression under genetic perturbations, we now have effective means for generating evidence for causal gene-gene interactions at scale. However, evaluating the performance of network inference methods in real-world environments is challenging due to the lack of ground-truth knowledge. Moreover, traditional evaluations conducted on synthetic datasets do not reflect the performance in real-world systems. We thus introduce CausalBench, a benchmark suite revolutionizing network inference evaluation with real-world, large-scale single-cell perturbation data. CausalBench, distinct from existing benchmarks, offers biologically-motivated metrics and distribution-based interventional measures, providing a more realistic evaluation of network inference methods. An initial systematic evaluation of state-of-the-art causal inference methods using our CausalBench suite highlights how poor scalability of existing methods limits performance. Moreover, methods that use interventional information do not outperform those that only use observational data, contrary to what is observed on synthetic benchmarks. CausalBench subsequently enables the development of numerous promising methods through a community challenge, thus demonstrating its potential as a transformative tool in the field of computational biology, bridging the gap between theoretical innovation and practical application in drug discovery and disease understanding. Thus, CausalBench opens new avenues for method developers in causal network inference research, and provides to practitioners a principled and reliable way to track progress in network methods for real-world interventional data.
        </div>
      </li>

      <h4>[October 2nd, 2025]</h4>
          <li>
            <b>
                <a href="https://arxiv.org/abs/2505.19408"> Future Link Prediction Without Memory or Aggregation </a> 
            </b>
            <br> Presenter: <u>Lu Yi</u> Renmin University of China,
            <a class="btn btn-info btn-xs" data-toggle="collapse" href="#25oct2bio" role="button" aria-expanded="false" aria-controls="collapseExample">
              Speaker Bio
            </a>
            <div class="collapse" id="25oct2bio">
              <div class="card card-body">
                <u>Lu Yi</u> is a Ph.D. candidate at the ALGO Lab, Renmin University of China, supervised by Prof. Zhewei Wei. She received her B.Sc. degree in Computer Science and Technology from Beijing University of Posts and Telecommunications in 2022. Her research interests include dynamic graph learning, multi-agent systems, graph unlearning, and efficient graph algorithms. She will be visiting the University of Montreal from September 2025 for six months. Her homepage is https://luyi256.github.io/.
              </div>
            </div>
            <br> 
            <a href="https://arxiv.org/abs/2505.19408"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
            <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#25oct2" role="button" aria-expanded="false" aria-controls="collapseExample">
                Abstract
              </a>
          <div class="collapse" id="25oct2">
          <div class="card card-body">
            Future link prediction on temporal graphs is a fundamental task with wide applicability in real-world dynamic systems. These scenarios often involve both recurring (seen) and novel (unseen) interactions, requiring models to generalize effectively across both types of edges. However, existing methods typically rely on complex memory and aggregation modules, yet struggle to handle unseen edges. In this paper, we revisit the architecture of existing temporal graph models and identify two essential but overlooked modeling requirements for future link prediction: representing nodes with unique identifiers and performing target-aware matching between source and destination nodes. To this end, we propose Cross-Attention based Future Link Predictor on Temporal Graphs (CRAFT), a simple yet effective architecture that discards memory and aggregation modules and instead builds on two components: learnable node embeddings and cross-attention between the destination and the source's recent interactions. This design provides strong expressive power and enables target-aware modeling of the compatibility between candidate destinations and the source's interaction patterns. Extensive experiments on diverse datasets demonstrate that CRAFT consistently achieves superior performance with high efficiency, making it well-suited for large-scale real-world applications. 
          </div>
        </li>


        







  

    </div>
  </div>
</section>




<section id="winter2025" class="some-section">
  <div class="container">
    <div class="row">
      <div class="col-sm-2"></div>
      <div class="col-sm-8">
        <div class="listing" style="clear:both;">
        <div class="left">
      
        <h3 style="text-align:center">Past Talks, Winter 2025</h3>



        <h4>[January 16th, 2025]</h4>
            <li>
              <b>
                  <a href="https://arxiv.org/pdf/2410.13469"> Interpreting Temporal Graph Neural Networks with Koopman Theory </a> 
              </b>
              <br> Presenter: <u>Michele Guerra</u> UiT The Arctic University of Norway, Department of Mathematics and Statistics, Norway
              <a class="btn btn-info btn-xs" data-toggle="collapse" href="#25jan16bio" role="button" aria-expanded="false" aria-controls="collapseExample">
                Speaker Bio
              </a>
              <div class="collapse" id="25jan16bio">
                <div class="card card-body">
                  <u>Michele Guerra</u> is a Ph.D. student in the Department of Mathematics and Statistics at UiT The Arctic University of Norway. He received his MSc (2019) and BSc (2016) degrees in Physics from University of Padua, Italy. Michele’s research spans from uncertainty quantification to interpretability for randomised and trainable models on time series and graphs.
                </div>
              </div>
              <br> 
              <a href="https://youtu.be/GWFtIffcE0M"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a>
              <a href="https://arxiv.org/pdf/2410.13469"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
              <a href="https://github.com/NGMLGroup/Koopman-TGNN-Interpretability"><img src="https://img.shields.io/badge/Github-link-lightgrey"></a>

              <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#25jan16" role="button" aria-expanded="false" aria-controls="collapseExample">
                  Abstract
                </a>
            <div class="collapse" id="25jan16">
            <div class="card card-body">
              Spatiotemporal graph neural networks (STGNNs)
              have shown promising results in many domains, from
              forecasting to epidemiology. However, understanding the dynamics learned by these models and explaining their behaviour is significantly more complex than for models dealing with static data. Inspired by Koopman theory, which allows a simpler
              description of intricate, nonlinear dynamical systems, we introduce an explainability approach for
              temporal graphs. We present two methods to interpret the STGNN’s decision process and identify
              the most relevant spatial and temporal patterns in
              the input for the task at hand. The first relies on
              dynamic mode decomposition (DMD), a Koopmaninspired dimensionality reduction method. The second relies on sparse identification of nonlinear dynamics (SINDy), a popular method for discovering
              governing equations, which we use for the first time
              as a general tool for explainability. We show how
              our methods can correctly identify interpretable features such as infection times and infected nodes in
              the context of dissemination processes.
            </div>
          </li>


        <h4>[January 30th, 2025]</h4>
        <li>
          <b>
              <a href="https://openreview.net/forum?id=8imVCizVEw"> Learning-Based Link Anomaly Detection in Continuous-Time Dynamic Graphs </a> (TMLR) 
          </b>
          <br> Presenter: <u>Tim Poštuvan</u> EPFL
          <a class="btn btn-info btn-xs" data-toggle="collapse" href="#25jan30bio" role="button" aria-expanded="false" aria-controls="collapseExample">
            Speaker Bio
          </a>
          <div class="collapse" id="25jan30bio">
            <div class="card card-body">
              <u>Tim Poštuvan</u> is a Research Scientist at DeepL, specializing in natural language processing. He holds a master’s degree in Data Science from the École Polytechnique Fédérale de Lausanne (EPFL). His current research focuses on enhancing large language models (LLMs) through reinforcement learning from human feedback.
            </div>
          </div>
          <br> 
          <a href="https://youtu.be/1hV6AE8zjIY"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a>
          <a href="https://openreview.net/forum?id=8imVCizVEw"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
          <a href="https://github.com/timpostuvan/CTDG-link-anomaly-detection?tab=readme-ov-file"><img src="https://img.shields.io/badge/Github-link-lightgrey"></a>
          <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#25jan30" role="button" aria-expanded="false" aria-controls="collapseExample">
              Abstract
            </a>
        <div class="collapse" id="25jan30">
        <div class="card card-body">
          Anomaly detection in continuous-time dynamic graphs is an emerging field yet underexplored in the context of learning algorithms. In this paper, we pioneer structured analyses of link-level anomalies and graph representation learning for identifying categorically
          anomalous graph links. First, we introduce a fine-grained taxonomy for edge-level anomalies
          leveraging structural, temporal, and contextual graph properties. Based on these properties,
          we introduce a method for generating and injecting typed anomalies into graphs. Next, we
          introduce a novel method to generate continuous-time dynamic graphs featuring consistencies across either or combinations of time, structure, and context. To enable temporal graph
          learning methods to detect specific types of anomalous links rather than the bare existence
          of a link, we extend the generic link prediction setting by: (1) conditioning link existence
          on contextual edge attributes; and (2) refining the training regime to accommodate diverse
          perturbations in the negative edge sampler. Comprehensive benchmarks on synthetic and
          real-world datasets – featuring synthetic and labeled organic anomalies and employing six
          state-of-the-art link prediction methods – validate our taxonomy and generation processes
          for anomalies and benign graphs, as well as our approach to adapting methods for anomaly
          detection. Our results reveal that different learning methods excel in capturing different
          aspects of graph normality and detecting different types of anomalies. We conclude with
          a comprehensive list of findings highlighting opportunities for future research. The code is
          available at https://github.com/timpostuvan/CTDG-link-anomaly-detection.
        </div>
      </li>

      <h4>[Feb 6th, 2025]</h4>
      <li>
        <b>
            <a href="https://openreview.net/pdf/f7ebe8406d2b497951e78f9b8f76d6ef0e79cc3f.pdf"> Towards Neural Scaling Laws on Graphs </a> (LOG 2024) 
            <br> 
            <a href="https://openreview.net/pdf/b3c2dec341f08c88d8203a954c3be27b2b9b0a78.pdf"> Do Neural Scaling Laws Exist on Graph Self-Supervised Learning </a> (LOG 2024) 

        </b>
        <br> Presenter: <u>Jingzhe Liu</u> Michigan State University and <u>Qian Ma</u> Rensselaer Polytechnic Institute
        <a class="btn btn-info btn-xs" data-toggle="collapse" href="#25feb6bio" role="button" aria-expanded="false" aria-controls="collapseExample">
          Speaker Bio
        </a>
        <div class="collapse" id="25feb6bio">
          <div class="card card-body">
            <u>Jingzhe Liu</u> is a second-year PhD student at Michigan State University, supervised by Dr. Jiliang Tang. Before that, he got his bachelor degree from Shanghai Jiao Tong University. His research interests focus on applying cutting-edge artificial intelligence techniques to understand and to learn the knowledge in complex networks.
            <br>
            <u>Qian Ma</u> is a first-year PhD student at Rensselaer Polytechnic Institute(RPI), supervised by Dr. Yao Ma. Prior to that he earned his Master’s Degree from City University of Hong Kong(CityU), where he worked closely with Dr. Xiangyu Zhao and Dr. Haoliang Li on spatial-temporal data analysis. He also holds a Bachelor’s degree from the University of Electronic Science and Technology of China (UESTC).
          </div>
        </div>
        <br> 
        <a href="https://youtu.be/8K0m88kwENs"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a>
        <a href="https://openreview.net/pdf/f7ebe8406d2b497951e78f9b8f76d6ef0e79cc3f.pdf"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
        <a href="https://openreview.net/pdf/b3c2dec341f08c88d8203a954c3be27b2b9b0a78.pdf"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
        <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#25feb6" role="button" aria-expanded="false" aria-controls="collapseExample">
            Abstract
          </a>
      <div class="collapse" id="25feb6">
      <div class="card card-body">
        Deep graph models (e.g., graph neural networks and graph transformers) have become important techniques for leveraging knowledge across various types of graphs. Yet, the neural scaling laws on graphs, i.e., how the performance of deep graph models changes with model and dataset sizes, have not been systematically investigated, casting doubts on the feasibility of achieving large graph models. To fill this gap, we benchmark many graph datasets from different tasks and make an attempt to establish the neural scaling laws on graphs from both model and data perspectives. The model size we investigated is up to 100 million parameters, and the dataset size investigated is up to 50 million samples. We first verify the validity of such laws on graphs, establishing proper formulations to describe the scaling behaviors. For model scaling, we identify that despite the parameter numbers, the model depth also plays an important role in affecting the model scaling behaviors, which differs from observations in other domains such as CV and NLP. For data scaling, we suggest that the number of graphs can not effectively measure the graph data volume in scaling law since the sizes of different graphs are highly irregular. Instead, we reform the data scaling law with the number of nodes or edges as the metric to address the irregular graph sizes. We further demonstrate that the reformed law offers a unified view of the data scaling behaviors for various fundamental graph tasks including node classification, link prediction, and graph classification. This work provides valuable insights into neural scaling laws on graphs, which can serve as an important tool for collecting new graph data and developing large graph models.
      </div>
    </li>


    <h4>[Feb 13th, 2025]</h4>
      <li>
        <b>
            <a href="https://openreview.net/forum?id=266nH7kLSV&noteId=vhZ9sXPFfc"> Temporal Graph Neural Tangent Kernel with Graphon-Guaranteed </a> (NeurIPS 2024)  
        </b>
        <br> Presenter: <u>Katherine Tieu</u>  University of Illinois at Urbana-Champaign
        <a class="btn btn-info btn-xs" data-toggle="collapse" href="#25feb13bio" role="button" aria-expanded="false" aria-controls="collapseExample">
          Speaker Bio
        </a>
        <div class="collapse" id="25feb13bio">
          <div class="card card-body">
            <u>Katherine Tieu</u> is a senior undergraduate student at University of Illinois Urbana-Champaign. Her research interests include Graph Representation Learning, and Trustworthy Machine Learning.
          </div>
        </div>
        <br> 
        <a href="https://youtu.be/tlCEjwQ0_YM"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a>
        <a href="https://openreview.net/forum?id=266nH7kLSV&noteId=vhZ9sXPFfc"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
        <a href="https://github.com/kthrn22/TempGNTK"><img src="https://img.shields.io/badge/Github-link-lightgrey"></a>
        <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#25feb13" role="button" aria-expanded="false" aria-controls="collapseExample">
            Abstract
          </a>
      <div class="collapse" id="25feb13">
      <div class="card card-body">
        Graph Neural Tangent Kernel (GNTK) fuses graph neural networks and graph kernels, simplifies the process of graph representation learning, interprets the training dynamics of graph neural networks, and serves various applications like protein identification, image segmentation, and social network analysis. In practice, graph data carries complex information among entities that inevitably evolves over time, and previous static graph neural tangent kernel methods may be stuck in the sub-optimal solution in terms of both effectiveness and efficiency. As a result, extending the advantage of GNTK to temporal graphs becomes a critical problem. To this end, we propose the temporal graph neural tangent kernel, which not only extends the simplicity and interpretation ability of GNTK to the temporal setting but also leads to rigorous temporal graph classification error bounds. Furthermore, we prove that when the input temporal graph grows over time in the number of nodes, our temporal graph neural tangent kernel will converge in the limit to the graphon NTK value, which implies the transferability and robustness of the proposed kernel method, named Temporal Graph Neural Tangent Kernel with Graphon-Guaranteed or Temp-GNTK. In addition to the theoretical analysis, we also perform extensive experiments, not only demonstrating the superiority of Temp-GNTK in the temporal graph classification task, but also showing that Temp-G^3NTK can achieve very competitive performance in node-level tasks like node classification compared with various SOTA graph kernel and representation learning baselines. Our code is available at https://github.com/kthrn22/TempGNTK.
      </div>
    </li>


    <h4>[Feb 20th, 2025]</h4>
      <li>
        <b>
            <a href="https://openreview.net/forum?id=9M2XqvH2SB"> Reproducibility study of: “Explaining Temporal Graph Models Through an Explorer-Navigator Framework </a> (TMLR and NeurIPS Journal Track)  
        </b>
        <br> Presenter: <u>Andreas Berentzen</u> and <u>Jesse Wonnink</u> University of Amsterdam
        <a class="btn btn-info btn-xs" data-toggle="collapse" href="#25feb20bio" role="button" aria-expanded="false" aria-controls="collapseExample">
          Speaker Bio
        </a>
        <div class="collapse" id="25feb20bio">
          <div class="card card-body">
            <u>Andreas Berentzen</u> began his journey in artificial intelligence in 2017, studying AI at the University of Amsterdam. He completed his bachelor's degree in 2021 with a thesis on aggregation functions for hypergraph neural networks. After 2.5 years as a machine learning consultant and developer, he returned to the University of Amsterdam to pursue a master’s degree in AI, driven by a desire to deepen his understanding of contemporary neural networks. During his master’s, Andreas presented graph ML projects at ICML 2024 and NeurIPS 2024. He is currently working on his thesis at TNO, exploring graph-based unsupervised anomaly detection for operational technology. Ever since his bachelor’s, he has been passionate about graph modeling and graph machine learning and hopes to continue in this field for many years.
            Andreas is always open to connecting with others interested in graph-related topics! Twitter handle: https://x.com/AndyTheGuttler             
          </div>
        </div>
        <br> 
        <a href="https://youtu.be/NyE5mLZ86AA"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a>
        <a href="https://openreview.net/forum?id=9M2XqvH2SB"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
        <a href="https://github.com/cisaic/tgnnexplainer"><img src="https://img.shields.io/badge/Github-link-lightgrey"></a>
        <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#25feb20" role="button" aria-expanded="false" aria-controls="collapseExample">
            Abstract
          </a>
      <div class="collapse" id="25feb20">
      <div class="card card-body">
        This paper seeks to reproduce and extend the results of the paper “Explaining Temporal Graph Models Through an Explorer-Navigator Framework” by (Xia et al., 2023). The main contribution of the original authors is a novel explainer for temporal graph networks, the Temporal GNN Explainer (T-GNNExplainer), which finds a subset of preceding events that “explain” a prediction made by a temporal graph model. The explorer is tested on two temporal graph models that are trained on two real-world and two synthetic datasets. The explorer is evaluated using a newly proposed metric for explanatory graph models. The authors compare the performance of their explorer to three baseline explainer methods, either adapted from a GNN explainer or developed by the authors. The authors claim that T-GNNExplainer achieves superior performance compared to the baselines when evaluated with their proposed metric. This work reproduces the original experiments by using the code (with minor adjustments), model specifications, and hyperparameters provided by the original authors. To evaluate the robustness of these claims, the method was extended to one new dataset (MOOC). Results show that the T-GNNexplainer performs best on some, but not all metrics as reported in the original findings. We conclude that the main lines of this paper hold up even though all results are less pronounced than claimed. Results show that the T-GNNExplainer does not perform similarly across different T-GNN models, precise dataset specifications are needed to obtain high performance, and there are simpler, less computationally costly explainer methods (like PBONE) that could offer competitive results.
      </div>
    </li>


    <h4>[Feb 27th, 2025]</h4>
      <li>
        <b>
            <a href="https://openreview.net/forum?id=ZKHV6Cpsxg"> UTG: Towards a Unified View of Snapshot and Event Based Models for Temporal Graphs </a> (LOG 2024)  
        </b>
        <br> Presenter: <u>Shenyang Huang</u> McGill University, Mila
        <a class="btn btn-info btn-xs" data-toggle="collapse" href="#25feb27bio" role="button" aria-expanded="false" aria-controls="collapseExample">
          Speaker Bio
        </a>
        <div class="collapse" id="25feb27bio">
          <div class="card card-body">
            <u>Shenyang Huang</u>(he/him) is a PhD student at McGill University and Mila, focusing on temporal graph learning (supervised by Prof. Reihaneh Rabbany and Prof. Guillaume Rabusseau). He is interested in representation learning on temporal graphs, anomaly detection and graph representation learning. He was the Organization Chair for the Temporal Graph Learning Workshop @ NeurIPS 2022. His previous research includes change point detection on temporal graphs, COVID-19 disease modeling with temporal contact graphs and link prediction on temporal graphs. He also enjoys writing medium blog posts about temporal graph learning.
          </div>
        </div>
        <br> 
        <a href="https://youtu.be/zLfzIIRj5uo"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a>
        <a href="https://openreview.net/forum?id=ZKHV6Cpsxg"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
        <a href="https://github.com/shenyangHuang/UTG"><img src="https://img.shields.io/badge/Github-link-lightgrey"></a>
        <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#25feb27" role="button" aria-expanded="false" aria-controls="collapseExample">
            Abstract
          </a>
      <div class="collapse" id="25feb27">
      <div class="card card-body">
        Many real world graphs are inherently dynamic, constantly evolving with node and edge additions. These graphs can be represented by temporal graphs, either through a stream of edge events or a sequence of graph snapshots. Until now, the development of machine learning methods for both types has occurred largely in isolation, resulting in limited experimental comparison and theoretical cross- pollination between the two. In this paper, we introduce Unified Temporal Graph (UTG), a framework that unifies snapshot-based and event-based machine learning models under a single umbrella, enabling models developed for one representation to be applied effectively to datasets of the other. We also propose a novel UTG training procedure to boost the performance of snapshot-based models in the streaming setting. We comprehensively evaluate both snapshot and event-based models across both types of temporal graphs on the temporal link prediction task. Our main findings are threefold: first, when combined with UTG training, snapshot-based models can perform competitively with event- based models such as TGN and GraphMixer even on event datasets. Second, snapshot-based models are at least an order of magnitude faster than most event- based models during inference. Third, while event-based methods such as NAT and DyGFormer outperforms snapshot-based methods on both types of temporal graphs, this is because they leverage joint neighborhood structural features thus emphasizing the potential to incorporate these features into snapshot-based models as well. These findings highlight the importance of comparing model architectures independent of the data format and suggest the potential of combining the efficiency of snapshot-based models with the performance of event-based models in the future.
      </div>
    </li>


    <h4>[March 6th, 2025]</h4>
      <li>
        <b>
            <a href="https://arxiv.org/abs/2310.15865"> Using Time-Aware Graph Neural Networks to Predict Temporal Centralities in Dynamic Graphs </a> (NeurIPS 2024)  
        </b>
        <br> Presenter: <u>Franziska Heeg</u> Julius-Maximilans-Universität, Würzburg
        <a class="btn btn-info btn-xs" data-toggle="collapse" href="#25mar6bio" role="button" aria-expanded="false" aria-controls="collapseExample">
          Speaker Bio
        </a>
        <div class="collapse" id="25mar6bio">
          <div class="card card-body">
            <u>Franziska Heeg</u> completed her Master's degree in Mathematics at the University of Würzburg. Since 2022, she has been a PhD student at the Chair for Machine Learning for Complex Networks at the Center for AI and Data Science (CAIDAS) at the University of Würzburg. Her research focuses on using higher-order network models for temporal graph learning
          </div>
        </div>
        <br> 
        <a href="https://openreview.net/forum?id=6n709MszkP"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
        <a href="https://zenodo.org/records/10202792"><img src="https://img.shields.io/badge/Github-link-lightgrey"></a>
        <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#25mar6" role="button" aria-expanded="false" aria-controls="collapseExample">
            Abstract
          </a>
      <div class="collapse" id="25mar6">
      <div class="card card-body">
        Node centralities play a pivotal role in network science, social network analysis,
        and recommender systems. In temporal data, static path-based centralities like
        closeness or betweenness can give misleading results about the true importance
        of nodes in a temporal graph. To address this issue, temporal generalizations
        of betweenness and closeness have been defined that are based on the shortest
        time-respecting paths between pairs of nodes. However, a major issue of those
        generalizations is that the calculation of such paths is computationally expensive.
        Addressing this issue, we study the application of De Bruijn Graph Neural Networks
        (DBGNN), a time-aware graph neural network architecture, to predict temporal
        path-based centralities in time series data. We experimentally evaluate our approach in 13 temporal graphs from biological and social systems and show that
        it considerably improves the prediction of betweenness and closeness centrality
        compared to (i) a static Graph Convolutional Neural Network, (ii) an efficient
        sampling-based approximation technique for temporal betweenness, and (iii) two
        state-of-the-art time-aware graph learning techniques for dynamic graphs.
      </div>
    </li>


    <h4>[March 13th, 2025]</h4>
      <li>
        <b>
            <a href="https://arxiv.org/pdf/2408.04713v3"> DyGMamba: Efficiently Modeling Long-Term Temporal Dependency on Continuous-Time Dynamic Graphs with State Space Models </a>  
        </b>
        <br> Presenter: <u>Zifeng Ding</u> University of Cambridge
        <a class="btn btn-info btn-xs" data-toggle="collapse" href="#25mar13bio" role="button" aria-expanded="false" aria-controls="collapseExample">
          Speaker Bio
        </a>
        <div class="collapse" id="25mar13bio">
          <div class="card card-body">
            <u>Zifeng Ding</u> is a Research Associate (Postdoctoral Researcher) at the University of Cambridge. Currently, he is working with Prof. Andreas Vlachos in the Cambridge NLIP Group. His research interests include temporal reasoning with LLMs, multimodal fact-checking, LLM hallucination detection and mitigation, synthetic data generation for LLMs, and representation learning on structured knowledge (e.g., knowledge graphs) as well as temporal/dynamic graphs.
          </div>
        </div>
        <br> 
        <a href="https://youtu.be/CT3qw3IElzo"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a>
        <a href="https://arxiv.org/pdf/2408.04713v3"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
        <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#25mar13" role="button" aria-expanded="false" aria-controls="collapseExample">
            Abstract
          </a>
      <div class="collapse" id="25mar13">
      <div class="card card-body">
        Learning useful representations for continuous-time dynamic graphs (CTDGs) is challenging, due to the concurrent need to span long node interaction histories and grasp nuanced temporal details. In particular, two problems emerge: (1) Encoding longer histories requires more computational resources, making it crucial for CTDG models to maintain low computational complexity to ensure efficiency; (2) Meanwhile, more powerful models are needed to identify and select the most critical temporal information within the extended context provided by longer histories. To address these problems, we propose a CTDG representation learning model named DyGMamba, originating from the popular Mamba state space model (SSM). DyGMamba first leverages a node-level SSM to encode the sequence of historical node interactions. Another time-level SSM is then employed to exploit the temporal patterns hidden in the historical graph, where its output is used to dynamically select the critical information from the interaction history. We validate DyGMamba experimentally on the dynamic link prediction task. The results show that our model achieves state-of-the-art in most cases. DyGMamba also maintains high efficiency in terms of computational resources, making it possible to capture long temporal dependencies with a limited computation budget.
      </div>
    </li>


    <h4>[March 20th, 2025]</h4>
    <li>
      <b>
          <a href="https://arxiv.org/abs/2407.09618"> The Heterophilic Graph Learning Handbook: Benchmarks, Models, Theoretical Analysis, Applications and Challenges </a>  
      </b>
      <br> Presenter: <u>Sitao Luan</u> Mila, McGill University
      <a class="btn btn-info btn-xs" data-toggle="collapse" href="#25mar20bio" role="button" aria-expanded="false" aria-controls="collapseExample">
        Speaker Bio
      </a>
      <div class="collapse" id="25mar20bio">
        <div class="card card-body">
          <u>Sitao Luan</u>  is an incoming postdoctoral fellow at Mila. He obtained his Ph.D. degree in computer science at McGill University in 2024, under the supervision of Professor Xiao-Wen Chang and Doina Precup. His research interests are graph representation learning and graph neural networks, focusing on addressing the heterophily problem. He will introduce the recent progress of heterophilic graph learning and discuss how it can be developed for temporal graph learning.
        </div>
      </div>
      <br> 
      <a href="https://youtu.be/c60o4_WaMqM"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a>
      <a href="https://drive.google.com/file/d/1b4_aGA6u6jr-HPQx9D6pV5Yqu239xv5w/view?usp=sharing"> <img src="https://img.shields.io/badge/Talk%20-Slides-blue"></a>
      <a href="https://drive.google.com/file/d/1arMehKyDaKzZKHcLBUYCIcStK6JO8DzW/view?usp=sharing"> <img src="https://img.shields.io/badge/Talk%20-Slides-blue"></a>
      <a href="https://arxiv.org/abs/2407.09618"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
      <a href="https://www.arxiv.org/abs/2412.16435"><img src="https://img.shields.io/badge/Paper-link-important"></a>
      <a href="https://sites.google.com/mila.quebec/heterophilic-graph-learning/home"><img src="https://img.shields.io/badge/website-blue"></a>
      <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#25mar20" role="button" aria-expanded="false" aria-controls="collapseExample">
          Abstract
        </a>
    <div class="collapse" id="25mar20">
    <div class="card card-body">
      Homophily principle, i.e. nodes with the same labels or similar attributes are more likely to be connected, has been commonly believed to be the main reason for the superiority of Graph Neural Networks (GNNs) over traditional Neural Networks (NNs) on graph-structured data, especially on node-level tasks. However, recent work has identified a non-trivial set of datasets where GNN's performance compared to the NN's is not satisfactory. Heterophily, i.e. low homophily, has been considered the main cause of this empirical observation. People have begun to revisit and re-evaluate most existing graph models, including graph transformer and its variants, in the heterophily scenario across various kinds of graphs, e.g. heterogeneous graphs, temporal graphs and hypergraphs. Moreover, numerous graph-related applications are found to be closely related to the heterophily problem. In the past few years, considerable effort has been devoted to studying and addressing the heterophily issue.
In this survey, we provide a comprehensive review of the latest progress on heterophilic graph learning, including an extensive summary of benchmark datasets and evaluation of homophily metrics on synthetic graphs, meticulous classification of the most updated supervised and unsupervised learning methods, thorough digestion of the theoretical analysis on homophily/heterophily, and broad exploration of the heterophily-related applications. Notably, through detailed experiments, we are the first to categorize benchmark heterophilic datasets into three sub-categories: malignant, benign and ambiguous heterophily. Malignant and ambiguous datasets are identified as the real challenging datasets to test the effectiveness of new models on the heterophily challenge. Finally, we propose several challenges and future directions for heterophilic graph representation learning.
    </div>
  </li>


  <h4>[March 27th, 2025]</h4>
    <li>
      <b>
          <a href="https://arxiv.org/abs/2502.09473"> Learning to Predict Global Atrial Fibrillation Dynamics from Sparse Measurements</a>  
      </b>
      <br> Presenter: <u>Alexander Jenkins</u> Imperial College London
      <a class="btn btn-info btn-xs" data-toggle="collapse" href="#25mar27bio" role="button" aria-expanded="false" aria-controls="collapseExample">
        Speaker Bio
      </a>
      <div class="collapse" id="25mar27bio">
        <div class="card card-body">
          <u>Alexander Jenkins</u>  is a PhD student at Imperial College London researching graph and time series signal processing with applications to cardiac fibrillation under the supervision of Professor Danilo Mandic and Dr. Fu Siong Ng. He obtained a master's degree in physics from the University of Manchester. Alexander is currently a visiting researcher in the Graph Machine Learning Group in Lugano, Switzerland, and is supported by a Hasler Foundation grant and the AI4Health Centre for Doctoral Training in London.
        </div>
      </div>
      <br> 
      <a href="https://youtu.be/amHOZnMm5LE"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a>
      <a href="https://arxiv.org/abs/2502.09473"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
      <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#25mar27" role="button" aria-expanded="false" aria-controls="collapseExample">
          Abstract
        </a>
    <div class="collapse" id="25mar27">
    <div class="card card-body">
      Catheter ablation of Atrial Fibrillation (AF) consists of a one-size-fits-all treatment with limited success in persistent AF. This may be due to our inability to map the dynamics of AF with the limited resolution and coverage provided by sequential contact mapping catheters, preventing effective patient phenotyping for personalised, targeted ablation. Here we introduce FibMap, a graph recurrent neural network model that reconstructs global AF dynamics from sparse measurements. Trained and validated on 51 non-contact whole atria recordings, FibMap reconstructs whole atria dynamics from 10% surface coverage, achieving a 210% lower mean absolute error and an order of magnitude higher performance in tracking phase singularities compared to baseline methods. Clinical utility of FibMap is demonstrated on real-world contact mapping recordings, achieving reconstruction fidelity comparable to non-contact mapping. FibMap's state-spaces and patient-specific parameters offer insights for electrophenotyping AF. Integrating FibMap into clinical practice could enable personalised AF care and improve outcomes.
    </div>
  </li>

    <h4>[April 3rd, 2025] [canelled, to be scheduled]</h4>
      <li>
        <b>
            <a href="https://arxiv.org/pdf/2408.00872"> Online Detection of Anomalies in Temporal Knowledge Graphs with Interpretability </a> (Proceedings of the ACM on Management of Data) 
        </b>
        <br> Presenter: <u>Jiasheng Zhang</u> School of Computer Science and Engineering, University of Electronic Science and
        Technology of China, China
        <a class="btn btn-info btn-xs" data-toggle="collapse" href="#25apr3bio" role="button" aria-expanded="false" aria-controls="collapseExample">
          Speaker Bio
        </a>
        <div class="collapse" id="25apr3bio">
          <div class="card card-body">
            TBD
          </div>
        </div>
        <br> 
        <a href="https://arxiv.org/pdf/2408.00872"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
        <a href="https://github.com/zjs123/ANoT"><img src="https://img.shields.io/badge/Github-link-lightgrey"></a>
        <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#25apr3" role="button" aria-expanded="false" aria-controls="collapseExample">
            Abstract
          </a>
      <div class="collapse" id="25apr3">
      <div class="card card-body">
        Temporal knowledge graphs (TKGs) are valuable resources for capturing evolving relationships among entities, yet they are often plagued by noise, necessitating robust anomaly detection mechanisms. Existing dynamic graph anomaly detection approaches struggle to capture the rich semantics introduced by node and edge categories within TKGs, while TKG embedding methods lack interpretability, undermining the credibility of anomaly detection. Moreover, these methods falter in adapting to pattern changes and semantic drifts resulting from knowledge updates. To tackle these challenges, we introduce AnoT, an efficient TKG summarization method tailored for interpretable online anomaly detection in TKGs. AnoT begins by summarizing a TKG into a novel rule graph, enabling flexible inference of complex patterns in TKGs. When new knowledge emerges, AnoT maps it onto a node in the rule graph and traverses the rule graph recursively to derive the anomaly score of the knowledge. The traversal yields reachable nodes that furnish interpretable evidence for the validity or the anomalous of the new knowledge. Overall, AnoT embodies a detector-updater-monitor architecture, encompassing a detector for offline TKG summarization and online scoring, an updater for real-time rule graph updates based on emerging knowledge, and a monitor for estimating the approximation error of the rule graph. Experimental results on four real-world datasets demonstrate that AnoT surpasses existing methods significantly in terms of accuracy and interoperability. All of the raw datasets and the implementation of AnoT are provided
      </div>
    </li>

    <h4>[April 10th, 2025]</h4>
      <li>
        <b>
            <a href="https://arxiv.org/pdf/2504.04934"> Boosting Relational Deep Learning with Pretrained Tabular Models</a>
        </b>
        <br> Presenter: <u>Veronica Lachi </u> Mobile and Social Computing Lab at Bruno Kessler Foundation
        <a class="btn btn-info btn-xs" data-toggle="collapse" href="#25apr10bio" role="button" aria-expanded="false" aria-controls="collapseExample">
          Speaker Bio
        </a>
        <div class="collapse" id="25apr10bio">
          <div class="card card-body">
            <u>Veronica Lachi </u>is a researcher in the Mobile and Social Computing Lab at Bruno Kessler Foundation in Trento. Her research interests focus on the theoretical properties of Graph Neural Networks, particularly their expressiveness, hierarchical pooling, and temporal GNNs. She obtained a PhD in Artificial Intelligence from the University of Siena under the supervision of Prof. Monica Bianchini. During her PhD, she was a Visiting Researcher at UiT The Arctic University of Tromsø. 
          </div>
        </div>
        <br> 
        <a href="https://youtu.be/DS_0-7XIc5s"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a>
        <a href="https://arxiv.org/pdf/2504.04934"><img src="https://img.shields.io/badge/Paper-link-important"></a>  
        <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#25apr10" role="button" aria-expanded="false" aria-controls="collapseExample">
            Abstract
          </a>
      <div class="collapse" id="25apr10">
      <div class="card card-body">
        Relational databases, organized into tables connected by primary-foreign key relationships, are a common format for organizing data. Making predictions on relational data often involves transforming them into a flat tabular format through table joins and feature engineering, which serve as inputs to tabular methods. However, designing features that fully capture complex relational patterns remains challenging. Graph Neural Networks (GNNs) offer a compelling alternative by inherently modeling these relationships, but their time overhead during inference limits their applicability for real-time scenarios. In this work, we aim to bridge this gap by leveraging existing feature engineering efforts to enhance the efficiency of GNNs in relational databases. Specifically, we use GNNs to capture complex relationships within relational databases—patterns that are difficult to featurize, while employing engineered features to encode temporal information, avoiding the need to retain the entire historical graph and enabling the use of smaller, more efficient graphs. Our LIGHTRDL approach not only enhances efficiency but also outperforms existing models. Experimental results on the RelBench benchmark demonstrate that our framework achieves up to 33% performance improvement and a 526× inference speedup compared to GNNs, making it highly suitable for real-time inference
      </div>
    </li>

    <h4>[April 17th, 2025]</h4>
    <li>
      <b>
        <a href="https://openreview.net/forum?id=tj5xJInWty"> Temporal Heterogeneous Graph Generation with Privacy, Utility, and Efficiency</a>
      </b> (ICLR 2025 Spotlight)
      <br> Presenter: <u>Xinyu He</u> University of Illinois Urbana-Champaign
      <a class="btn btn-info btn-xs" data-toggle="collapse" href="#25apr17bio" role="button" aria-expanded="false" aria-controls="collapseExample">
        Speaker Bio
      </a>
      <div class="collapse" id="25apr17bio">
        <div class="card card-body">
          <u>Xinyu He</u> is a PhD student at University of Illinois at Urbana-Champaign, advised by Prof. Hanghang Tong in the IDEA-ISAIL joint lab. She earned her bachelor's degree in Tsinghua University. Her research generally focuses on data mining and machine learning, especially graph mining. Her research interest includes different aspects of Trustworthy ML and recommender systems, with a current interest of intersection of the two areas. Her research also extends to complex graph modeling and large language model in recommender systems.
        </div>
      </div>
      <br> 
      <a href="https://openreview.net/forum?id=tj5xJInWty"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
      <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#25apr17" role="button" aria-expanded="false" aria-controls="collapseExample">
          Abstract
        </a>
    <div class="collapse" id="25apr17">
    <div class="card card-body">
      Nowadays, temporal heterogeneous graphs attract much research and industrial attention for building the next-generation Relational Deep Learning models and applications, due to their informative structures and features. While providing timely and precise services like personalized recommendations and question answering, this rich information also introduces extra exposure risk for each node in the graph. The distinctive local topology, the abundant heterogeneous features, and the time dimension of the graph data are more prone to expose sensitive information and narrow down the scope of victim candidates, which calls for well-defined protection techniques on graphs. To this end, we propose a Temporal Heterogeneous Graph Generator balancing Privacy, Utility, and Efficiency, named THePUff. More specifically, we first propose a differential privacy algorithm to perturb the input temporal heterogeneous graph for protecting privacy, and then utilize both the perturbed graph and the original one in a generative adversarial setting for THePUff to learn and generate privacy-guaranteed and utility-preserved graph data in an efficient manner. We further propose 6 new metrics in the temporal setting to measure heterogeneous graph utility and privacy. Finally, based on temporal heterogeneous graph datasets with up to 1 million nodes and 20 million edges, the experiments show that THePUff generates utilizable temporal heterogeneous graphs with privacy protected, compared with state-of-the-art baselines.
    </div>
  </li>

  <h4>[April 24th, 2025]</h4>
  <li>
    <b>
      <a href="https://openreview.net/forum?id=8e2LirwiJT"> TGB-Seq Benchmark: Challenging Temporal GNNs with Complex Sequential Dynamics</a>
    </b> (ICLR 2025)
    <br> Presenter: <u>Lu Yi</u> ALGO Lab, Renmin University of China
    <a class="btn btn-info btn-xs" data-toggle="collapse" href="#25apr24bio" role="button" aria-expanded="false" aria-controls="collapseExample">
      Speaker Bio
    </a>
    <div class="collapse" id="25apr24bio">
      <div class="card card-body">
        <u>Lu Yi</u> is a Ph.D. candidate at the ALGO Lab, Renmin University of China, supervised by Prof. Zhewei wei. She received her B.Sc. degree in Computer Science and Technology at Beijing University of Posts and Telecommunications in 2022. Her research insterests include dynamic graph learning, graph unlearning, and efficient graph algorithms
      </div>
    </div>
    <br> 
    <a href="https://openreview.net/forum?id=8e2LirwiJT"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
    <a href="https://arxiv.org/abs/2408.09212"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
    <a href="https://tgb-seq.github.io/"><img src="https://img.shields.io/badge/website-blue"></a>
    <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#25apr24" role="button" aria-expanded="false" aria-controls="collapseExample">
        Abstract
      </a>
  <div class="collapse" id="25apr24">
  <div class="card card-body">
    Lu Yi will present her recent ICLR2025 accepted paper, "TGB-Seq Benchmark: Challenging Temporal GNNs with Complex Sequential Dynamics". Below is the abstract of the paper:
  Future link prediction is a fundamental challenge in various real-world dynamic systems. To address this, numerous temporal graph neural networks (temporal GNNs) and benchmark datasets have been developed. However, these datasets often feature excessive repeated edges and lack complex sequential dynamics, a key characteristic inherent in many real-world applications such as recommender systems and "Who-To-Follow" on social networks. This oversight has led existing methods to inadvertently downplay the importance of learning sequential dynamics, focusing primarily on predicting repeated edges.
  In this study, we demonstrate that existing methods, such as GraphMixer and DyGFormer, are inherently incapable of learning simple sequential dynamics, such as "a user who has followed OpenAI and Anthropic is more likely to follow AI at Meta next." Motivated by this issue, we introduce the Temporal Graph Benchmark with Sequential Dynamics (TGB-Seq), a new benchmark carefully curated to minimize repeated edges, challenging models to learn sequential dynamics and generalize to unseen edges. TGB-Seq comprises large real-world datasets spanning diverse domains, including e-commerce interactions, movie ratings, business reviews, social networks, citation networks and web link networks. Benchmarking experiments reveal that current methods usually suffer significant performance degradation and incur substantial training costs on TGB-Seq, posing new challenges and opportunities for future research.
    </div>
  </li>

  <h4>[May 1st, 2025]</h4>
    <li>
      <b>
        <a href="https://www.sciencedirect.com/science/article/abs/pii/S0022000021000428?via%3Dihub"> Spanners in Temporal Graphs</a>
      </b> 
      <br> Presenter: <u>Jason Schoeters</u> 
      <a class="btn btn-info btn-xs" data-toggle="collapse" href="#25may1bio" role="button" aria-expanded="false" aria-controls="collapseExample">
        Speaker Bio
      </a>
      <div class="collapse" id="25may1bio">
        <div class="card card-body">
          <u>Jason Schoeters</u> is a Postdoctoral Research Fellow at the University of Florence and the DISIA lab. His main research interests lie in temporal graph theory, specifically concerning classical and parameterized algorithms and complexity. 
        </div>
      </div>
      <br> 
      <a href="https://www.sciencedirect.com/science/article/abs/pii/S0022000021000428?via%3Dihub"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
      <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#25may1" role="button" aria-expanded="false" aria-controls="collapseExample">
          Abstract
        </a>
    <div class="collapse" id="25may1">
    <div class="card card-body">
      In this talk, I'll first give an introduction to the study of temporal spanners, which are subsets of edges maintaining connectivity over time in temporal graphs. These fundamental structures admit many differences from spanning structures in static graphs (think spanning trees), and many theoretical questions have remained open over the last decades despite significant effort.  
      I'll then present a recent work of ours on enumerating temporal spanners, accepted at the 4th Symposium on Algorithmic Foundations of Dynamic Networks (SAND) 2025. Finally, I want to discuss an idea of how to tackle a long-standing open question of mine [ICALP 2019] with learning techniques, and get some feedback on this idea.
      This talk is based on some of my research over the last years, with Arnaud Casteigts, Esteban Christiann, Kazuhiro Kurita, Andrea Marino, Joseph G. Peters, Eric Sanlaville, and Takeaki Uno.
    </div>
  </li>





        </div>
      </div>
    </section>


<section id="fall2024" class="some-section">
  <div class="container">
    <div class="row">
      <div class="col-sm-2"></div>
      <div class="col-sm-8">
        <div class="listing" style="clear:both;">
        <div class="left">
      
        <h3 style="text-align:center">Past Talks, Fall 2024</h3>

        <h4>[September 19th, 2024]</h4>
          <li>
            <b>
                <a href="https://arxiv.org/abs/2406.04897"> From Link Prediction to Forecasting: Information Loss in Batch-based Temporal Graph Learning </a> 
            </b>
            <br> Presenter: <u>Moritz Lampert</u> Julius-Maximilians-Universiät Würzburg, DE
            <a class="btn btn-info btn-xs" data-toggle="collapse" href="#24sept19bio" role="button" aria-expanded="false" aria-controls="collapseExample">
              Speaker Bio
            </a>
            <div class="collapse" id="24sept19bio">
              <div class="card card-body">
                <u>Moritz Lampert</u> is a PhD student at the Chair of Machine Learning for Complex Networks, Center for Artificial Intelligence and Data Science (CAIDAS), Julius-Maximilians-Universität Würzburg, under the supervision of Prof. Ingo Scholtes. His research interests include different aspects of graph representation learning with a current focus on temporal graphs and applications in single-cell biology. Prior to his PhD studies, he completed his master's degree at the same institution.
              </div>
            </div>
            <br> 
            <a href="https://arxiv.org/abs/2406.04897"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
            <a href="https://youtu.be/-vlnL_1dkWE"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a>
            <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#24sept19" role="button" aria-expanded="false" aria-controls="collapseExample">
                Abstract
              </a>
          <div class="collapse" id="24sept19">
          <div class="card card-body">
            Dynamic link prediction is an important problem considered by many recent works proposing various approaches for learning temporal edge patterns. To assess their efficacy, models are evaluated on publicly available benchmark datasets involving continuous-time and discrete-time temporal graphs. However, as we show in this work, the suitability of common batch-oriented evaluation depends on the datasets' characteristics, which can cause two issues: First, for continuous-time temporal graphs, fixed-size batches create time windows with different durations, resulting in an inconsistent dynamic link prediction task. Second, for discrete-time temporal graphs, the sequence of batches can additionally introduce temporal dependencies that are not present in the data. In this work, we empirically show that this common evaluation approach leads to skewed model performance and hinders the fair comparison of methods. We mitigate this problem by reformulating dynamic link prediction as a link forecasting task that better accounts for temporal information present in the data. We provide implementations of our new evaluation method for commonly used graph learning frameworks.
          </div>
        </li>


        <h4>[September 26th, 2024]</h4>
        <li>
          <b>
              <a href="https://arxiv.org/abs/2310.15978"> Graph Deep Learning for Time Series Forecasting  </a> 
          </b>
          <br> Presenter: <u>Andrea Cini</u> The Swiss AI Lab IDSIA USI-SUPSI & Universit`a della Svizzera italiana, Switzerland.
          <a class="btn btn-info btn-xs" data-toggle="collapse" href="#24sept26bio" role="button" aria-expanded="false" aria-controls="collapseExample">
            Speaker Bio
          </a>
          <div class="collapse" id="24sept26bio">
            <div class="card card-body">
              <u>Andrea Cini</u> is a postdoctoral researcher at the Graph Machine Learning Group and IDSIA, at USI. He obtained his PhD from USI under the supervision of Prof. Cesare Alippi, with a thesis on graph deep learning methods for time series forecasting. Previously, he was a visiting researcher at Imperial College London and earned his MSc and BSc at Politecnico di Milano. His research focuses on relational time series processing;  in particular, he introduced methods for forecasting, data reconstruction, and probabilistic graph learning. His work has been published in leading machine learning venues, including JMLR, NeurIPS, ICML, and ICLR, where he frequently serves as a reviewer. He is one of the creators of the Torch Spatiotemporal library.
            </div>
          </div>
          <br>
          <a href="https://youtu.be/VXyGd8JiYjs"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a> 
          <a href="https://arxiv.org/abs/2310.15978"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
          <a href="https://andreacini.github.io/"><img src="https://img.shields.io/badge/website-blue"></a>
          <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#24sept26" role="button" aria-expanded="false" aria-controls="collapseExample">
              Abstract
            </a>
        <div class="collapse" id="24sept26">
        <div class="card card-body">
          Graph-based deep learning methods have become popular tools to process collections
          of correlated time series. Differently from traditional multivariate forecasting methods,
          neural graph-based predictors take advantage of pairwise relationships by conditioning
          forecasts on a (possibly dynamic) graph spanning the time series collection. The
          conditioning can take the form of an architectural inductive bias on the neural forecasting
          architecture, resulting in a family of deep learning models called spatiotemporal graph
          neural networks. Such relational inductive biases enable the training of global forecasting
          models on large time-series collections, while at the same time localizing predictions
          w.r.t. each element in the set (i.e., graph nodes) by accounting for local correlations
          among them (i.e., graph edges). Indeed, recent theoretical and practical advances in
          graph neural networks and deep learning for time series forecasting make the adoption
          of such processing frameworks appealing and timely. However, most of the studies in
          the literature focus on proposing variations of existing neural architectures by taking
          advantage of modern deep learning practices, while foundational and methodological
          aspects have not been subject to systematic investigations. To fill the gap, this paper aims
          to introduce a comprehensive methodological framework that formalizes the forecasting
          problem and provides design principles for graph-based predictive models and methods
          to assess their performance. At the same time, together with an overview of the field, we
          provide design guidelines, recommendations, and best practices, as well as an in-depth
          discussion of open challenges and future research directions.
        </div>
      </li>

      <h4>[October 3rd, 2024]</h4>
      <li>
        <b>
            <a href="https://www.arxiv.org/abs/2408.10700"> AnyGraph: Graph Foundation Model in the Wild </a> 
        </b>
        <br> Presenter: <u>Lianghao Xia</u> The University of Hong Kong
        <a class="btn btn-info btn-xs" data-toggle="collapse" href="#24oct3bio" role="button" aria-expanded="false" aria-controls="collapseExample">
          Speaker Bio
        </a>
        <div class="collapse" id="24oct3bio">
          <div class="card card-body">
            <u>Dr. Xia Lianghao</u> is currently a postdoctoral researcher at the Data Intelligence Laboratory of the University of Hong Kong, collaborating with Professor Huang Chao. Lianghao's research mainly focuses on the field of data science, with particular attention to foundational models, graph learning, information retrieval, and spatio-temporal modeling. He has published 14 first-author papers in top conferences in related fields. His work has received multiple awards, including the Most Influential Paper Award at WWW'2023, SIGIR'2023, 2022, as well as the Best Paper Nomination and Spotlight Paper Award at the WWW'2023. In addition, he was selected by Stanford University as the world's top 2% scientists in 2024.
          </div>
        </div>
        <br> 
        <a href="https://youtu.be/8VEbhSV6sjM"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a> 
        <a href="https://www.arxiv.org/abs/2408.10700"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
        <a href="https://github.com/HKUDS/AnyGraph"><img src="https://img.shields.io/badge/Github-link-lightgrey"></a>
        <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#24oct3" role="button" aria-expanded="false" aria-controls="collapseExample">
            Abstract
          </a>
      <div class="collapse" id="24oct3">
      <div class="card card-body">
        The growing ubiquity of relational data structured as graphs has underscored the need for graph learning models with exceptional generalization capabilities. However, current approaches often struggle
        to effectively extract generalizable insights, frequently requiring extensive fine-tuning and limiting their versatility. Graph foundation
        models offer a transformative solution, with the potential to learn
        robust, generalizable representations from graph data. This enables
        more effective and adaptable applications across a wide spectrum
        of tasks and domains. In this work, we investigate a unified graph
        model, AnyGraph, designed to handle key challenges: i) Structure
        Heterogenity. Addressing distribution shift in graph structural
        information; ii) Feature Heterogenity. Handling diverse feature
        representation spaces across graph datasets; iii) Fast Adaptation.
        Efficiently adapting the model to new graph domains; iv) Scaling
        Law Emergence. Enabling the model to exhibit scaling law behavior, where its performance scales favorably with the amount
        of data and parameter sizes. To tackle these critical challenges, we
        build the AnyGraph upon a Graph Mixture-of-Experts (MoE) architecture. This approach empowers the model to effectively manage
        both the in-domain and cross-domain distribution shift concerning structure-level and feature-level heterogeneity. Furthermore, a
        lightweight graph expert routing mechanism is proposed to facilitate AnyGraph’s fast adaptability to new data and domains. Our
        extensive experiments on diverse 38 graph datasets have demonstrated the strong zero-shot learning performance of AnyGraph
        across diverse graph domains with significant distribution shift.
        Furthermore, we have validated the model’s fast adaptation ability
        and scaling law emergence, showcasing its versatility.
      </div>
    </li>


    <h4>[October 10th, 2024]</h4>
        <li>
          <b>
              <a href="https://arxiv.org/pdf/2406.12072"> DTGB: A Comprehensive Benchmark for Dynamic Text-Attributed Graphs </a> 
          </b>
          <br> Presenter: <u>Jiasheng Zhang</u> University of Electronic Science and Technology of China
          <a class="btn btn-info btn-xs" data-toggle="collapse" href="#24oct10bio" role="button" aria-expanded="false" aria-controls="collapseExample">
            Speaker Bio
          </a>
          <div class="collapse" id="24oct10bio">
            <div class="card card-body">
              <u>Jiasheng Zhang</u> is a Ph.D. student in the Department of Computer Science at the University of Electronic Science and Technology of China (UESTC), specializing in temporal knowledge graphs and dynamic graph learning. He is currently visiting Yale University, where he is working with Rex Ying on using large language models for temporal graphs and temporal knowledge reasoning. He is recognized as Rising Star in Scientific Research by UESTC.
            </div>
          </div>
          <br> 
          <a href="https://youtu.be/Kg6xeuEBMsE"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a> 
          <a href="https://arxiv.org/pdf/2406.12072"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
          <a href="https://github.com/zjs123/DTGB"><img src="https://img.shields.io/badge/Github-link-lightgrey"></a>
          <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#24oct10" role="button" aria-expanded="false" aria-controls="collapseExample">
              Abstract
            </a>
        <div class="collapse" id="24oct10">
        <div class="card card-body">
          Dynamic text-attributed graphs (DyTAGs) are prevalent in various real-world scenarios, where each node and edge are associated with text descriptions, and both the graph structure and text descriptions evolve over time. Despite their broad applicability, there is a notable scarcity of benchmark datasets tailored to DyTAGs, which hinders the potential advancement in many research fields. To address this gap, we introduce Dynamic Text-attributed Graph Benchmark (DTGB), a collection of large-scale, time-evolving graphs from diverse domains, with nodes and edges enriched by dynamically changing text attributes and categories. To facilitate the use of DTGB, we design standardized evaluation procedures based
          on four real-world use cases: future link prediction, destination node retrieval, edge classification, and textual relation generation. These tasks require models to understand both dynamic graph structures and natural language, highlighting the
          unique challenges posed by DyTAGs. Moreover, we conduct extensive benchmark experiments on DTGB, evaluating 7 popular dynamic graph learning algorithms and their variants of adapting to text attributes with LLM embeddings, along with
          6 powerful large language models (LLMs). Our results show the limitations of
          existing models in handling DyTAGs. Our analysis also demonstrates the utility of
          DTGB in investigating the incorporation of structural and textual dynamics. The
          proposed DTGB fosters research on DyTAGs and their broad applications. It offers
          a comprehensive benchmark for evaluating and advancing models to handle the
          interplay between dynamic graph structures and natural language. The dataset and
          source code are available at https://github.com/zjs123/DTGB.
        </div>
      </li>

      <h4>[October 17th, 2024]</h4>
        <li>
          <b>
              <a href="https://dl.acm.org/doi/pdf/10.1145/3637528.3671831"> Unifying Evolution, Explanation, and Discernment: A Generative Approach for Dynamic Graph Counterfactuals (KDD 2024) </a> 
          </b>
          <br> Presenter: <u>Bardh Prenkaj</u> Technical University of Munich
          <a class="btn btn-info btn-xs" data-toggle="collapse" href="#24oct17bio" role="button" aria-expanded="false" aria-controls="collapseExample">
            Speaker Bio
          </a>
          <div class="collapse" id="24oct17bio">
            <div class="card card-body">
              Dr. <u>Bardh Prenkaj</u> is a postdoc in AI at the Technical University of Munich trying to understand What Makes us (or not) Human and What Actually is Machine Intelligence with Gjergji Kasneci. From 10/2022 to 10/2024, he was a postdoc at the Sapienza University of Rome in Anomaly Detection and Explainability. He received his PhD in Computer Science in 2022 and his MSc in 2018. In Rome, he worked in the AIIM - formerly IIM - group advised by Paola Velardi and Giovanni Stilo. He then worked as a senior researcher at the CS Department in Sapienza in anomaly detection for social isolation disorders. He made BetterScholar with Antonio Norelli, an alternative to Google Scholar profiles. 
            </div>
          </div>
          <br> 
          <a href="https://youtu.be/LZ47oqbfYJU"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a> 
          <a href="https://dl.acm.org/doi/pdf/10.1145/3637528.3671831"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
          <a href="https://github.com/bardhprenkaj/HANSEL"><img src="https://img.shields.io/badge/Github-link-lightgrey"></a>
          <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#24oct17" role="button" aria-expanded="false" aria-controls="collapseExample">
              Abstract
            </a>
        <div class="collapse" id="24oct17">
        <div class="card card-body">
          We present GRACIE (Graph Recalibration and Adaptive Counterfactual Inspection and Explanation), a novel approach for generative classification and counterfactual explanations of dynamically changing graph data. We study graph classification problems through the lens of generative classifiers. We propose a dynamic, self-supervised latent variable model that updates by identifying plausible counterfactuals for input graphs and recalibrating decision boundaries through contrastive optimization. Unlike prior work, we do not rely on linear separability between the learned graph representations to find plausible counterfactuals. Moreover, GRACIE eliminates the need for stochastic sampling in latent spaces and graph-matching heuristics. Our work distills the implicit link between generative classification and loss functions in the latent space, a key insight to understanding recent successes with this architecture. We further observe the inherent trade-off between validity and pulling explainee instances towards the central region of the latent space, empirically demonstrating our theoretical findings. In extensive experiments on synthetic and real-world graph data, we attain considerable improvements, reaching ∼99% validity when sampling sets of counterfactuals even in the challenging setting of dynamic data landscapes.
        </div>
      </li>
      

      <h4>[October 24th, 2024]</h4>
        <li>
          <b>
              <a href="https://openreview.net/forum?id=gVg8V9isul"> Long Range Propagation on Continuous-Time Dynamic Graphs (ICML 2024) </a> 
          </b>
          <br> Presenter: <u>Alessio Gravina</u> Department of Computer Science, University of Pisa
          <a class="btn btn-info btn-xs" data-toggle="collapse" href="#24oct24bio" role="button" aria-expanded="false" aria-controls="collapseExample">
            Speaker Bio
          </a>
          <div class="collapse" id="24oct24bio">
            <div class="card card-body">
              <u>Alessio Gravina</u> is a postdoctoral researcher at the University of Pisa, Italy. He received his Ph.D. from the University of Pisa in 2024 with a thesis on graph deep learning methods inspired by dynamical systems and neural differential equations. He holds MSc (2020) and BSc (2018) degrees in computer science from University of Pisa, Italy. He has been a visiting researcher at Huawei Research Center, Munich in 2023, at Swiss AI Lab IDSIA in 2022, and at Stanford University in 2019, while he won the Fujitsu AI-NLP Challenge in 2018. Alessio's interests are in the area of deep learning and machine learning for graphs, with a special focus on differential equation-based graph neural networks.
            </div>
          </div>
          <br> 
          <a href="https://youtu.be/z3sgrpVInz0?si=50jvpnotIHVLcZbC"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a> 
          <a href="https://openreview.net/pdf?id=gVg8V9isul"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
          <a href="https://github.com/gravins/non-dissipative-propagation-CTDGs"><img src="https://img.shields.io/badge/Github-link-lightgrey"></a>
          <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#24oct24" role="button" aria-expanded="false" aria-controls="collapseExample">
              Abstract
            </a>
        <div class="collapse" id="24oct24">
        <div class="card card-body">
          Learning Continuous-Time Dynamic Graphs (C-TDGs) requires accurately modeling spatio-temporal information on streams of irregularly sampled events. While many methods have been proposed recently, we find that most message passing-, recurrent- or self-attention-based methods perform poorly on long-range tasks. These tasks require correlating information that occurred "far" away from the current event, either spatially (higher-order node information) or along the time dimension (events occurred in the past). To address long-range dependencies, we introduce Continuous-Time Graph Anti-Symmetric Network (CTAN). Grounded within the ordinary differential equations framework, our method is designed for efficient propagation of information. In this paper, we show how CTAN's (i) long-range modeling capabilities are substantiated by theoretical findings and how (ii) its empirical performance on synthetic long-range benchmarks and real-world benchmarks is superior to other methods. Our results motivate CTAN's ability to propagate long-range information in C-TDGs as well as the inclusion of long-range tasks as part of temporal graph models evaluation.
        </div>
      </li>

      <h4>[November 7th, 2024]</h4>
        <li>
          <b>
              <a href="https://dl.acm.org/doi/pdf/10.1145/3637528.3671825"> Making Temporal Betweenness Computation Faster and Restless (KDD 2024) </a> 
          </b>
          <br> Presenter: <u>Filippo Brunelli</u> European Commission — JRC
          <a class="btn btn-info btn-xs" data-toggle="collapse" href="#24nov7bio" role="button" aria-expanded="false" aria-controls="collapseExample">
            Speaker Bio
          </a>
          <div class="collapse" id="24nov7bio">
            <div class="card card-body">
              <u>Filippo Brunelli</u> is a scientific officer at the Joint Research Centre of the European Commission. His current work revolves around quantitative and qualitative analysis of multimodal transport networks to support European transport policies aiming at enhancing accessibility and reducing externalities. He obtained his PhD degree from Inria, while being hosted at IRIF (Paris), under the supervision of Laurent Viennot and Pierluigi Crescenzi. The focus of the thesis was on temporal graphs, specifically exploring models and algorithms with potential uses in transport networks, where efficient routing algorithms are crucial. Previously, he obtained a bachelor's and master's degree in mathematics, respectively, at the University of Trento and the University of Pisa (Italy).
            </div>
          </div>
          <br> 
          <a href="https://youtu.be/jH0m-gjJ72c?si=6C2RvOLj3O6J-iVR"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a> 
          <a href="https://dl.acm.org/doi/pdf/10.1145/3637528.3671825"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
          <a href="https://github.com/piluc/TWBC"><img src="https://img.shields.io/badge/Github-link-lightgrey"></a>
          <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#24nov7" role="button" aria-expanded="false" aria-controls="collapseExample">
              Abstract
            </a>
        <div class="collapse" id="24nov7">
        <div class="card card-body">
          Buß et al [KDD 2020] recently proved that the problem of computing the betweenness of all nodes of a temporal graph is computationally hard in the case of foremost and fastest paths, while it is solvable in time 𝑂 (𝑛^3 𝑇^2) in the case of shortest and shortest cforemost paths, where 𝑛 is the number of nodes and 𝑇 is the number of distinct time steps. A new algorithm for temporal betweenness computation is introduced in this paper. In the case of shortest and shortest foremost paths, it requires 𝑂 (𝑛 +𝑀) space and runs in time 𝑂 (𝑛𝑀) = 𝑂 (𝑛^3𝑇 ), where 𝑀 is the number of temporal edges, thus significantly improving the algorithm of Buß et al in terms of time complexity (note that 𝑇 is usually large). Experimental evidence is provided that our algorithm performs between twice and almost 250 times better than the algorithm of Buß et al. Moreover, we were able to compute the exact temporal betweenness values of several large temporal graphs with over a million of temporal edges. For such size, only approximate computation was possible by usingthe algorithm of Santoro and Sarpe [WWW 2022]. Maybe more importantly, our algorithm extends to the case of restless walks (that is, walks with waiting constraints in each node), thus providing a polynomial-time algorithm (with complexity 𝑂 (𝑛𝑀)) for computing the temporal betweenness in the case of several different optimality criteria. Such restless computation was known only for the shortest criterion (Rymar et al [JGAA 2023]), with complexity 𝑂 (𝑛^2𝑀𝑇^2). We performed an extensive experimental validation by comparing different waiting constraints and different optimisation criteria. Moreover, as a case study, we investigate six public transit networks including Berlin, Rome, and Paris. Overall we find a general consistency between the different variants of betweenness centrality. However, we do measure a sensible influence of waiting constraints, and note some cases of low correlation for certain pairs of criteria in some networks
        </div>
      </li>
      
      <h4>[November 14th, 2024]</h4>
        <li>
          <b>
              <a href="https://arxiv.org/abs/2406.09639"> TGB 2.0: A Benchmark for Learning on Temporal Knowledge Graphs and Heterogeneous Graphs (NeurIPS 2024 Datasets and Benchmarks Track) </a> 
          </b>
          <br> Presenter: <u>Julia Gastinger</u> Mannheim University and <u>Shenyang Huang</u> McGill University, Mila
          <a class="btn btn-info btn-xs" data-toggle="collapse" href="#24nov14bio" role="button" aria-expanded="false" aria-controls="collapseExample">
            Speaker Bio
          </a>
          <div class="collapse" id="24nov14bio">
            <div class="card card-body">
              <u>Julia Gastinger</u> (she/her) is a Ph.D. student at Mannheim University, supervised by Professor Heiner Stuckenschmidt. Previously, she was a Research Scientist in the AI Innovations group at NEC Laboratories Europe. Her research primarily focuses on graph-based Machine Learning – she is interested in how to incorporate the time aspect in knowledge graph representations.
              She served as a Reviewing Chair and Co-Organizer in Temporal Graph Learning Workshop @ NeurIPS 2023.
              <br>
              <u>Shenyang Huang</u> (he/him) is a PhD student at McGill University and Mila, focusing on temporal graph learning (supervised by Prof. Reihaneh Rabbany and Prof. Guillaume Rabusseau). 
                  He is interested in representation learning on temporal graphs, anomaly detection and graph representation learning. He was the Organization Chair for the Temporal Graph Learning Workshop @ NeurIPS 2022.
                  His previous research includes change point detection on temporal graphs, COVID-19 disease modeling with temporal contact graphs and link prediction on temporal graphs. He also enjoys writing <a href="https://medium.com/@shenyanghuang1996">medium blog posts</a> about temporal graph learning. 
            </div>
          </div>
          <br> 
          <a href="https://youtu.be/w35ilttAhws"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a> 
          <a href="https://drive.google.com/file/d/1UeLTKDep3mlCI23qlf48MwPD-jzxZpKo/view?usp=sharing"> <img src="https://img.shields.io/badge/Talk%20-Slides-blue"></a>
          <a href="https://arxiv.org/pdf/2406.09639"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
          <a href="https://tgb.complexdatalab.com/"><img src="https://img.shields.io/badge/website-blue"></a>
          <a href="https://github.com/shenyangHuang/TGB"><img src="https://img.shields.io/badge/Github-link-lightgrey"></a>
          <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#24nov14" role="button" aria-expanded="false" aria-controls="collapseExample">
              Abstract
            </a>
        <div class="collapse" id="24nov14">
        <div class="card card-body">
          Multi-relational temporal graphs are powerful tools for modeling real-world data,
          capturing the evolving and interconnected nature of entities over time. Recently,
          many novel models are proposed for ML on such graphs intensifying the need for
          robust evaluation and standardized benchmark datasets. However, the availability of such resources remains scarce and evaluation faces added complexity due
          to reproducibility issues in experimental protocols. To address these challenges,
          we introduce Temporal Graph Benchmark 2.0 (TGB 2.0), a novel benchmarking
          framework tailored for evaluating methods for predicting future links on Temporal Knowledge Graphs and Temporal Heterogeneous Graphs with a focus on
          large-scale datasets, extending the Temporal Graph Benchmark. TGB 2.0 facilitates comprehensive evaluations by presenting eight novel datasets spanning five
          domains with up to 53 million edges. TGB 2.0 datasets are significantly larger
          than existing datasets in terms of number of nodes, edges, or timestamps. In
          addition, TGB 2.0 provides a reproducible and realistic evaluation pipeline for
          multi-relational temporal graphs. Through extensive experimentation, we observe
          that 1) leveraging edge-type information is crucial to obtain high performance,
          2) simple heuristic baselines are often competitive with more complex methods,
          3) most methods fail to run on our largest datasets, highlighting the need for
          research on more scalable methods.
        </div>
      </li>



      <h4>[November 21st, 2024]</h4>
        <li>
          <b>
              <a href="https://arxiv.org/pdf/2407.20060"> RELBENCH: A Benchmark for Deep Learning on Relational Databases (NeurIPS 2024 Datasets and Benchmarks Track) </a> 
          </b>
          <br> Presenter: <u>Rishabh Ranjan</u> Stanford University
          <a class="btn btn-info btn-xs" data-toggle="collapse" href="#24nov21bio" role="button" aria-expanded="false" aria-controls="collapseExample">
            Speaker Bio
          </a>
          <div class="collapse" id="24nov21bio">
            <div class="card card-body">
              <u>Rishabh</u> is a second year PhD student at Stanford University. He is advised by Prof. Jure Leskovec and also works with Prof. Carlos Guestrin.  He completed his undergrad in Computer Science and Engineering at IIT Delhi, where he was the President’s Gold Medalist for the class of 2022 and also received the Suresh Chandra Memorial Trust Award for the best undergrad thesis in CS. Prior to the PhD, he spent a year at Carnegie Mellon University as a visiting research scholar hosted by Prof. Zachary Lipton. His interests lie at the intersection of relational deep learning and foundation models, with the research goal of extending the success of foundation models like LLMs to structured data such as tables, time series and relational databases. Website: https://rishabh-ranjan.github.io
            </div>
          </div>
          <br> 

          <a href="https://youtu.be/2idUm4OBX7Y"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a> 
          <a href="https://arxiv.org/pdf/2407.20060"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
          <a href="https://proceedings.mlr.press/v235/fey24a.html"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
          <a href="https://github.com/snap-stanford/relbench"><img src="https://img.shields.io/badge/Github-link-lightgrey"></a>
          <a href="https://relbench.stanford.edu/"><img src="https://img.shields.io/badge/website-blue"></a>
          <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#24nov21" role="button" aria-expanded="false" aria-controls="collapseExample">
              Abstract
            </a>
        <div class="collapse" id="24nov21">
        <div class="card card-body">
          Much of the world's most valued data is stored in relational databases and data warehouses, where the data is organized into many tables connected by primary-foreign key relations. However, building machine learning models using this data is both challenging and time consuming. The core problem is that no machine learning method is capable of learning on multiple tables interconnected by primary-foreign key relations. Current methods can only learn from a single table, so the data must first be manually joined and aggregated into a single training table, the process known as feature engineering. Feature engineering is slow, error prone and leads to suboptimal models. Here we introduce an end-to-end deep representation learning approach to directly learn on data laid out across multiple tables. We name our approach Relational Deep Learning (RDL). The core idea is to view relational databases as a temporal, heterogeneous graph, with a node for each row in each table, and edges specified by primary-foreign key links. Message Passing Graph Neural Networks can then automatically learn across the graph to extract representations that leverage all input data, without any manual feature engineering. Relational Deep Learning leads to more accurate models that can be built much faster. To facilitate research in this area, we develop RelBench, a set of benchmark datasets and an implementation of Relational Deep Learning. The data covers a wide spectrum, from discussions on Stack Exchange to book reviews on the Amazon Product Catalog. Overall, we define a new research area that generalizes graph machine learning and broadens its applicability to a wide set of AI use cases.
        </div>
      </li>

      <h4>[November 28th, 2024]</h4>
      <li>
        <b>
            <a href="https://arxiv.org/pdf/2408.09918"> Expressive Power of Temporal Message Passing </a> 
        </b>
        <br> Presenter: <u>Przemysław Andrzej Wałega</u> University of Oxford, Queen Mary University of London, UK
        <a class="btn btn-info btn-xs" data-toggle="collapse" href="#24nov28bio" role="button" aria-expanded="false" aria-controls="collapseExample">
          Speaker Bio
        </a>
        <div class="collapse" id="24nov28bio">
          <div class="card card-body">
          <u>Przemysław Andrzej Wałega</u> is an Associate Professor (Senior Lecturer) in Queen Mary University of London, Centre for Fundamental Computer Science and Senior Researcher in University of Oxford, Department of Computer Science. He received PhD in Logics in the Institute of Philosophy at the University of Warsaw, BEng and MS degrees in Mechatronics from Warsaw University of Technology, and BS degree in Philosophy at the Institute of Philosophy, University of Warsaw
          He is especially interested in methods for complex reasoning about time. His research is devoted to the temporal formalism DatalogMTL whereas his PhD thesis is about interval temporal logics and on an interplay between their computational complexity and expressive power. Most recently, He is interested in characterising expressive power of temporal graph neural networks with logical languages and explain models' predictions with extracted logical rules.
          </div>
        </div>
        <br> 

        <a href="https://youtu.be/Jb6GgR-ZbFI"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a> 
        <a href="https://arxiv.org/pdf/2408.09918"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
        <a href="https://www.seresearch.qmul.ac.uk/cfcs/people/pwalega/"><img src="https://img.shields.io/badge/website-blue"></a>
        <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#24nov28" role="button" aria-expanded="false" aria-controls="collapseExample">
            Abstract
          </a>
      <div class="collapse" id="24nov28">
      <div class="card card-body">
        Graph neural networks (GNNs) have recently been adapted to
        temporal settings, often employing temporal versions of the
        message-passing mechanism known from GNNs. We divide
        temporal message passing mechanisms from literature into
        two main types: global and local, and establish WeisfeilerLeman characterisations for both. This allows us to formally
        analyse expressive power of temporal message-passing models. We show that global and local temporal message-passing
        mechanisms have incomparable expressive power when applied to arbitrary temporal graphs. However, the local mechanism is strictly more expressive than the global mechanism
        when applied to colour-persistent temporal graphs, whose
        node colours are initially the same in all time points. Our
        theoretical findings are supported by experimental evidence,
        underlining practical implications of our analysis.
      </div>
    </li>




      </div>
    </div>
  </section>





<section id="winter2024" class="some-section">
  <div class="container">
    <div class="row">
      <div class="col-sm-2"></div>
      <div class="col-sm-8">
        <div class="listing" style="clear:both;">
        <div class="left">

        <h3 style="text-align:center">Past Talks, Winter 2024</h3>

        <h4>[January 18th, 2024]</h4>
          <li>
            <b>
                <a href="https://arxiv.org/abs/2306.06155"> Intensity Profile Projection: A Framework for Continuous-Time Representation Learning for Dynamic Networks </a> NeurIPS 2023
            </b>
            <br> Presenter: <u>Alexander Modell</u> Imperial College London and <a href="https://people.maths.bris.ac.uk/~pr12244/"><u>Patrick Rubin-Delanchy</u></a> University of Bristol
            <a class="btn btn-info btn-xs" data-toggle="collapse" href="#24jan18bio" role="button" aria-expanded="false" aria-controls="collapseExample">
              Speaker Bio
            </a>
            <div class="collapse" id="24jan18bio">
              <div class="card card-body">
                <u>Patrick Rubin-Delanchy</u> obtained his PhD in Statistics at Imperial College London in 2008, supervised by Prof. Andrew Walden. He was awarded a Heilbronn research fellowship in Data Science in 2012, which he first held at the University of Bristol and then at the University of Oxford. I became assistant professor of Statistics at the University of Bristol in July 2017, and was promoted to full professor in July 2022. As of Jan 2024, He is the chair of Statistical Learning at the University of Edinburgh. His research interests include data exploration, graph embedding and unsupervised learning.
                <br>
                <u>Alex Modell</u> is research associate in Statistics at Imperial College London. His research is in statistical modelling and large-scale inference for high-dimensional and graph structured data, with a particular interest in unsupervised learning with temporal data. He is currently funded by the EPSRC grant “Network Time Series and Stochastic Processes”.
              </div>
            </div>
            <br> 
            <a href="https://youtu.be/jVbD4U_vWgo"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a>
            <a href="https://arxiv.org/abs/2306.06155"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
            <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#jan18" role="button" aria-expanded="false" aria-controls="collapseExample">
                Abstract
              </a>
          <div class="collapse" id="jan18">
          <div class="card card-body">
            We present a new representation learning framework, Intensity Profile Projection, for continuous-time dynamic network data. Given triples (i,j,t), each representing a time-stamped (t) interaction between two entities (i,j), our procedure returns a continuous-time trajectory for each node, representing its behaviour over time. The framework consists of three stages: estimating pairwise intensity functions, e.g. via kernel smoothing; learning a projection which minimises a notion of intensity reconstruction error; and constructing evolving node representations via the learned projection. The trajectories satisfy two properties, known as structural and temporal coherence, which we see as fundamental for reliable inference. Moreoever, we develop estimation theory providing tight control on the error of any estimated trajectory, indicating that the representations could even be used in quite noise-sensitive follow-on analyses. The theory also elucidates the role of smoothing as a bias-variance trade-off, and shows how we can reduce the level of smoothing as the signal-to-noise ratio increases on account of the algorithm `borrowing strength' across the network.
          </div>
        </li>

        <h4>[January 25th, 2024]</h4>
        <li>
          <b>
              <a href="https://dl.acm.org/doi/10.1145/3581784.3607056"> DistTGL: Distributed Memory-Based Temporal Graph Neural Network Training </a> SC 2023
          </b>
          <br> Presenter: <u>Hongkuan Zhou</u> University of Southern California
          <a class="btn btn-info btn-xs" data-toggle="collapse" href="#24jan25bio" role="button" aria-expanded="false" aria-controls="collapseExample">
            Speaker Bio
          </a>
          <div class="collapse" id="24jan25bio">
            <div class="card card-body">
              <u>Hongkuan Zhou</u> is a Ph.D. student at Ming Hsieh Department of Electrical and Computer Engineering at University of Southern California. His research interest lies in the acceleration and application of GNNs and Temporal GNNs on general-purpose hardware. 
            </div>
          </div>
          <br> 
          <a href="https://youtu.be/e4ucpfrLtJE"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a>
          <a href="https://dl.acm.org/doi/10.1145/3581784.3607056"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
          <a href="https://github.com/amazon-science/disttgl"><img src="https://img.shields.io/badge/Github-link-lightgrey"></a>
          <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#jan25" role="button" aria-expanded="false" aria-controls="collapseExample">
              Abstract
            </a>
        <div class="collapse" id="jan25">
        <div class="card card-body">
          Memory-based Temporal Graph Neural Networks are powerful tools in dynamic graph representation learning and have demonstrated superior performance in many real-world applications. However, their node memory favors smaller batch sizes to capture more dependencies in graph events and needs to be maintained synchronously across all trainers. As a result, existing frameworks suffer from accuracy loss when scaling to multiple GPUs. Even worse, the tremendous overhead of synchronizing the node memory makes it impractical to deploy the solution in GPU clusters. In this work, we propose DistTGL --- an efficient and scalable solution to train memory-based TGNNs on distributed GPU clusters. DistTGL has three improvements over existing solutions: an enhanced TGNN model, a novel training algorithm, and an optimized system. In experiments, DistTGL achieves near-linear convergence speedup, outperforming the state-of-the-art single-machine method by 14.5% in accuracy and 10.17× in training throughput.
        </div>
      </li>
<!-- 
      <h4>[Feb 1st, 2024]</h4> **cancelled**
        <li>
          <b>
              <a href="https://arxiv.org/abs/2110.00506"> Temporal Graphs and Temporal Network Characteristics for Bio-Inspired Networks during Optimization </a>
          </b>
          <br> Presenter: <u>Abdel Isakovic</u> Colgate University
          <a class="btn btn-info btn-xs" data-toggle="collapse" href="#24feb1bio" role="button" aria-expanded="false" aria-controls="collapseExample">
            Speaker Bio
          </a>
          <div class="collapse" id="24feb1bio">
            <div class="card card-body">
              <u>Abdel F. Isakovic</u> is a visiting professor of physics at Colgate University. He was previously Assoc. Prof. of Physics and Interim Assoc. Dean for Research at Khalifa University, Abu Dhabi (UAE). Prof. Isakovic obtained PhD from University of Minnesota, and has been affiliated with Cornell University and Brookhaven National Laboratory. He works on computational and experimental problems in condensed matter and biophysics, and on education research projects.

            </div>
          </div>
          <br> 
          <a href="https://arxiv.org/abs/2110.00506"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
          <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#24feb1" role="button" aria-expanded="false" aria-controls="collapseExample">
              Abstract
            </a>
        <div class="collapse" id="24feb1">
        <div class="card card-body">
          Temporal network analysis and time evolution of network characteristics are powerful tools in describing the changing topology of dynamic networks. This paper uses such approaches to better visualize and provide analytical measures for the changes in performance that we observed in
            Voronoi-type spatial coverage, particularly for the example of time evolving networks with a changing number of wireless sensors being deployed. Specifically, our analysis focuses on the role different
            combinations of impenetrable obstacles and environmental noise play in connectivity and overall
            network structure. It is shown how the use of (i) temporal network graphs, and (ii) network centrality and regularity measures illustrate the differences between various options developed for the
            balancing act of energy and time efficiency in network coverage. Lastly, we compare the outcome
            of these measures with the less abstract classification variables, such as percent area covered, and
            cumulative distance travelled.
        </div>
      </li>
 -->

      <h4>[Feb 8th, 2024]</h4>
        <li>
          <b>
              <a href="https://arxiv.org/abs/2302.04071"> Taming Local Effects in Graph-based Spatiotemporal Forecasting</a> NeurIPS 2023
          </b> 
          <br> Presenter: <u>Ivan Marisca</u>, The Swiss AI Lab IDSIA USI-SUPSI, Università della Svizzera italiana
          <a class="btn btn-info btn-xs" data-toggle="collapse" href="#24feb8bio" role="button" aria-expanded="false" aria-controls="collapseExample">
            Speaker Bio
          </a>
          <div class="collapse" id="24feb8bio">
            <div class="card card-body">
              <a href="https://marshka.github.io/"><u>Ivan Marisca</u></a> is a Ph.D. student at the Swiss AI lab IDSIA and USI - Università della Svizzera italiana (CH), under the supervision of Prof. Cesare Alippi. He received his MSc (2020) degree in Computer Science and Engineering from Politecnico di Milano (IT). Ivan's research focuses on graph-based learning from irregular spatiotemporal data, with applications in prediction, imputation, and control on sensor networks. His work has been published in top-tier conferences of the field, such as NeurIPS, ICLR, and AAAI. In addition to his research, Ivan regularly works as a teaching assistant and holds lectures in machine learning courses for MSc students at USI. He is also a co-creator and maintainer of <a href="https://torch-spatiotemporal.readthedocs.io/en/latest/">Torch Spatiotemporal</a>.
            </div>
          </div>
          <br> 
          <a href="https://youtu.be/DMZ9ARAl_Bs"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a>
          <a href="https://arxiv.org/abs/2302.04071"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
          <a href="https://github.com/Graph-Machine-Learning-Group/taming-local-effects-stgnns"><img src="https://img.shields.io/badge/Github-link-lightgrey"></a>
          <a href="https://github.com/TorchSpatiotemporal/tsl"><img src="https://img.shields.io/badge/TSL-link-red"></a>          
          <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#24feb8" role="button" aria-expanded="false" aria-controls="collapseExample">
              Abstract
            </a>
        <div class="collapse" id="24feb8">
        <div class="card card-body">
          Spatiotemporal graph neural networks have shown to be effective in time series forecasting applications, achieving better performance than standard univariate predictors in several settings. These architectures take advantage of a graph structure and relational inductive biases to learn a single (global) inductive model to predict any number of the input time series, each associated with a graph node. Despite the gain achieved in computational and data efficiency w.r.t. fitting a set of local models, relying on a single global model can be a limitation whenever some of the time series are generated by a different spatiotemporal stochastic process. The main objective of this paper is to understand the interplay between globality and locality in graph-based spatiotemporal forecasting, while contextually proposing a methodological framework to rationalize the practice of including trainable node embeddings in such architectures. We ascribe to trainable node embeddings the role of amortizing the learning of specialized components. Moreover, embeddings allow for 1) effectively combining the advantages of shared message-passing layers with node-specific parameters and 2) efficiently transferring the learned model to new node sets. Supported by strong empirical evidence, we provide insights and guidelines for specializing graph-based models to the dynamics of each time series and show how this aspect plays a crucial role in obtaining accurate predictions.
        </div>
      </li>

      <h4>[Feb 22nd, 2024]</h4>
        <li>
          <b>
              <a href="https://arxiv.org/abs/2402.03651">Temporal Graph Analysis with TGX </a> WSDM 2024 Demo Track
          </b>
          <br> Presenter: <u>Shenyang Huang</u> McGill University, Mila
          <a class="btn btn-info btn-xs" data-toggle="collapse" href="#24feb22bio" role="button" aria-expanded="false" aria-controls="collapseExample">
            Speaker Bio
          </a>
          <div class="collapse" id="24feb22bio">
            <div class="card card-body">
              <u> Shenyang Huang </u> is a PhD student at McGill University and Mila, focusing on temporal graph learning (supervised by Prof. Reihaneh Rabbany and Prof. Guillaume Rabusseau). He is interested in representation learning on temporal graphs, anomaly detection and graph representation learning. He was the Organization Chair for the Temporal Graph Learning Workshop @ NeurIPS 2022. His previous research includes change point detection on temporal graphs, COVID-19 disease modeling with temporal contact graphs and link prediction on temporal graphs. He also enjoys writing medium blog posts about temporal graph learning.
            </div>
          </div>
          <br> 
          <a href="https://youtu.be/qTWj2nHjufo"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a>
          <a href="https://arxiv.org/abs/2402.03651"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
          <a href="https://github.com/ComplexData-MILA/TGX"><img src="https://img.shields.io/badge/Github-link-lightgrey"></a>
          <a href="https://pypi.org/project/py-tgx/"><img src="https://img.shields.io/pypi/v/py-tgx.svg?color=brightgreen"></a>
          <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#24feb22" role="button" aria-expanded="false" aria-controls="collapseExample">
              Abstract
            </a>
        <div class="collapse" id="24feb22">
        <div class="card card-body">
          Real-world networks, with their evolving relations, are best captured as temporal graphs. However, existing software libraries are largely designed for static graphs where the dynamic nature of temporal graphs is ignored. Bridging this gap, we introduce TGX, a Python package specially designed for analysis of temporal networks that encompasses an automated pipeline for data loading, data processing, and analysis of evolving graphs. TGX provides access to eleven built-in datasets and eight external Temporal Graph Benchmark (TGB) datasets as well as any novel datasets in the .csv format. Beyond data loading, TGX facilitates data processing functionalities such as discretization of temporal graphs and node subsampling to accelerate working with larger datasets. For comprehensive investigation, TGX offers network analysis by providing a diverse set of measures, including average node degree and the evolving number of nodes and edges per timestamp. Additionally, the package consolidates meaningful visualization plots indicating the evolution of temporal patterns, such as Temporal Edge Appearance (TEA) and Temporal Edge Trafficc (TET) plots. The TGX package is a robust tool for examining the features of temporal graphs and can be used in various areas like studying social networks, citation networks, and tracking user interactions. We plan to continuously support and update TGX based on community feedback. TGX is publicly available
        </div>
      </li>

      <h4>[Feb 29th, 2024]</h4>
        <li>
          <b>
              <a href="https://arxiv.org/abs/2302.01018">Graph Neural Networks for Temporal Graphs: State of the Art, Open Challenges, and Opportunities </a> TMLR
          </b>
          <br> Presenter: <u>Veronica Lachi</u> University of Siena, Siena, Italy
          <a class="btn btn-info btn-xs" data-toggle="collapse" href="#24feb29bio" role="button" aria-expanded="false" aria-controls="collapseExample">
            Speaker Bio
          </a>
          <div class="collapse" id="24feb29bio">
            <div class="card card-body">
              <u>Veronica Lachi</u> is a PhD candidate in Engineering and Information Sciences at the University of Siena. She received a master's degree cum laude in Applied Mathematics from the University of Siena. Her research interests are centered around geometric deep learning, specifically focusing on the theoretical properties of graph neural networks, pooling in graph neural networks, and graph neural networks for temporal graphs.
            </div>
          </div>
          <br> 
          <a href="https://arxiv.org/abs/2302.01018"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
          <a href="https://youtu.be/XqTbJBPT-DY"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a>
          <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#24feb29" role="button" aria-expanded="false" aria-controls="collapseExample">
              Abstract
            </a>
        <div class="collapse" id="24feb29">
        <div class="card card-body">
          Graph Neural Networks (GNNs) have become the leading paradigm for learning on (static) graph-structured data. However, many real-world systems are dynamic in nature, since the graph and node/edge attributes change over time. In recent years, GNN-based models for temporal graphs have emerged as a promising area of research to extend the capabilities of GNNs. In this work, we provide the first comprehensive overview of the current state-of-the-art of temporal GNN, introducing a rigorous formalization of learning settings and tasks and a novel taxonomy categorizing existing approaches in terms of how the temporal aspect is represented and processed. We conclude the survey with a discussion of the most relevant open challenges for the field, from both research and application perspectives.
        </div>
      </li>

      <h4>[March 7th, 2024]</h4>
        <li>
          <b>
              <a href="https://openreview.net/pdf?id=CAqdG2dy5s">Graph-based Virtual Sensing from Sparse and Partial Multivariate Observations
              </a> ICLR 2024
          </b>
          <br> Presenter: <u>Giovanni De Felice</u> University of Liverpool
          <a class="btn btn-info btn-xs" data-toggle="collapse" href="#24mar7bio" role="button" aria-expanded="false" aria-controls="collapseExample">
            Speaker Bio
          </a>
          <div class="collapse" id="24mar7bio">
            <div class="card card-body">
              <u>Giovanni De Felice</u> is a PhD student in the ‘Data Mining & Machine Learning group’ at the University of Liverpool and a visiting at Università della Svizzera Italiana (CH). His research focuses on time series and spatiotemporal analysis, with a particular focus on material weathering and performance prediction.
              Previously, he received his MSc (2020) degree cum laude in Particle Physics from the University of Pisa (IT), conducting his thesis within the Mu2e experiment at Fermilab (US).
            </div>
          </div>
          <br> 
          <a href="https://youtu.be/l_3bv5b3LbM"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a>
          <a href="https://openreview.net/pdf?id=CAqdG2dy5s"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
          <a href="https://arxiv.org/abs/2402.12598"><img src="https://img.shields.io/badge/arXiv-pdf-yellowgreen"></a>
          <a href="https://github.com/gdefe/ggnet-virtual-sensing"><img src="https://img.shields.io/badge/Github-link-lightgrey"></a>
          <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#24mar7" role="button" aria-expanded="false" aria-controls="collapseExample">
              Abstract
            </a>
        <div class="collapse" id="24mar7">
        <div class="card card-body">
          Virtual sensing techniques allow for inferring signals at new unmonitored locations by exploiting spatio-temporal measurements coming from physical sensors
          at different locations. However, as the sensor coverage becomes sparse due to
          costs or other constraints, physical proximity cannot be used to support interpolation. In this paper, we overcome this challenge by leveraging dependencies
          between the target variable and a set of correlated variables (covariates) that can
          frequently be associated with each location of interest. From this viewpoint, covariates provide partial observability, and the problem consists of inferring values
          for unobserved channels by exploiting observations at other locations to learn how
          such variables can correlate. We introduce a novel graph-based methodology to
          exploit such relationships and design a graph deep learning architecture, named
          GgNet, implementing the framework. The proposed approach relies on propagating information over a nested graph structure that is used to learn dependencies between variables as well as locations. GgNet is extensively evaluated under
          different virtual sensing scenarios, demonstrating higher reconstruction accuracy
          compared to the state-of-the-art.
        </div>
      </li>


      <h4>[March 21st, 2024]</h4>
        <li>
          <b>
              <a href="https://www.arxiv.org/abs/2402.06716">Dynamic Graph Information Bottleneck
              </a> WWW 2024 Research Track
          </b>
          <br> Presenter: <u>Haonan Yuan</u> Beihang University
          <a class="btn btn-info btn-xs" data-toggle="collapse" href="#24mar21bio" role="button" aria-expanded="false" aria-controls="collapseExample">
            Speaker Bio
          </a>
          <div class="collapse" id="24mar21bio">
            <div class="card card-body">
              <u>Haonan Yuan</u> is currently a Ph.D. candidate at the State Key Laboratory of Software Development Environment, 
              and Beijing Advanced Innovation Center for Big Data and Brain Computing at Beihang University, 
              supervised by Prof. Jianxin Li and Prof. Qingyun Sun. His research interests include generalizable graphs 
              representation learning, dynamic graph learning, and graph foundation model. His work has been published 
              in top-tier conferences of the field, such as NeurIPS, AAAI, WWW, and CIKM. He is the program committee member 
              of the Graph Foundation Model Workshop @ WWW 2024 in Singapore.
            </div>
          </div>
          <br> 
          <a href="https://youtu.be/CwWbxmOhOfE"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a>
          <a href="https://www.arxiv.org/abs/2402.06716"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
          <a href="https://github.com/RingBDStack/DGIB"><img src="https://img.shields.io/badge/Github-link-lightgrey"></a>          
          <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#24mar21" role="button" aria-expanded="false" aria-controls="collapseExample">
              Abstract
            </a>
        <div class="collapse" id="24mar21">
        <div class="card card-body">
          Dynamic Graphs widely exist in the real world, which carry complicated spatial and temporal feature patterns, challenging their representation learning. Dynamic Graph Neural Networks (DGNNs) have shown impressive predictive abilities by exploiting the intrinsic dynamics. However, DGNNs exhibit limited robustness, prone to adversarial attacks. This paper presents the novel Dynamic Graph Information Bottleneck (DGIB) framework to learn robust and discriminative representations. Leveraged by the Information Bottleneck (IB) principle, we first propose the expected optimal representations should satisfy the Minimal-Sufficient-Consensual (MSC) Condition. To compress redundant as well as conserve meritorious information into latent representation, DGIB iteratively directs and refines the structural and feature information flow passing through graph snapshots. To meet the MSC Condition, we decompose the overall IB objectives into DGIBMS and DGIBC, in which the DGIBMS channel aims to learn the minimal and sufficient representations, with the DGIBMS channel guarantees the predictive consensus. Extensive experiments on real-world and synthetic dynamic graph datasets demonstrate the superior robustness of DGIB against adversarial attacks compared with state-of-the-art baselines in the link prediction task. To the best of our knowledge, DGIB is the first work to learn robust representations of dynamic graphs grounded in the information-theoretic IB principle.
        </div>
      </li>

      <h4>[March 28th, 2024]</h4>
        <li>
          <b>
              <a href="https://openreview.net/attachment?id=88tGIxxhsf&name=pdf">Anomaly Detection in Continuous-Time Temporal Provenance Graphs
              </a> NeurIPS 2023 Temporal Graph Learning Workshop
          </b>
          <br> Presenter: <u>Jakub Reha</u> University of Amsterdam
          <a class="btn btn-info btn-xs" data-toggle="collapse" href="#24mar28bio" role="button" aria-expanded="false" aria-controls="collapseExample">
            Speaker Bio
          </a>
          <div class="collapse" id="24mar28bio">
            <div class="card card-body">
              <u>Jakub Reha</u> is a PhD candidate at AMLAB at the University of Amsterdam. 
              He holds a Bachelor's degree from the Technical University of Denmark and a Master’s degree from KTH Royal 
              Institute of Technology. His research interests are centred around anomaly detection in temporal graphs and 
              causality in machine learning, specifically causal discovery in time series.
            </div>
          </div>
          <br> 
          <a href="https://youtu.be/K2aDM9lMz0g"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a>
          <a href="https://openreview.net/attachment?id=88tGIxxhsf&name=pdf"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
          <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#24mar28" role="button" aria-expanded="false" aria-controls="collapseExample">
              Abstract
            </a>
        <div class="collapse" id="24mar28">
        <div class="card card-body">
          Recent advances in Graph Neural Networks (GNNs) have matured the field of
          learning on graphs, making GNNs essential for prediction tasks in complex, interconnected, and evolving systems. In this paper, we focus on self-supervised,
          inductive learning for continuous-time dynamic graphs. Without compromising
          generality, we propose an approach to learn representations and mine anomalies in
          provenance graphs, which are a form of large-scale, heterogeneous, attributed, and
          continuous-time dynamic graphs used in the cybersecurity domain, syntactically
          resembling complex temporal knowledge graphs. We modify the Temporal Graph
          Network (TGN) framework to heterogeneous input data and directed edges, refining
          it specifically for inductive learning on provenance graphs. We present and release
          two pioneering large-scale, continuous-time temporal, heterogeneous, attributed
          benchmark graph datasets. The datasets incorporate expert-labeled anomalies, promoting subsequent research on representation learning and anomaly detection on
          intricate real-world networks. Comprehensive experimental analyses of modules,
          datasets, and baselines underscore the effectiveness of TGN-based inductive learning, affirming its practical utility in identifying semantically significant anomalies
          in real-world systems.
        </div>
      </li>

      <h4>[April 4th, 2024]</h4>
        <li>
          <b>
              <a href="https://arxiv.org/pdf/2312.13680v2.pdf">HGE: Embedding Temporal Knowledge Graphs in a Product Space of Heterogeneous Geometric Subspace
              </a> AAAI 2024
          </b>
          <br> Presenter: <u>Jiaxin Pan</u> University of Stuttgart
          <a class="btn btn-info btn-xs" data-toggle="collapse" href="#24apr4bio" role="button" aria-expanded="false" aria-controls="collapseExample">
            Speaker Bio
          </a>
          <div class="collapse" id="24apr4bio">
            <div class="card card-body">
              <u>Jiaxin Pan</u> is a Ph.D. student at the University of Stuttgart, supervised by Prof. Steffen Staab. Her research interests are temporal knowledge graphs and termporal query answering.
            </div>
          </div>
          <br> 
          <a href="https://youtu.be/S7TIifWRqBQ"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a>
          <a href="https://arxiv.org/pdf/2312.13680v2.pdf"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
          <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#24apr4" role="button" aria-expanded="false" aria-controls="collapseExample">
              Abstract
            </a>
        <div class="collapse" id="24apr4">
        <div class="card card-body">
          Temporal knowledge graphs represent temporal facts
          (s, p, o, τ ) relating a subject s and an object o via a relation
          label p at time τ , where τ could be a time point or time interval. Temporal knowledge graphs may exhibit static temporal patterns at distinct points in time and dynamic temporal patterns between different timestamps. In order to learn
          a rich set of static and dynamic temporal patterns and apply them for inference, several embedding approaches have
          been suggested in the literature. However, as most of them
          resort to single underlying embedding spaces, their capability to model all kinds of temporal patterns was severely limited by having to adhere to the geometric property of their
          one embedding space. We lift this limitation by an embedding approach that maps temporal facts into a product space
          of several heterogeneous geometric subspaces with distinct
          geometric properties, i.e. Complex, Dual, and Split-complex
          spaces. In addition, we propose a temporal-geometric attention mechanism to integrate information from different geometric subspaces conveniently according to the captured relational and temporal information. Experimental results on
          standard temporal benchmark datasets favorably evaluate our
          approach against state-of-the-art models
        </div>
      </li>


      <h4>[April 11th, 2024]</h4>
        <li>
          <b>
              <a href="https://arxiv.org/abs/2305.10738v2">Deep Temporal Graph Clustering
              </a> ICLR 2024
          </b>
          <br> Presenter: <u>Meng Liu</u> and <u>Ke Liang</u> National University of Defense Technology, Changsha, China
          <a class="btn btn-info btn-xs" data-toggle="collapse" href="#24apr11bio" role="button" aria-expanded="false" aria-controls="collapseExample">
            Speaker Bio
          </a>
          <div class="collapse" id="24apr11bio">
            <div class="card card-body">
              <u>Meng Liu</u> is a Ph.D. candidate at National University of Defense Technology. His research interests include Temporal Graph Learning, Deep Clustering, and Knowledge Graph. He has published 7 papers as first author including ICLR, SIGIR, ACM MM, and CIKM, which have received 200+ citations. He received awards such as Best Student Paper of CCHI 2023, China National Scholarships (Twice), Excellent Master Thesis, etc. He also serves as reviewer for TKDE, TOIS, TNNLS, TOMM, and NeurIPS, ICML, ICLR, KDD, etc.
              <br>
              <u>Ke Liang</u> is currently pursuing a Ph.D. degree at the National University of Defense Technology (NUDT). Before that, he got BSc degree from Beihang University and MSc degree from Penn State University. His research interests include graph learning and knowledge graphs. He has published papers and serve as reviewers in several top-level journal/conferences, e.g., IEEE T-KDE, IEEE T-NNLS, ICML, AAAI, SIGIR and etc. The github repo (https://github.com/LIANGKE23/Awesome-Knowledge-Graph-Reasoning) he hosts earns more than 900 stars
            </div>
          </div>
          <br> 
          <a href="https://youtu.be/f7vqnZ5uAes"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a>
          <a href="https://arxiv.org/abs/2305.10738v2"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
          <a href="https://github.com/MGitHubL/Deep-Temporal-Graph-Clustering"><img src="https://img.shields.io/badge/Github-link-lightgrey"></a>
          <a href="https://github.com/MGitHubL/Data4TGC"><img src="https://img.shields.io/badge/datasets-green"></a>
          <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#24apr11" role="button" aria-expanded="false" aria-controls="collapseExample">
              Abstract
            </a>
        <div class="collapse" id="24apr11">
        <div class="card card-body">
          Deep graph clustering has recently received significant attention due to its ability
          to enhance the representation learning capabilities of models in unsupervised
          scenarios. Nevertheless, deep clustering for temporal graphs, which could capture
          crucial dynamic interaction information, has not been fully explored. It means
          that in many clustering-oriented real-world scenarios, temporal graphs can only be
          processed as static graphs. This not only causes the loss of dynamic information
          but also triggers huge computational consumption. To solve the problem, we
          propose a general framework for deep Temporal Graph Clustering called TGC,
          which introduces deep clustering techniques to suit the interaction sequence-based
          batch-processing pattern of temporal graphs. In addition, we discuss differences
          between temporal graph clustering and static graph clustering from several levels.
          To verify the superiority of the proposed framework TGC, we conduct extensive
          experiments. The experimental results show that temporal graph clustering enables
          more flexibility in finding a balance between time and space requirements, and our
          framework can effectively improve the performance of existing temporal graph
          learning methods. The code is released: https://github.com/MGitHubL/
          Deep-Temporal-Graph-Clustering.
        </div>
      </li>


      <h4>[April 18th, 2024]</h4>
        <li>
          <b>
              <a href="https://openreview.net/forum?id=DZqic2sPTY">GraphPulse: Topological representations for temporal graph property prediction
              </a> ICLR 2024
          </b>
          <br> Presenter: <u>Kiarash Shamsi</u> Department of computer science, University of Manitoba
          <a class="btn btn-info btn-xs" data-toggle="collapse" href="#24apr18bio" role="button" aria-expanded="false" aria-controls="collapseExample">
            Speaker Bio
          </a>
          <div class="collapse" id="24apr18bio">
            <div class="card card-body">
              <u>Kiarash Shamsi</u> is a Ph.D. student at the University of Manitoba, under the supervision of Dr. Cuneyt Akcora. He has published as a first author in conferences such as NeurIPS, ICLR, and ICBC. His research interests are temporal graph learning, graph neural networks, topological data analysis, and blockchain data analysis and systems.
            </div>
          </div>
          <br> 
          <a href="https://youtu.be/vZ0oQZIKSNA"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a>
          <a href="https://openreview.net/forum?id=DZqic2sPTY"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
          <a href="https://github.com/kiarashamsi/GraphPulse"><img src="https://img.shields.io/badge/Github-link-lightgrey"></a>
          <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#24apr18" role="button" aria-expanded="false" aria-controls="collapseExample">
              Abstract
            </a>
        <div class="collapse" id="24apr18">
        <div class="card card-body">
          Many real-world networks evolve over time, and predicting the evolution of such
          networks remains a challenging task. Graph Neural Networks (GNNs) have
          shown empirical success for learning on static graphs, but they lack the ability to effectively learn from nodes and edges with different timestamps. Consequently, the prediction of future properties in temporal graphs remains a relatively under-explored area. In this paper, we aim to bridge this gap by introducing a principled framework, named GraphPulse. The framework combines
          two important techniques for the analysis of temporal graphs within a Newtonian framework. First, we employ the Mapper method, a key tool in topological
          data analysis, to extract essential clustering information from graph nodes. Next,
          we harness the sequential modeling capabilities of Recurrent Neural Networks
          (RNNs) for temporal reasoning regarding the graph’s evolution. Through extensive experimentation, we demonstrate that our model enhances the ROC-AUC
          metric by 10.2% in comparison to the top-performing state-of-the-art method
          across various temporal networks. We provide the implementation of GraphPulse
          at <a href="https://github.com/kiarashamsi/GraphPulse">https://github.com/kiarashamsi/GraphPulse</a>.
        </div>
      </li>

      <h4>[April 25th, 2024]</h4>
        <li>
          <b>
              <a href="https://arxiv.org/abs/2312.13068">Continuous-time Graph Representation with Sequential Survival Process
              </a> AAAI 2024
          </b>
          <br> Presenter: <u>Abdulkadir Celikkanat</u> Department of Applied Mathematics and Computer Science, Technical University of Denmark
          <a class="btn btn-info btn-xs" data-toggle="collapse" href="#24apr25bio" role="button" aria-expanded="false" aria-controls="collapseExample">
            Speaker Bio
          </a>
          <div class="collapse" id="24apr25bio">
            <div class="card card-body">
              <u>Abdulkadir Celikkanat</u> recently started working as an assistant professor at Aalborg University, and he was previously a postdoctoral researcher at the Technical University of Denmark. He obtained his Ph.D. degree at CentraleSupelec, University of Paris-Saclay, where he worked on representation learning methods for graph-structured data. Before that, he earned his BSc in Mathematics and an MSc in Computer Engineering from Bogazici University. Currently, he is interested in the metagenomics binning problem and working on integrating heterogeneous environmental factors with bacterial genome data.
            </div>
          </div>
          <br> 
          <a href="https://youtu.be/yx5cwzygxa8"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a>
          <a href="https://arxiv.org/abs/2312.13068"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
          <a href="https://abdcelikkanat.github.io/projects/grassp/ "><img src="https://img.shields.io/badge/website-blue"></a>
          <a href="https://github.com/abdcelikkanat/grassp "><img src="https://img.shields.io/badge/Github-link-lightgrey"></a>
          <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#24apr25" role="button" aria-expanded="false" aria-controls="collapseExample">
              Abstract
            </a>
        <div class="collapse" id="24apr25">
        <div class="card card-body">
          Over the past two decades, there has been a tremendous increase in the growth of representation learning methods for
          graphs, with numerous applications across various fields, including bioinformatics, chemistry, and the social sciences.
          However, current dynamic network approaches focus on
          discrete-time networks or treat links in continuous-time networks as instantaneous events. Therefore, these approaches
          have limitations in capturing the persistence or absence of
          links that continuously emerge and disappear over time for
          particular durations. To address this, we propose a novel
          stochastic process relying on survival functions to model the
          durations of links and their absences over time. This forms
          a generic new likelihood specification explicitly accounting
          for intermittent edge-persistent networks, namely GRAS2P:
          Graph Representation with Sequential Survival Process. We
          apply the developed framework to a recent continuous time
          dynamic latent distance model characterizing network dynamics in terms of a sequence of piecewise linear movements of nodes in latent space. We quantitatively assess the
          developed framework in various downstream tasks, such as
          link prediction and network completion, demonstrating that
          the developed modeling framework accounting for link persistence and absence well tracks the intrinsic trajectories of
          nodes in a latent space and captures the underlying characteristics of evolving network structure.</a>.
        </div>
      </li>

      <h4>[May 2nd, 2024]</h4>
        <li>
          <b>
              <a href="https://arxiv.org/abs/2311.10112">zrLLM: Zero-Shot Relational Learning on Temporal Knowledge Graphs with Large Language Models
              </a> NAACL 2024
          </b>
          <br> Presenter: <u>Zifeng Ding</u> Database System and Data Mining group at Ludwig Maximilian University of Munich (LMU Munich)
          <a class="btn btn-info btn-xs" data-toggle="collapse" href="#24may2bio" role="button" aria-expanded="false" aria-controls="collapseExample">
            Speaker Bio
          </a>
          <div class="collapse" id="24may2bio">
            <div class="card card-body">
              <u>Zifeng Ding</u> is now a Computer Science PhD student in the group of Database System and Data Mining at Ludwig Maximilian University of Munich (LMU Munich), supervised by Prof. Volker Tresp. He is a nominated PhD of European Laboratory for Learning and Intelligent Systems (ELLIS), co-supervised by Prof. Michael Bronstein at University of Oxford. He is also a researcher at Siemens AG.
            </div>
          </div>
          <br> 
          <a href="https://youtu.be/buUeOQLtzBc"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a>
          <a href="https://arxiv.org/abs/2311.10112"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
          <a href="https://drive.google.com/file/d/1Ju8Iu-2H6itZz1aXTgCr3bt9Q1opBWOl/view?usp=sharing"> <img src="https://img.shields.io/badge/Talk%20-Slides-blue"></a>
          <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#24may2" role="button" aria-expanded="false" aria-controls="collapseExample">
              Abstract
            </a>
        <div class="collapse" id="24may2">
        <div class="card card-body">
          Modeling evolving knowledge over temporal knowledge graphs (TKGs) has become a heated topic. 
          Various methods have been proposed to forecast links on TKGs. Most of them are embedding-based, 
          where hidden representations are learned to represent knowledge graph (KG) entities and relations 
          based on the observed graph contexts. Although these methods show strong performance on traditional 
          TKG forecasting (TKGF) benchmarks, they face a strong challenge in modeling the unseen zero-shot relations 
          that have no prior graph context. In this paper, we try to mitigate this problem as follows. We first input 
          the text descriptions of KG relations into large language models (LLMs) for generating relation representations, 
          and then introduce them into embedding-based TKGF methods. LLM-empowered representations can capture the semantic 
          information in the relation descriptions. This makes the relations, whether seen or unseen, with similar semantic 
          meanings stay close in the embedding space, enabling TKGF models to recognize zero-shot relations even without any 
          observed graph context. Experimental results show that our approach helps TKGF models to achieve much better performance 
          in forecasting the facts with previously unseen relations, while still maintaining their ability in link forecasting 
          regarding seen relations. 
        </div>
      </li>


      <h4>[May 9th, 2024]</h4>
        <li>
          <b>
            <a href="https://link.springer.com/article/10.1007/s10618-021-00803-2">The role of Egocentric Perspective in Temporal Networks</a>
          </b>
          <br> Presenter: <u>Antonio Longa</u> University of Trento
          <a class="btn btn-info btn-xs" data-toggle="collapse" href="#24may9bio" role="button" aria-expanded="false" aria-controls="collapseExample">
            Speaker Bio
          </a>
          <div class="collapse" id="24may9bio">
            <div class="card card-body">
              <u>Antonio Longa</u> is an Assistant Professor (RTD-A) at the University of Trento, actively engaged in research within the Structured Machine Learning (SML) Group led by Andrea Passerini. He earned PhD with honours from the University of Trento and Fondazione Bruno Kessler, under the mentorship of Bruno Lepri. He is currently deeply engaged in research, which spans the realms of Temporal Graph Neural Networks (TGNNs) and the vital domain of GNN explainability. His work involves unravelling the dynamics of temporal networks while also enhancing the interpretability of GNNs. These parallel endeavors allow to explore the temporal dimension in machine learning while ensuring that the inner workings of GNNs are transparent and understandable.
            </div>
          </div>
          <br> 
          <a href="https://youtu.be/331aLqDiVDE"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a>
          <a href="https://link.springer.com/article/10.1007/s10618-021-00803-2"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
          <a href="https://www.nature.com/articles/s42005-023-01517-1"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
          <!-- <a href="https://arxiv.org/abs/2311.10112"><img src="https://img.shields.io/badge/Paper-link-important"></a>  -->
          <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#24may9" role="button" aria-expanded="false" aria-controls="collapseExample">
              Abstract
            </a>
        <div class="collapse" id="24may9">
        <div class="card card-body">
          Temporal networks play a crucial role in modeling and understanding time-dependent systems, spanning from social interactions to biological processes. Over time, network science has developed numerous measures for analyzing and comparing temporal networks. Some of these methods involve breaking down the network into smaller interaction segments, focusing on a limited number of nodes over a short time span. Along this line, one approach is to adopt an egocentric perspective, considering the temporal evolution of each node's neighborhood. In this talk, we introduce techniques based on the egocentric viewpoint, specifically focusing on the concept of Egocentric Temporal Neighborhoods (ETNs). Furthermore, we demonstrate how this concept can be extended to include labeled nodes (LETNs) and higher-order interactions (HETNs). Finally, we illustrate how these structures can be utilized to generate surrogate temporal networks (ETN-gen).
        </div>
      </li>


      <h4>[May 16th, 2024]</h4>
        <li>
          <b>
            <a href="https://arxiv.org/abs/2404.16726">History repeats Itself: A Baseline for Temporal Knowledge Graph Forecasting</a> IJCAI 2024
          </b>
          <br> Presenter: <u>Julia Gastinger</u> NEC Laboratories Europe, Mannheim University
          <a class="btn btn-info btn-xs" data-toggle="collapse" href="#24may16bio" role="button" aria-expanded="false" aria-controls="collapseExample">
            Speaker Bio
          </a>
          <div class="collapse" id="24may16bio">
            <div class="card card-body">
              <u>Julia Gastinger</u> (she/her) is a research scientist at NEC Laboratories Europe and a Ph.D. student at Mannheim University, supervised by Professor Heiner Stuckenschmidt. Currently she is doing a research internship at Mila. Her research primarily focuses on graph-based Machine Learning – she is interested in how to incorporate the time aspect in knowledge graph representations. Prior to joining NEC Laboratories Europe, Julia graduated with a master’s degree from Stuttgart University, where she studied Engineering Cybernetics with a focus on Autonomous Systems and Control Theory. 
            </div>
          </div>
          <br> 
          <a href="https://youtu.be/2TmG9383I5c"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a>
          <a href="https://arxiv.org/abs/2404.16726"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
          <a href="https://github.com/nec-research/recurrency_baseline_tkg"><img src="https://img.shields.io/badge/Github-link-lightgrey"></a>
          <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#24may16" role="button" aria-expanded="false" aria-controls="collapseExample">
              Abstract
            </a>
        <div class="collapse" id="24may16">
        <div class="card card-body">
          Temporal Knowledge Graph (TKG) Forecasting aims at predicting links in Knowledge Graphs for future timesteps based on a history of Knowledge Graphs. To this day, standardized evaluation protocols and rigorous comparison across TKG models are available, but the importance of simple baselines is often neglected in the evaluation, which prevents researchers from discerning actual and fictitious progress. We propose to close this gap by designing an intuitive baseline for TKG Forecasting based on predicting recurring facts. Compared to most TKG models, it requires little hyperparameter tuning and no iterative training. Further, it can help to identify failure modes in existing approaches. The empirical findings are quite unexpected: compared to 11 methods on five datasets, our baseline ranks first or third in three of them, painting a radically different picture of the predictive quality of the state of the art.
        </div>
      </li>


      <h4>[May 30th, 2024]</h4>
        <li>
          <b>
              <a href="https://charithmendis.com/assets/pdf/asplos24-tglite.pdf">TGLite: A Lightweight Programming Framework for
                Continuous-Time Temporal Graph Neural Networks
              </a> ASPLOS'24
          </b>
          <br> Presenter:  <u>Wanyu Zhao</u>, <u>Charith Mendis</u> and <u>Yufeng Wang</u> University of Illinois at Urbana-Champaign, USA
          <a class="btn btn-info btn-xs" data-toggle="collapse" href="#24may30bio" role="button" aria-expanded="false" aria-controls="collapseExample">
            Speaker Bio
          </a>
          <div class="collapse" id="24may30bio">
            <div class="card card-body">
              <u>Charith Mendis</u> is an Assistant Professor at the University of Illinois at Urbana-Champaign. Previously, he was a visiting faculty researcher at Google and was instrumental in designing and developing the learned TPU cost model used in production. His research interests are in automating compiler construction and in building high-performance ML systems. He received his Ph.D. and Master from the Massachusetts Institute of Technology and his B.Sc. from the University of Moratuwa. He recently co-led the DARPA ISAT study on "ML Optimized Compilers for Heterogeneous Architectures (MOCHA)". He is the recipient of an NSF CAREER Award, an IEEE Micro Top Picks honorable mention, the William A. Martin outstanding master's thesis award at MIT, a best student paper award, a best paper award, and the university gold medal for his B.Sc. He has published work at both top programming languages venues such as PLDI and ASPLOS as well as at top machine learning venues such as ICML and NeurIPS.
            <br>
             <u>Wanyu Zhao</u> is a first-year Ph.D. student in Computer Science at the University of Illinois Urbana-Champaign (UIUC), under the supervision of Professor Charith Mendis. Their current research focuses on developing efficient and scalable systems for temporal graph learning. With a strong interest in the intersection of systems and machine learning, Wanyu aims to explore novel techniques in constructing efficient AI systems through algorithmic insights and comprehensive systems understanding.
            <br>
              <u>Yufeng Wang</u> (first author of TGLite and TGOpt) received his M.S. in Computer Science from the University of Illinois at Urbana-Champaign, where he was advised by Professor Charith Mendis. His research is focused on Temporal Graph Neural Networks, particularly on optimizing their performance and ease of implementation, with his work being published at the PPoPP and ASPLOS conferences. He graduated in 2023 with the David J. Kuck Outstanding Master’s Thesis Award. Yufeng is currently a Software Engineer at Tesla, working on deep learning compilers.
            </div>
          </div>
          <br> 
          <a href="https://youtu.be/871k93Kolrg"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a>
          <a href="https://charithmendis.com/assets/pdf/asplos24-tglite.pdf"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
          <a href="https://charithmendis.com/assets/pdf/ppopp23-tgopt.pdf"><img src="https://img.shields.io/badge/Paper-link-important"></a>
          <a href="https://github.com/ADAPT-uiuc/tglite"><img src="https://img.shields.io/badge/Github-link-lightgrey"></a>
          <a href="https://tglite.readthedocs.io/en/latest"><img src="https://img.shields.io/badge/website-blue"></a>
          <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#24may30" role="button" aria-expanded="false" aria-controls="collapseExample">
              Abstract
            </a>
        <div class="collapse" id="24may30">
        <div class="card card-body">
          In recent years, Temporal Graph Neural Networks (TGNNs) have achieved great success in 
          learning tasks for graphs that change over time. Moreover, larger and more complicated 
          temporal graphs are introduced frequently, requiring additional compute and memory resources. 
          To facilitate these demands as well as to increase the productivity of machine learning researchers, 
          we need a high-performance programming framework with user-friendly abstractions. In this talk, we present TGLite, 
          a light-weight framework for programming TGNNs that can simultaneously achieve both goals: ease of programmability 
          and high performance. TGLite is built on top of PyTorch and seamlessly integrates with it and for the first time exposes 
          a rich set of primitive operators to program TGNNs. Further, it provides an array of in-built optimizations such as 
          deduplication, memoization, pre-computation and preloading to enable high-performance TGNN implementations. We show 
          how these optimizations accelerate TGNN training and inference by more than 3x and 4x compared to the TGL framework. 
          Moreover, compared to TGL, TGLite's programming interface provides first-class support for TGNN primitive operators 
          making it easier for ML researchers to try out new TGNN models.
        </div>
      </li>


      <h4>[June 6th, 2024]</h4>
        <li>
          <b>
              <a href="https://arxiv.org/pdf/2403.00032">Time to Cite: Modeling Citation Networks using the Dynamic Impact
                Single-Event Embedding Model
              </a> AISTATS 2024
          </b>
          <br> Presenter:  <u>Nikolaos Nakis</u>, Technical University of Denmark
          <a class="btn btn-info btn-xs" data-toggle="collapse" href="#24june6bio" role="button" aria-expanded="false" aria-controls="collapseExample">
            Speaker Bio
          </a>
          <div class="collapse" id="24june6bio">
            <div class="card card-body">
              <u>Nikolaos Nakis</u> is currently a postdoctoral researcher at École Polytechnique, part of the Polytechnic Institute of Paris. He holds a Ph.D. from the Technical University of Denmark. Nikolaos received his B.S. in Physics from the National and Kapodistrian University of Athens and an M.S. in Mathematical Modeling and Computation from the Technical University of Denmark. His research focuses on applying machine learning to complex systems and graph representation learning, with a primary emphasis on social network analysis.
            </div>
          </div>
          <br> 
          <a href="https://youtu.be/fPFT2pYUZdM"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a>
          <a href="https://arxiv.org/pdf/2403.00032.pdf"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
          <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#24june6" role="button" aria-expanded="false" aria-controls="collapseExample">
              Abstract
            </a>
        <div class="collapse" id="24june6">
        <div class="card card-body">
          Understanding the structure and dynamics of
          scientific research, i.e., the science of science
          (SciSci), has become an important area of research in order to address imminent questions
          including how scholars interact to advance science, how disciplines are related and evolve,
          and how research impact can be quantified
          and predicted. Central to the study of SciSci
          has been the analysis of citation networks.
          Here, two prominent modeling methodologies have been employed: one is to assess
          the citation impact dynamics of papers using
          parametric distributions, and the other is to
          embed the citation networks in a latent space
          optimal for characterizing the static relations
          between papers in terms of their citations. Interestingly, citation networks are a prominent
          example of single-event dynamic networks,
          i.e., networks for which each dyad only has
          a single event (i.e., the point in time of citation). We presently propose a novel likelihood function for the characterization of such
          single-event networks. Using this likelihood,
          we propose the Dynamic Impact Single-Event
          Embedding model (DISEE). The DISEE
          model characterizes the scientific interactions
          in terms of a latent distance model in which
          random effects account for citation heterogeneity while the time-varying impact is characterized using existing parametric representations for assessment of dynamic impact. We
          highlight the proposed approach on several
          real citation networks finding that the DISEE
          well reconciles static latent distance network
          embedding approaches with classical dynamic
          impact assessments.
        </div>
      </li>

      <h4>[June 13th, 2024]</h4>
        <li>
          <b>
              <a href="https://arxiv.org/abs/2311.18526">HOT: Higher-Order Dynamic Graph Representation Learning with Efficient Transformers

              </a> LOG 2023
          </b>
          <br> Presenter:  <u>Maciej Besta</u>, Department of Computer Science, ETH Zurich
          <a class="btn btn-info btn-xs" data-toggle="collapse" href="#24june13bio" role="button" aria-expanded="false" aria-controls="collapseExample">
            Speaker Bio
          </a>
          <div class="collapse" id="24june13bio">
            <div class="card card-body">
              <u>Maciej Besta</u> leads research on graph computations and large language models at the Scalable Parallel Computing Lab at ETH Zurich and the ETH Future Computing Lab; he also works on network topologies and occasionally other aspects of the high-performance computing landscape. Maciej published more than 50 top conference and journal papers. He won, among others, the competition for the Best Student of Poland (2012), the first Google Fellowship in Parallel Computing (2013), the ACM/IEEE-CS High-Performance Computing Fellowship (2015), the IEEE TCSC Award for Excellence in Scalable Computing Early Career (2023), and the OlympusMons Award for contributions to scalable storage systems (2024). His doctoral dissertation on irregular computations received the ETH Medal for outstanding doctoral thesis (2021), and awards from IEEE (2021), SPEC (2022), and ACM (2022) for the best dissertation worldwide in - respectively - scalable computing, performance analysis, and high-performance computing. He received Best Paper awards and nominations at ACM/IEEE Supercomputing 2013, 2014, 2019 (2 papers), 2022, and 2023 (2 papers); at ACM HPDC 2015 and 2016, ACM Research Highlights 2018, and others. More detailed information on https://people.inf.ethz.ch/bestam/
            </div>
          </div>
          <br> 
          <a href="https://youtu.be/Wafe_SK1Tbw"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a>
          <a href="https://arxiv.org/abs/2311.18526"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
          <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#24june13" role="button" aria-expanded="false" aria-controls="collapseExample">
              Abstract
            </a>
        <div class="collapse" id="24june13">
        <div class="card card-body">
          Many graph representation learning (GRL) problems are dynamic, with millions of edges added or removed per second. An example workload in this setting is dynamic link prediction: using a history of graph updates to predict whether a given pair of vertices will become connected. In this talk, we present a general pipeline for highly accurate yet scalable GRL, and apply it to the dynamic link prediction problem. The key idea underlying our pipeline is that harnessing higher-order (HO) graph structures, such as k-hop neighbors and more general subgraphs such as cliques, improves the accuracy of various GRL tasks. The pipeline consists of three general stages: extracting selected HO structures, encoding the structures into the appropriate representation, and making the prediction. However, using HO also comes with challenges. In the first stage, extracting HO structures is time-consuming and difficult to program. We address this issue with a simple yet surprisingly powerful observation: operations on sets of vertices, such as intersection or union, form a large part of many complex HO mining algorithms, and can offer rich and simple parallelism at multiple levels. In the second and third stage, the encoding of extracted HO structures into a form suitable for predictions, results in increased memory pressure. We address this with HOT: a Transformer-based model that imposes hierarchy on the attention matrix, significantly reducing memory footprint. The final design offers a sweetspot between high accuracy and low memory utilization, for example achieving 9%, 7%, and 15% higher accuracy than – respectively – DyGFormer, TGN, and GraphMixer, for the MOOC dataset. Finally, we also discuss a broader problem of predicting complex subgraphs called motifs, detailing how this problem generalizes link prediction and how to use Graph Neural Networks for high accuracy.
        </div>
      </li>

      <h4>[June 20th, 2024]</h4>
        <li>
          <b>
              <a href="https://arxiv.org/abs/2402.16387">On the Generalization Capability of Temporal Graph Learning Algorithms: Theoretical Insights and a Simpler Method
              </a> 
          </b>
          <br> Presenter:  <u>Jian Kang</u>, University of Rochester
          <a class="btn btn-info btn-xs" data-toggle="collapse" href="#24june20bio" role="button" aria-expanded="false" aria-controls="collapseExample">
            Speaker Bio
          </a>
          <div class="collapse" id="24june20bio">
            <div class="card card-body">
              <u>Jian Kang</u> is an Assistant Professor in the Department of Computer Science at the University of Rochester. His research lies in fair and reliable graph learning for social good. Prior to joining the University of Rochester, he received Ph.D. in Computer Science from the University of Illinois Urbana-Champaign, advised by Dr. Hanghang Tong. He is recognized as a Rising Star in Data Science by the University of Chicago and a Mavis Future Faculty Fellow by the University of Illinois Urbana-Champaign.
            </div>
          </div>
          <br> 
          <a href="https://arxiv.org/abs/2402.16387"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
          <a href="https://youtu.be/iIDf58TP6pI"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a>
          <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#24june20" role="button" aria-expanded="false" aria-controls="collapseExample">
              Abstract
            </a>
        <div class="collapse" id="24june20">
        <div class="card card-body">
          Temporal Graph Learning (TGL) has become a prevalent technique across diverse real-world
          applications, especially in domains where data can be represented as a graph and evolves over
          time. Although TGL has recently seen notable progress in algorithmic solutions, its theoretical
          foundations remain largely unexplored. This paper aims at bridging this gap by investigating the
          generalization ability of different TGL algorithms (e.g., GNN-based, RNN-based, and memorybased methods) under the finite-wide over-parameterized regime. We establish the connection
          between the generalization error of TGL algorithms and 1 “the number of layers/steps” in the
          GNN-/RNN-based TGL methods and 2 “the feature-label alignment (FLA) score”, where FLA
          can be used as a proxy for the expressive power and explains the performance of memory-based
          methods. Guided by our theoretical analysis, we propose Simplified-Temporal-Graph-Network
          (SToNe), which enjoys a small generalization error, improved overall performance, and lower model
          complexity. Extensive experiments on real-world datasets demonstrate the effectiveness of SToNe.
          Our theoretical findings and proposed algorithm offer essential insights into TGL from a theoretical
          standpoint, laying the groundwork for the designing practical TGL algorithms in future studies.

        </div>
      </li>











        <!-- <h4>[June 1st, 2023]</h4>
          <li>
            Cancelled due to NeurIPS benchmark track deadline
          </li> -->
        </div>
      </div>
    </section>


<section id="fall2023" class="some-section">
    <div class="container">
      <div class="row">
        <div class="col-sm-2"></div>
        <div class="col-sm-8">
          <div class="listing" style="clear:both;">
          <div class="left">

        <h3 style="text-align:center">Past Talks, Fall 2023</h3>
          <h4>[September 14th, 2023]</h4>
          <li>
            <b>
                <a href="https://arxiv.org/abs/2305.10498"> Edge Directionality Improves Learning on Heterophilic Graphs </a> 2023
            </b>
            <br> Presenter: <u>Emanuele Rossi</u> Imperial College London
            <a class="btn btn-info btn-xs" data-toggle="collapse" href="#sep14bio" role="button" aria-expanded="false" aria-controls="collapseExample">
              Speaker Bio
            </a>
            <div class="collapse" id="sep14bio">
              <div class="card card-body">
                <u>Emanuele Rossi </u> is a final-year Ph.D. student at Imperial College London, working on Graph Neural Networks and supervised by Prof. Michael Bronstein. His research explores various aspects of graph neural networks, such as scalability, dynamic graphs, and learning with missing node features. Before starting his Ph.D., Emanuele spent time working at Twitter and Fabula AI, which was bought by Twitter in June 2019. He also holds an MPhil from the University of Cambridge and a BEng from Imperial College London, both in Computer Science.
              </div>
            </div>
            <br> 
            <a href="https://youtu.be/VjpUSR1NZvI"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a>
            <a href="https://arxiv.org/abs/2305.10498"><img src="https://img.shields.io/badge/arXiv-pdf-yellowgreen"></a>
            <a href="https://github.com/emalgorithm/directed-graph-neural-network"><img src="https://img.shields.io/badge/Github-link-lightgrey"></a>
            <a href="https://towardsdatascience.com/direction-improves-graph-learning-170e797e94fe"><img src="https://img.shields.io/badge/blog-post-blueviolet"></a> 
            <a href="https://drive.google.com/file/d/1p9KCJVz39sLJOhsjqBgG_2JUUbMW1zP-/view?usp=sharing"> <img src="https://img.shields.io/badge/Talk%20-Slides-blue"></a>  
            <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#sep14" role="button" aria-expanded="false" aria-controls="collapseExample">
                Abstract
              </a>
          <div class="collapse" id="sep14">
          <div class="card card-body">
            Graph Neural Networks (GNNs) have become the de-facto standard tool for modeling relational data. However, while many real-world graphs are directed, the majority of today's GNN models discard this information altogether by simply making the graph undirected. The reasons for this are historical: 1) many early variants of spectral GNNs explicitly required undirected graphs, and 2) the first benchmarks on homophilic graphs did not find significant gain from using direction. In this paper, we show that in heterophilic settings, treating the graph as directed increases the effective homophily of the graph, suggesting a potential gain from the correct use of directionality information. To this end, we introduce Directed Graph Neural Network (Dir-GNN), a novel general framework for deep learning on directed graphs. Dir-GNN can be used to extend any Message Passing Neural Network (MPNN) to account for edge directionality information by performing separate aggregations of the incoming and outgoing edges. We prove that Dir-GNN matches the expressivity of the Directed Weisfeiler-Lehman test, exceeding that of conventional MPNNs. In extensive experiments, we validate that while our framework leaves performance unchanged on homophilic datasets, it leads to large gains over base models such as GCN, GAT and GraphSage on heterophilic benchmarks, outperforming much more complex methods and achieving new state-of-the-art results.
          </div>
        </li>

        <h4>[September 21st, 2023]</h4>
        <li>
          <b>
              <a href="https://dl.acm.org/doi/abs/10.1145/3534678.3542619"> Temporal Graph Learning for Financial World: Algorithms, Scalability, Explainability & Fairness </a> AAAI 2022
          </b>
          <br> Presenter: <u>Karamjit Singh</u>, AI Garage and Mastercard
          <a class="btn btn-info btn-xs" data-toggle="collapse" href="#sep21bio" role="button" aria-expanded="false" aria-controls="collapseExample">
            Speaker Bio
          </a>
          <div class="collapse" id="sep21bio">
            <div class="card card-body">
              <u>Karamjit Singh</u> is currently the Director of Artificial Intelligence at Mastercard, where he focuses on creating AI-driven products in the payment space. With 11 years of experience spanning various industries, Karamjit holds dual master's degrees, including an M.Tech in Computer Applications from IIT Delhi and a Master’s in Mathematics. He has authored over 20 publications in AI/ML conferences and holds more than 15 patents. Karamjit has achieved recognition through accomplishments like securing the 2nd Rank in CIKM 2020 Analytics Cup and winning the IEEE VGTC VPG International Data-Visualization Contest. He has also contributed to data science conferences and workshops as part of program committees and organized the MUFin workshop at CIKM 2021, ECML PAKDD 2022, AAAI 2023.
            </div>
          </div>
          <br> 
          <a href="https://youtu.be/FhqE-4bNVaQ"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a>
          <a href="https://dl.acm.org/doi/abs/10.1145/3534678.3542619"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
          <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#sep21" role="button" aria-expanded="false" aria-controls="collapseExample">
              Abstract
            </a>
        <div class="collapse" id="sep21">
        <div class="card card-body">
          The most intuitive way to model a transaction in the financial world is through a Graph. Every transaction can be considered as an edge between two vertices, one of which is the paying party and another is the receiving party. Properties of these nodes and edges directly map to business problems in the financial world. The problem of detecting a fraudulent transaction can be considered as a property of the edge. The problem of money laundering can be considered as a path-detection in the Graph. The problem of a merchant going delinquent can be considered as the property of a node. While there are many such examples, the above help in realising the direct mapping of Graph properties with the financial problems in the real-world. This tutorial is based on the potential of using Graph Neural Network based Learning for solving business problems in the financial world
        </div>
      </li>


      <h4>[September 28th, 2023]</h4>
        <li>
          <b>
              <a href="https://arxiv.org/abs/2307.01026"> Temporal Graph Benchmark for Machine Learning on Temporal Graphs
              </a> NeurIPS 2023 Datasets and Benchmarks Track
          </b>
          <br> Presenter: <u>Shenyang Huang</u>, <u>Farimah Poursafaei</u> McGill University, Mila
          <a class="btn btn-info btn-xs" data-toggle="collapse" href="#sep28bio" role="button" aria-expanded="false" aria-controls="collapseExample">
            Speaker Bio
          </a>
          <div class="collapse" id="sep28bio">
            <div class="card card-body">
              <u> Shenyang Huang </u> is a PhD student at McGill University and Mila, focusing on temporal graph learning (supervised by Prof. Reihaneh Rabbany and Prof. Guillaume Rabusseau). He is interested in representation learning on temporal graphs, anomaly detection and graph representation learning. He was the Organization Chair for the Temporal Graph Learning Workshop @ NeurIPS 2022. His previous research includes change point detection on temporal graphs, COVID-19 disease modeling with temporal contact graphs and link prediction on temporal graphs. He also enjoys writing medium blog posts about temporal graph learning.
              <br>
              <u> Farimah Poursafaei </u> is a PostDoc at McGill University and Mila. She conducts research on dynamic graph neural networks, and temporal graphs. She completed her PhD at McGill University in Computer Engineering. During her PhD, she was working on anomaly detection on cryptocurrency transactions networks. She served as the Reviewing Chair in Temporal Graph Learning Workshop @ NeurIPS 2022.
            </div>
          </div>
          <br> 
          <a href="https://youtu.be/QmYZOT_so9U"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a>
          <a href="https://drive.google.com/file/d/1wr7ZS0U_jAuFKciPJsO93U-yRHx1Wysg/view?usp=sharing"><img src="https://img.shields.io/badge/Talk%20-Slides-blue"></a>
          <a href="https://arxiv.org/abs/2307.01026"><img src="https://img.shields.io/badge/arXiv-pdf-yellowgreen"></a>
          <a href="https://pypi.org/project/py-tgb/"><img src="https://img.shields.io/pypi/v/py-tgb.svg?color=brightgreen"></a>
          <a href="https://tgb.complexdatalab.com/"><img src="https://img.shields.io/badge/website-blue"></a>
          <a href="https://docs.tgb.complexdatalab.com/"><img src="https://img.shields.io/badge/docs-orange"></a>
          <a href="https://github.com/shenyangHuang/TGB"><img src="https://img.shields.io/badge/Github-link-lightgrey"></a>
          <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#sep28" role="button" aria-expanded="false" aria-controls="collapseExample">
              Abstract
            </a>
        <div class="collapse" id="sep28">
        <div class="card card-body">
          We present the Temporal Graph Benchmark (TGB), a collection of challenging and diverse benchmark datasets for realistic, reproducible, and robust evaluation of machine learning models on temporal graphs. TGB datasets are of large scale, spanning years in duration, incorporate both node and edge-level prediction tasks and cover a diverse set of domains including social, trade, transaction, and transportation networks. For both tasks, we design evaluation protocols based on realistic use-cases. We extensively benchmark each dataset and find that the performance of common models can vary drastically across datasets. In addition, on dynamic node property prediction tasks, we show that simple methods often achieve superior performance compared to existing temporal graph models. We believe that these findings open up opportunities for future research on temporal graphs. Finally, TGB provides an automated machine learning pipeline for reproducible and accessible temporal graph research, including data loading, experiment setup and performance evaluation. TGB will be maintained and updated on a regular basis and welcomes community feedback. TGB datasets, data loaders, example codes, evaluation setup, and leaderboards are publicly available
        </div>
      </li>


      <h4>[October 5th, 2023]</h4>
        <li>
          <b>
              <a href="https://ojs.aaai.org/index.php/AAAI/article/view/20338"> HAGEN: Homophily-Aware Graph Convolutional Recurrent Network for Crime Forecasting </a> AAAI 2022
          </b>
          <br> Presenter: <u>Chenyu Wang</u> and <u>Zongyu Lin</u> Tsinghua University
          <a class="btn btn-info btn-xs" data-toggle="collapse" href="#oct5bio" role="button" aria-expanded="false" aria-controls="collapseExample">
            Speaker Bio
          </a>
          <div class="collapse" id="oct5bio">
            <div class="card card-body">
              <u>Zongyu Lin</u> is now a CS Ph.D student from UCLA, graduated from Tsinghua university. His research interest lies broadly in AI for content generation (e.g., large language models and diffusion models), and AI for science (e.g., time series forecasting). 
              <br>
              <u>Chenyu Wang</u> is now a Ph.D student at MIT EECS, advised by Prof. Caroline Uhler and Prof. Tommi Jaakkola. Prior to that, she attained her bachelor's degree at Tsinghua University. Her research interest lies broadly in machine learning, representation learning, and AI for science (especially computational biology).
            </div>
          </div>
          <br> 
          <a href="https://youtu.be/IyBV33tEx0E"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a>
          <a href="https://drive.google.com/file/d/1oRVmyo-R5sLEjnpD1mp429RBZ3wyGVar/view?usp=sharing"> <img src="https://img.shields.io/badge/Talk%20-Slides-blue"></a>
          <a href="https://ojs.aaai.org/index.php/AAAI/article/view/20338"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
          <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#oct5" role="button" aria-expanded="false" aria-controls="collapseExample">
              Abstract
            </a>
        <div class="collapse" id="oct5">
        <div class="card card-body">
          The goal of the crime forecasting problem is to predict different types of crimes for each geographical region (like a neighborhood or censor tract) in the near future. Since nearby regions usually have similar socioeconomic characteristics which indicate similar crime patterns, recent state-of-the-art solutions constructed a distance-based region graph and utilized Graph Neural Network (GNN) techniques for crime forecasting, because the GNN techniques could effectively exploit the latent relationships between neighboring region nodes in the graph if the edges reveal high dependency or correlation. However, this distance-based pre-defined graph can not fully capture crime correlation between regions that are far from each other but share similar crime patterns. Hence, to make a more accurate crime prediction, the main challenge is to learn a better graph that reveals the dependencies between regions in crime occurrences and meanwhile captures the temporal patterns from historical crime records. To address these challenges, we propose an end-to-end graph convolutional recurrent network called HAGEN with several novel designs for crime prediction. Specifically, our framework could jointly capture the crime correlation between regions and the temporal crime dynamics by combining an adaptive region graph learning module with the Diffusion Convolution Gated Recurrent Unit (DCGRU). Based on the homophily assumption of GNN (i.e., graph convolution works better where neighboring nodes share the same label), we propose a homophily-aware constraint to regularize the optimization of the region graph so that neighboring region nodes on the learned graph share similar crime patterns, thus fitting the mechanism of diffusion convolution. Empirical experiments and comprehensive analysis on two real-world datasets showcase the effectiveness of HAGEN
        </div>
      </li>


      <h4>[October 12th, 2023]</h4>
        <li>
          <b>
              <a href="https://arxiv.org/abs/2307.03759"> A Survey on Graph Neural Networks for Time Series: Forecasting, Classification, Imputation, and Anomaly Detection </a>
          </b>
          <br> Presenter: <u>Ming Jin</u> Monash University
          <a class="btn btn-info btn-xs" data-toggle="collapse" href="#oct12bio" role="button" aria-expanded="false" aria-controls="collapseExample">
            Speaker Bio
          </a>
          <div class="collapse" id="oct12bio">
            <div class="card card-body">
              <u>Ming Jin</u> is a Ph.D. Candidate in Computer Science at Monash University, where he is currently being supervised by Prof. Shirui Pan and A/Prof. Yuan-Fang Li. He is also a Research Staff at Metso Outotec and a Research Assistant at Monash University. Ming completed his Bachelor's and Master's degrees at Hebei University of Technology and The University of Melbourne in 2017 and 2019, respectively. He has published over ten top-ranked conference and journal papers and regularly served as a PC member and reviewer of major AI/ML/DM conferences and journals, including IJCAI, PAKDD, TNNLS, TKDE, and more. Ming's research interests mainly focus on graph neural networks and geometric deep learning, with a particular emphasis on temporal settings such as dynamic graph neural networks. He is particularly passionate about applying these techniques to tackle practical challenges such as time series forecasting, industrial process modeling, and anomaly detection.
            </div>
          </div>
          <br> 
          <a href="https://youtu.be/8qPWcq0C4Pg"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a>
          <a href="https://drive.google.com/file/d/1uyOGtQ7shn2Vo56BZTSiUnzvyM4dlt6V/view?usp=sharing"> <img src="https://img.shields.io/badge/Talk%20-Slides-blue"></a>
          <a href="https://arxiv.org/abs/2307.03759"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
          <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#oct12" role="button" aria-expanded="false" aria-controls="collapseExample">
              Abstract
            </a>
        <div class="collapse" id="oct12">
        <div class="card card-body">
          Time series are the primary data type used to record dynamic system measurements and generated in great volume by both physical sensors and online processes (virtual sensors). Time series analytics is therefore crucial to unlocking the wealth of information implicit in available data. With the recent advancements in graph neural networks (GNNs), there has been a surge in GNN-based approaches for time series analysis. These approaches can explicitly model inter-temporal and inter-variable relationships, which traditional and other deep neural network-based methods struggle to do. In this survey, we provide a comprehensive review of graph neural networks for time series analysis (GNN4TS), encompassing four fundamental dimensions: forecasting, classification, anomaly detection, and imputation. Our aim is to guide designers and practitioners to understand, build applications, and advance research of GNN4TS. At first, we provide a comprehensive task-oriented taxonomy of GNN4TS. Then, we present and discuss representative research works and introduce mainstream applications of GNN4TS. A comprehensive discussion of potential future research directions completes the survey. This survey, for the first time, brings together a vast array of knowledge on GNN-based time series research, highlighting foundations, practical applications, and opportunities of graph neural networks for time series analysis.
        </div>
      </li>

    <h4>[October 19th, 2023]</h4>
      <li>
        <b>
            <a href="https://arxiv.org/pdf/2306.03447.pdf"> GRAFENNE: Learning on Graphs with Heterogeneous and Dynamic Feature Sets </a> ICML 2023
        </b>
        <br> Presenter: <u>Sahil Manchanda</u> Department of Computer Science at the Indian Institute of Technology Delhi
        <a class="btn btn-info btn-xs" data-toggle="collapse" href="#oct19bio" role="button" aria-expanded="false" aria-controls="collapseExample">
          Speaker Bio
        </a>
        <div class="collapse" id="oct19bio">
          <div class="card card-body">
            <u>Sahil Manchanda</u> is a PhD scholar at the Department of Computer Science at the Indian Institute of Technology Delhi, working under the supervision of Prof. Sayan Ranu. Sahil works in the area of Learning to solve graph optimization problems with focus on Combinatorial Optimization, Graph Neural Networks, Lifelong Learning and Generative modeling. He is also interested in applications of Computer Science concepts in other fields such as VLSI Chip Design and Material Science to discover new materials. He has interned at prestigious institutes such as the University of Tokyo, Naver Labs- France and Qualcomm AI research Amsterdam. His research works have been published in conferences such as NeurIPS, AAAI, ICML and ECML-PKDD. Additionally he has one US patent granted to his name. Sahil has been the recipient of the Qualcomm Innovation Fellowship for the year 2022.
          </div>
        </div>
        <br> 
        <a href="https://youtu.be/OIaEKwQBexY"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a>
        <a href="https://arxiv.org/pdf/2306.03447.pdf"><img src="https://img.shields.io/badge/arXiv-pdf-yellowgreen"></a>
        <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#oct19" role="button" aria-expanded="false" aria-controls="collapseExample">
            Abstract
          </a>
      <div class="collapse" id="oct19">
      <div class="card card-body">
        Graph neural networks (GNNs), in general, are built on the assumption of a static set of features characterizing each node in a graph. This assumption is often violated in practice. Existing methods partly address this issue through feature imputation. However, these techniques (i) assume uniformity of feature set across nodes, (ii) are transductive by nature, and (iii) fail to work when features are added or removed over time. In this work, we address these limitations through a novel GNN framework called GRAFENNE. GRAFENNE performs a novel allotropic transformation on the original graph, wherein the nodes and features are decoupled through a bipartite encoding. Through a carefully chosen message passing framework on the allotropic transformation, we make the model parameter size independent of the number of features and thereby inductive to both unseen nodes and features. We prove that GRAFENNE is at least as expressive as any of the existing message-passing GNNs in terms of Weisfeiler-Leman tests, and therefore, the additional inductivity to unseen features does not come at the cost of expressivity. In addition, as demonstrated over four real-world graphs, GRAFENNE empowers the underlying GNN with high empirical efficacy and the ability to learn in continual fashion over streaming feature sets.
      </div>
      </li>

      <h4>[October 26th, 2023]</h4>
        <li>
          <b>
              <a href="https://dl.acm.org/doi/abs/10.1145/3511808.3557233"> Along the Time: Timeline-traced Embedding for Temporal Knowledge Graph Completion </a> CIKM 2022
          </b>
          <br> Presenter: <u>Fuwei Zhang</u> and <u>Zhao Zhan</u> Institute of Computing Technology, Chinese Academy of Sciences
          <a class="btn btn-info btn-xs" data-toggle="collapse" href="#oct26bio" role="button" aria-expanded="false" aria-controls="collapseExample">
            Speaker Bio
          </a>
          <div class="collapse" id="oct26bio">
            <div class="card card-body">
              <u> Fuwei Zhang </u> is now a PhD student from the Institute of Artificial Intelligence, Beihang University. His research interests include data mining and applied machine learning, with a special focus on the representation and application of knowledge graphs.
              <br>
              <u> Zhao Zhan </u> is an assistant professor at Institute of Computing Technology, Chinese Academy of Sciences. His research interest lies in data mining and machine learning, especially the representation and application of knowledge graphs.
            </div>
          </div>
          <br> 
          <a href="https://youtu.be/X4UCzG1ASMo"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a>
          <a href="https://dl.acm.org/doi/abs/10.1145/3511808.3557233"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
          <a href="https://github.com/zhangfw123/TLT-KGE"><img src="https://img.shields.io/badge/Github-link-lightgrey"></a>
          <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#oct26" role="button" aria-expanded="false" aria-controls="collapseExample">
              Abstract
            </a>
        <div class="collapse" id="oct26">
        <div class="card card-body">
          Recent years have witnessed remarkable progress on knowledge graph embedding (KGE) methods to learn the representations of entities and relations in static knowledge graphs (SKGs). However, knowledge changes over time. In order to represent the facts happening in a specific time, temporal knowledge graph (TKG) embedding approaches are put forward. While most existing models ignore the independence of semantic and temporal information. We empirically find that current models have difficulty distinguishing representations of the same entity or relation at different timestamps. In this regard, we propose a TimeLine-Traced Knowledge Graph Embedding method (TLT-KGE) for temporal knowledge graph completion. TLT-KGE aims to embed the entities and relations with timestamps as a complex vector or a quaternion vector. Specifically, TLT-KGE models semantic information and temporal information as different axes of complex number space or quaternion space. Meanwhile, two specific components carving the relationship between semantic and temporal information are devised to buoy the modeling. In this way, the proposed method can not only distinguish the independence of the semantic and temporal information, but also establish a connection between them. Experimental results on the link prediction task demonstrate that TLT-KGE achieves substantial improvements over state-of-the-art competitors. The source code will be available on https://github.com/zhangfw123/TLT-KGE.
        </div>
      </li>
      
      <h4>[November 2nd, 2023]</h4>
        <li>
          <b>
             My journey in the land of temporal networks and dynamic graphs
          </b>
          <br> Presenter: <u>Petter Holme</u> Aalto University
          <a class="btn btn-info btn-xs" data-toggle="collapse" href="#nov2bio" role="button" aria-expanded="false" aria-controls="collapseExample">
            Speaker Bio
          </a>
          <div class="collapse" id="nov2bio">
            <div class="card card-body">
              <u>Petter Holme</u> is a Professor of Network Science at the Department of Computer Science, Aalto University, Finland, and a Research Fellow at The Center of Computational Social Science, Kobe University, Japan. Formerly, Holme held faculty positions at the Tokyo Institute of Technology, Japan, Sungkyunkwan University, Korea, and Umeå University and the Royal Institute of Technology, Sweden. His research covers a broad scientific ground in the borderland between the social and formal sciences. Among many other things, Holme pioneered the study of temporal networks. Holme has over 190 publications and over 19,000 citations.
            </div>
          </div>
          <br> 
          <a href="https://youtu.be/BSNJSUkc5-Q"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a>
          <a href="https://drive.google.com/file/d/1HxUWplqDtKJZfbg7Iuf6tJx_3CweNivY/view?usp=sharing"> <img src="https://img.shields.io/badge/Talk%20-Slides-blue"></a>
          <a href="https://link.springer.com/article/10.1140/epjb/e2015-60657-4"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
          <a href="https://petterhol.me/2022/08/10/t-extraordinary-fluidity-of-effortless-abstractions/"><img src="https://img.shields.io/badge/blog-post-blueviolet"></a> 

          <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#nov2" role="button" aria-expanded="false" aria-controls="collapseExample">
              Abstract
            </a>
        <div class="collapse" id="nov2">
        <div class="card card-body">
          I will cover some highlights and insights in my two-decade-long research on how to understand systems through their combined temporal and topological structure. I will discuss: The use of randomization techniques to understand diffusion dynamics on temporal networks. The profound difficulties in generalizing insights from network science and graph theory to temporal graphs. The philosophy of community structures in graphs. Why there hasn't been any discovery of ubiquitous structures that are both temporal and topological.
        </div>
      </li>

      <h4>[November 9th, 2023]</h4>
        <li>
          <b>
              <a href="https://dl.acm.org/doi/pdf/10.1145/3580305.3599517"> Temporal Dynamics-Aware Adversarial Attacks on Discrete-Time Dynamic Graph Models </a> KDD 2023
          </b>
          <br> Presenter: <u>Kartik Sharma</u> Georgia Institute of Technology
          <a class="btn btn-info btn-xs" data-toggle="collapse" href="#nov9bio" role="button" aria-expanded="false" aria-controls="collapseExample">
            Speaker Bio
          </a>
          <div class="collapse" id="nov9bio">
            <div class="card card-body">
              <u>Kartik Sharma</u> is a third-year PhD student at Georgia Tech, where he is advised by Prof. Srijan Kumar. He is interested in studying the robustness and alignment of machine learning models. His works are focused on studying these models for structured data such as social networks, temporal graphs, and knowledge bases. He has published in venues such as KDD, AAAI, CIKM, and WSDM.
            </div>
          </div>
          <br> 
          <a href="https://youtu.be/KP9UsCQG4tY"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a>
          <a href="https://dl.acm.org/doi/pdf/10.1145/3580305.3599517"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
          <a href="https://drive.google.com/file/d/1vXq9k-8oEKU-pbO4YwAAesr_ko-gmeqi/view?usp=sharing"><img src="https://img.shields.io/badge/Talk%20-Slides-blue"></a>
          <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#nov9" role="button" aria-expanded="false" aria-controls="collapseExample">
              Abstract
            </a>
        <div class="collapse" id="nov9">
        <div class="card card-body">
          Real-world graphs such as social networks, communication networks, and rating networks are constantly evolving over time. Many deep learning architectures have been developed to learn effective node representations using both graph structure and dynamics. While being crucial for practical applications, the robustness of these representation learners for dynamic graphs in the presence of
            adversarial attacks is highly understudied. In this work, we design a novel adversarial attack on discrete-time dynamic graph models where we desire to perturb the input graph sequence in a manner that preserves the temporal dynamics of the graph while dropping the performance of representation learners. To this end, we motivate a novel Temporal Dynamics-Aware Perturbation (TDAP)
            constraint, which ensures that perturbations introduced at each time step are restricted to only a small fraction of the number of
            changes in the graph since the previous time step. We present a
            theoretically-motivated Projected Gradient Descent approach for
            dynamic graphs to find effective perturbations under the TDAP
            constraint. Experiments on two tasks — dynamic link prediction
            and node classification, show that our approach is up to 4x more
            effective than the baseline methods for attacking these models.
            We extend our approach to a more practical online setting where
            graphs become available in real-time and show up to 5x superior
            performance over baselines We also show that our approach successfully evades state-of-the-art neural approaches for anomaly
            detection, thereby promoting the need to study robustness as a part
            of representation-learning approaches for dynamic graphs.
        </div>
      </li>

      <h4>[November 16th, 2023]  **cancelled, to be rescheduled**</h4>
        <li>
          <b>
              <a href="https://arxiv.org/abs/2110.00506"> Temporal Graphs and Temporal Network Characteristics for Bio-Inspired Networks during Optimization </a>
          </b>
          <br> Presenter: <u>Abdel Isakovic</u> Colgate University
          <a class="btn btn-info btn-xs" data-toggle="collapse" href="#nov16bio" role="button" aria-expanded="false" aria-controls="collapseExample">
            Speaker Bio
          </a>
          <div class="collapse" id="nov16bio">
            <div class="card card-body">
              <u>Abdel Isakovic</u> is a Visiting Assistant Professor of Physics at Colgate University.
            </div>
          </div>
          <br> 
          <a href="https://arxiv.org/abs/2110.00506"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
          <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#nov16" role="button" aria-expanded="false" aria-controls="collapseExample">
              Abstract
            </a>
        <div class="collapse" id="nov16">
        <div class="card card-body">
          Temporal network analysis and time evolution of network characteristics are powerful tools in describing the changing topology of dynamic networks. This paper uses such approaches to better visualize and provide analytical measures for the changes in performance that we observed in
            Voronoi-type spatial coverage, particularly for the example of time evolving networks with a changing number of wireless sensors being deployed. Specifically, our analysis focuses on the role different
            combinations of impenetrable obstacles and environmental noise play in connectivity and overall
            network structure. It is shown how the use of (i) temporal network graphs, and (ii) network centrality and regularity measures illustrate the differences between various options developed for the
            balancing act of energy and time efficiency in network coverage. Lastly, we compare the outcome
            of these measures with the less abstract classification variables, such as percent area covered, and
            cumulative distance travelled.
        </div>
      </li>


      <h4>[November 23rd, 2023]</h4>
      <li>
        <b>
            <a href="https://arxiv.org/abs/2310.04562"> ULTRA: Foundation Models for Knowledge Graph Reasoning </a>
        </b>
        <br> Presenter: <u>Michael Galkin</u> Intel AI Lab
        <a class="btn btn-info btn-xs" data-toggle="collapse" href="#nov23bio" role="button" aria-expanded="false" aria-controls="collapseExample">
          Speaker Bio
        </a>
        <div class="collapse" id="nov23bio">
          <div class="card card-body">
            <u>Michael Galkin</u> is a Research Scientist at Intel AI Lab in San Diego working on Graph Machine Learning and Geometric Deep Learning. Previously, he was a postdoc at Mila – Quebec AI Institute with Will Hamilton, Reihaneh Rabbany, and Jian Tang, focusing on many graph representation learning problems. Sometimes, Mike writes <a href="https://mgalkin.medium.com/">long blog posts on Medium</a> about graph learning.
          </div>
        </div>
        <br> 
        <a href="https://youtu.be/-RAKfpir5QU"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a>
        <a href="https://arxiv.org/abs/2310.04562"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
        <a href="https://github.com/DeepGraphLearning/ULTRA"><img src="https://img.shields.io/badge/Github-link-lightgrey"></a>
        <a href="https://towardsdatascience.com/ultra-foundation-models-for-knowledge-graph-reasoning-9f8f4a0d7f09"><img src="https://img.shields.io/badge/blog-post-blueviolet"></a> 
        <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#nov23" role="button" aria-expanded="false" aria-controls="collapseExample">
            Abstract
          </a>
      <div class="collapse" id="nov23">
      <div class="card card-body">
        Foundation models in language and vision have the ability to run inference on any textual and visual inputs thanks to the transferable representations such as a vocabulary of tokens in language. Knowledge graphs (KGs) have different entity and relation vocabularies that generally do not overlap. The key challenge of designing foundation models on KGs is to learn such transferable representations that enable inference on any graph with arbitrary entity and relation vocabularies. In this work, we make a step towards such foundation models and present ULTRA, an approach for learning universal and transferable graph representations. ULTRA builds relational representations as a function conditioned on their interactions. Such a conditioning strategy allows a pre-trained ULTRA model to inductively generalize to any unseen KG with any relation vocabulary and to be fine-tuned on any graph. Conducting link prediction experiments on 57 different KGs, we find that the zero-shot inductive inference performance of a single pre-trained ULTRA model on unseen graphs of various sizes is often on par or better than strong baselines trained on specific graphs. Fine-tuning further boosts the performance.
      </div>
    </li>



    <h4>[November 30th, 2023]</h4>
        <li>
          <b>
              <a href="https://arxiv.org/pdf/2112.08733.pdf"> Self-Supervised Dynamic Graph Representation Learning via Temporal Subgraph Contrast </a> TKDD
          </b>
          <br> Presenter: <u>Ke-Jia Chen</u> Nanjing University of Posts and Telecommunications
          <a class="btn btn-info btn-xs" data-toggle="collapse" href="#nov30bio" role="button" aria-expanded="false" aria-controls="collapseExample">
            Speaker Bio
          </a>
          <div class="collapse" id="nov30bio">
            <div class="card card-body">
              <u>Ke-Jia Chen</u> is an associate professor in Nanjing University of Posts and Telecommunications, China. She received the PhD in Université de Technologie de Compiègne, France and the M.S. and B.S. degree in Nanjing University, China. Her current research focuses on graph machine learning and complex network analysis. She once published papers in TOIS, TKDD, ECML, ICDM, ASONAM, etc.
            </div>
          </div>
          <br> 
          <a href="https://youtu.be/RisoMfeoLqg?si=tA1LJb74Qemau8yG"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a>
          <a href="https://arxiv.org/pdf/2112.08733.pdf"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
          <a href="https://drive.google.com/file/d/1qpip08-hvy5PCIsayhhjY80qbG1PnLM1/view?usp=sharing"> <img src="https://img.shields.io/badge/Talk%20-Slides-blue"></a>  
          <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#nov30" role="button" aria-expanded="false" aria-controls="collapseExample">
              Abstract
            </a>
        <div class="collapse" id="nov30">
        <div class="card card-body">
          Self-supervised learning on graphs has recently drawn a lot of attention due to its independence from labels and its robustness in
          representation. Current studies on this topic mainly use static information such as graph structures but cannot well capture dynamic information such as timestamps of edges. Realistic graphs
          are often dynamic, which means the interaction between nodes
          occurs at a specific time. This paper proposes a self-supervised dynamic graph representation learning framework (DySubC), which
          defines a temporal subgraph contrastive learning task to simultaneously learn the structural and evolutional features of a dynamic
          graph. Specifically, a novel temporal subgraph sampling strategy
          is firstly proposed, which takes each node of the dynamic graph
          as the central node and uses both neighborhood structures and
          edge timestamps to sample the corresponding temporal subgraph.
          The subgraph representation function is then designed according
          to the influence of neighborhood nodes on the central node after
          encoding the nodes in each subgraph. Finally, the structural and
          temporal contrastive loss are defined to maximize the mutual information between node representation and temporal subgraph representation. Experiments on five real-world datasets demonstrate
          that (1) DySubC performs better than the related baselines including two graph contrastive learning models and four dynamic graph
          representation learning models in the downstream link prediction
          task, and (2) the use of temporal information can not only sample
          more effective subgraphs, but also learn better representation by
          temporal contrastive loss.
        </div>
      </li>





    </div>
  </div>
</section>


<section id="summer2023" class="some-section">
  <div class="container">
    <div class="row">
      <div class="col-sm-2"></div>
      <div class="col-sm-8">
        <div class="listing" style="clear:both;">
        <div class="left">

      <h3 style="text-align:center">Past Talks, Summer 2023</h3>

        <h4>[May 4th, 2023]</h4>
        <li>
            <b>
                <a href="https://proceedings.mlr.press/v198/qarkaxhija22a.html"> De Bruijn Goes Neural: Causality-Aware Graph Neural Networks for Time Series Data on Dynamic Graphs</a> LOG 2022
            </b>
            <br> Presenter: <u>Ingo Scholtes</u> and <u>Lisi Qarkaxhija</u> Center for Artificial Intelligence and Data Science of Julius-Maximilians-Universität Würzburg, Germany  
            <a class="btn btn-info btn-xs" data-toggle="collapse" href="#may4bio" role="button" aria-expanded="false" aria-controls="collapseExample">
              Speaker Bio
            </a>
            <div class="collapse" id="may4bio">
              <div class="card card-body">
                <u>Ingo Scholtes</u> Ingo Scholtes is a Full Professor for Machine Learning in Complex Networks at the Center for Artificial Intelligence and Data Science of Julius-Maximilians-Universität Würzburg, Germany as well as SNSF Professor for Data Analytics at the Department of Computer Science at the University of Zürich, Switzerland. He has a background in computer science and mathematics and obtained his doctorate degree from the University of Trier, Germany. At CERN, he developed a large-scale data distribution system, which is currently used to monitor particle collision data from the ATLAS detector.
                After finishing his doctorate degree, he was a postdoctoral researcher at the interdisciplinary Chair of Systems Design at ETH Zürich from 2011 till 2016.In 2016 he held an interim professorship for Applied Computer Science at the Karlsruhe Institute of Technology, Germany.In 2017 he returned to ETH Zürich as a senior assistant and lecturer. In 2019 he was appointed Full Professor at the University of Wuppertal.Since 2021 he holds the Chair of Computer Science XV - Machine Learning for Complex Networks at Julius-Maximilians-Universität Würzburg, Germany.
                <br>
                <u>Lisi Qarkaxhija</u> Lisi Qarkaxhija is a Computer Science PhD candidate at the Chair of Machine Learning for Complex Networks, Center for Artificial Intelligence and Data Science (CAIDAS), Julius-Maximilians-Universität Würzburg, under the supervision of Prof. Ingo Scholtes. 
                His research focuses on developing higher-order graph neural network models and their applications in interdisciplinary fields.
                Prior to his PhD studies, Lisi completed his Masters in Data Science at University of Primorksa (FAMNIT) Koper, Slovenia, and his Bachelor's in Mathematics from the same institution.                                
              </div>
            </div>
            <br>  
            <a href="https://youtu.be/IezbzMMp9QM"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a>
            <a href="https://openreview.net/forum?id=Dbkqs1EhTr"><img src="https://img.shields.io/badge/LOG%20-OpenReview-red"></a>
            <a href="https://ingoscholtes.github.io/kdd2018-tutorial/pathpy"><img src="https://img.shields.io/badge/tutorial-link"></a>
            <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#may4" role="button" aria-expanded="false" aria-controls="collapseExample">
                Abstract
              </a>
          <div class="collapse" id="may4">
          <div class="card card-body">
            We introduce De Bruijn Graph Neural Networks (DBGNNs), a novel time-aware graph neural network architecture for time-resolved data on dynamic graphs. Our approach accounts for temporal-topological patterns that unfold in the causal topology of dynamic graphs, which is determined by \emph{causal walks}, i.e. temporally ordered sequences of links by which nodes can influence each other over time. Our architecture builds on multiple layers of higher-order De Bruijn graphs, an iterative line graph construction where nodes in a De Bruijn graph of order \textdollar k\textdollar represent walks of length \textdollar k-1\textdollar , while edges represent walks of length \textdollar k\textdollar . We develop a graph neural network architecture that utilizes De Bruijn graphs to implement a message passing scheme that considers non-Markovian characteristics of causal walks, which enables us to learn patterns in the causal topology of dynamic graphs. Addressing the issue that De Bruijn graphs with different orders \textdollar k\textdollar can be used to model the same data, we apply statistical model selection to determine the optimal graph to be used for message passing. An evaluation in synthetic and empirical data sets suggests that DBGNNs can leverage temporal patterns in dynamic graphs, which substantially improves performance in a node classification task.
          </div>
        </li>

        <h4>[May 11th, 2023]</h4>
        <li>
            <b>
                <a href="https://arxiv.org/pdf/2203.07782.pdf"> Complex Evolutional Pattern Learning for Temporal Knowledge Graph Reasoning</a>, ACL 2022 
            </b>
            <br> Presenter: <u>Zixuan Li</u>, Chinese Academy of Sciences
            <a class="btn btn-info btn-xs" data-toggle="collapse" href="#may11bio" role="button" aria-expanded="false" aria-controls="collapseExample">
              Speaker Bio
            </a>
            <div class="collapse" id="may11bio">
              <div class="card card-body">
                <u>Zixuan Li</u>is currently an assistant professor at CAS Key Lab of Network Data Science and Technology, Institute of Computing Technology, Chinese Academy of Sciences. Before that, he obtained his Ph.D. degree from the Institute of Computing Technology, Chinese Academy of Sciences. His current research interest includes knowledge graphs and natural language processing. He regularly publishes in top-tier conferences and journals of the field, including SIGIR, ACL, EMNLP, AAAI, KIS and IEEE TKDE.
              </div>
            </div>
            <br> 
            <a href="https://youtu.be/M_9jm_jOJgY"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a>
            <a href="https://arxiv.org/pdf/2203.07782.pdf"><img src="https://img.shields.io/badge/arXiv-pdf-yellowgreen"></a>
            <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#may11" role="button" aria-expanded="false" aria-controls="collapseExample">
                Abstract
              </a>
          <div class="collapse" id="may11">
          <div class="card card-body">
            A Temporal Knowledge Graph (TKG) is a sequence of KGs corresponding to different timestamps. TKG reasoning aims to predict potential facts in the future given the historical KG sequences. One key of this task is to mine and understand evolutional patterns of facts from these sequences. The evolutional patterns are complex in two aspects, length- diversity and time-variability. Existing models for TKG reasoning focus on modeling fact sequences of a fixed length, which cannot discover complex evolutional patterns that vary in length. Furthermore, these models are all trained offline, which cannot well adapt to the changes of evolutional patterns from then on. Thus, we propose a new model, called Complex Evolutional Network (CEN), which uses a length-aware Convolutional Neural Network (CNN) to handle evolutional patterns of different lengths via an easy-to-difficult curriculum learning strategy. Besides, we propose to learn the model under the online setting so that it can adapt to the changes of evolutional patterns over time. Extensive experiments demonstrate that CEN obtains substantial performance improvement under both the traditional offline and the proposed online settings
          </div>
        </li>

      <h4>[May 25th, 2023]</h4>
        <li>
          <b>
              <a href="https://arxiv.org/pdf/2303.12021.pdf"> Graph Kalman Filters</a> 
          </b>
          <br> Presenter: <u>Daniele Zambon</u>, The Swiss AI Lab IDSIA & Universit`a della Svizzera italiana, Switzerland.
          <a class="btn btn-info btn-xs" data-toggle="collapse" href="#may25bio" role="button" aria-expanded="false" aria-controls="collapseExample">
            Speaker Bio
          </a>
          <div class="collapse" id="may25bio">
            <div class="card card-body">
              <u>Daniele Zambon</u> is currently a postdoctoral researcher with the Swiss AI Lab IDSIA, Università della Svizzera italiana USI, Lugano, Switzerland. He received his Ph.D. degree from USI, with a thesis on anomaly and change detection in sequences of graphs. He holds MSc and BSc degrees in mathematics from Università degli Studi di Milano, Milan, Italy. He has been a Visiting Researcher/Intern at the University of Florida, Gainesville, FL, USA, the University of Exeter, Exeter, U.K., and STMicroelectronics, Geneva, Switzerland. His research interests include machine learning on graph-structured data, time series analysis, and learning in nonstationary environments. He regularly publishes in and is in the program committee of top-tier journals and conferences of the field, including IEEE TPAMI, IEEE TNNLS, IEEE TSP, NeurIPS, ICML, and ICLR.
            </div>
          </div>
          <br> 
          <a href="https://youtu.be/Os1yn9teSrk"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a>
          <a href="https://arxiv.org/pdf/2303.12021.pdf"><img src="https://img.shields.io/badge/arXiv-pdf-yellowgreen"></a>
          <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#may25" role="button" aria-expanded="false" aria-controls="collapseExample">
              Abstract
            </a>
        <div class="collapse" id="may25">
        <div class="card card-body">
          The well-known Kalman filters model dynamical systems by relying on state-space representations with the next state updated, and its uncertainty controlled, by fresh information associated with newly observed system outputs. This paper generalizes, for the first time in the literature, Kalman and extended Kalman filters to discrete-time settings where inputs, states,and outputs are represented as attributed graphs whose topology and attributes can change with time. The setup allows us to adapt the framework to cases where the output is a vector or a scalar too (node/graph level tasks). Within the proposed theoretical framework, the unknown state-transition and the readout functions are learned end-to-end along with the downstream prediction task.
        </div>
      </li>


      <h4>[June 8th, 2023]</h4>
        <li>
          <b>
              <a href="https://arxiv.org/abs/2305.08750"> Fast and Attributed Change Detection on Dynamic Graphs with Density of States </a> PAKDD 2023
          </b>
          <br> Presenter: <u>Shenyang Huang</u>, Mila and School of Computer Science, McGill University
          <a class="btn btn-info btn-xs" data-toggle="collapse" href="#june8bio" role="button" aria-expanded="false" aria-controls="collapseExample">
            Speaker Bio
          </a>
          <div class="collapse" id="june8bio">
            <div class="card card-body">
              <u>Shenyang Huang</u> is a PhD student at McGill University and Mila, focusing on temporal graph learning (supervised by Prof. Reihaneh Rabbany and Prof. Guillaume Rabusseau). He is interested in representation learning on temporal graphs, anomaly detection and graph representation learning. He was the Organization Chair for the Temporal Graph Learning Workshop @ NeurIPS 2022. His previous research includes change point detection on temporal graphs, COVID-19 disease modeling with temporal contact graphs and link prediction on temporal graphs. 
            </div>
          </div>
          <br> 
          <a href="https://youtu.be/20zusjJZNdo"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a>
          <a href="https://arxiv.org/abs/2305.08750"><img src="https://img.shields.io/badge/arXiv-pdf-yellowgreen"></a>
          <a href="https://link.springer.com/book/10.1007/978-3-031-33374-3"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
          <a href="https://github.com/shenyangHuang/SCPD"><img src="https://img.shields.io/badge/Github-link-lightgrey"></a>
          <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#june8" role="button" aria-expanded="false" aria-controls="collapseExample">
              Abstract
            </a>
        <div class="collapse" id="june8">
        <div class="card card-body">
          How can we detect traffic disturbances from international flight transportation logs or changes to collaboration dynamics in academic networks? These problems can be formulated as detecting anomalous change points in a dynamic graph. Current solutions do not scale well to large real-world graphs, lack robustness to large amounts of node additions/deletions, and overlook changes in node attributes. To address these limitations, we propose a novel spectral method: Scalable Change Point Detection (SCPD). SCPD generates an embedding for each graph snapshot by efficiently approximating the distribution of the Laplacian spectrum at each step. SCPD can also capture shifts in node attributes by tracking correlations between attributes and eigenvectors. Through extensive experiments using synthetic and real-world data, we show that SCPD (a) achieves state-of-the art performance, (b) is significantly faster than the state-of-the-art methods and can easily process millions of edges in a few CPU minutes, (c) can effectively tackle a large quantity of node attributes, additions or deletions and (d) discovers interesting events in large real-world graphs.
        </div>
      </li>


      <h4>[June 15th, 2023]</h4>
        <li>
          <b>
              <a href="https://openreview.net/forum?id=10iA3OowAV3"> Chartalist: Labeled Graph Datasets for UTXO and Account-based Blockchains </a> NeurIPS 2022 Datasets and Benchmarks Track
          </b>
          <br> Presenter: <u>Kiarash Shamsi</u> and <u>Cuneyt Gurcan Akcora</u>, University of Manitoba, Canada
          <a class="btn btn-info btn-xs" data-toggle="collapse" href="#june15bio" role="button" aria-expanded="false" aria-controls="collapseExample">
            Speaker Bio
          </a>
          <div class="collapse" id="june15bio">
            <div class="card card-body">
              <u>Kiarash Shamsi</u> is a Ph.D. student in computer science at the University of Manitoba in Canada, and attained his Master's and bachelor's degree in computer software engineering from the University of Science and Culture and the University of Science and Technology in Iran. Kiarash's research interests revolve around machine learning, deep learning, data analysis, and blockchain technologies, focusing on their practical applications. Kiarash is contributing to the advancement of these areas through research and publication, with his work being featured in prestigious conferences and journals such as NeurIPS, ICBC, and IEEE Access.
              <br>
              <u>Cuneyt Gurcan Akcora</u> is an assistant professor of computer science and statistics at the University of Manitoba in Canada. He received his Ph.D. from the University of Insubria, Italy. His research interests include data science on complex networks and large-scale graph analysis, with applications in social, biological, IoT, and blockchain networks. Akcora has been awarded a Fulbright Scholarship and has published his research in leading conferences and journals, including IEEEtran, KDD, NeurIPS, VLDB, ICDM, SDM, IJCAI, and ICDE.
            </div>
          </div>
          <br> 
          <a href="https://youtu.be/TnjCTLAeOxo"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a>
          <a href="https://openreview.net/forum?id=10iA3OowAV3"><img src="https://img.shields.io/badge/NeurIPS-OpenReview-red"></a>
          <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#june15" role="button" aria-expanded="false" aria-controls="collapseExample">
              Abstract
            </a>
        <div class="collapse" id="june15">
        <div class="card card-body">
          <u> Topic 1 Abstract</u> Over the last couple of years, Bitcoin cryptocurrency and the Blockchain technology that forms the basis of Bitcoin have witnessed an unprecedented attention.
          Designed to facilitate a secure distributed platform without central regulation, Blockchain is heralded as a novel paradigm that will be as powerful as Big Data, Cloud Computing, and Machine Learning.
          The Blockchain technology garners an ever increasing interest of researchers in various domains that benefit from scalable cooperation among trust-less parties. As Blockchain applications proliferate, so does the complexity and volume of data stored by Blockchains. Analyzing this data has emerged as an important research topic, already leading to methodological advancements in the information sciences.
          In this tutorial, we offer a holistic view on applied Data Science on Blockchains. Starting with the core components of Blockchain, we will detail the state of art in Blockchain data analytics for graph, security and finance domains. Our examples will answer questions, such as, "how to parse, extract and clean the data stored in blockchains?", "how to store and query Blockchain data?" and "what features could be computed from blockchains"?
          <br>
          <u> Topic 2 Abstract (Topological Data Analysis on Networks, Applications and Scalability issues)</u> 
          Over the last couple of years, Topological Data Analysis (TDA) has seen a growing interest from Data Scientists of diverse backgrounds. TDA is an emerging field at the interface of algebraic topology, statistics, and computer science. The key rationale in TDA is that the observed data are sampled from some metric space and the underlying unknown geometric structure of this space is lost because of sampling. TDA recovers the lost underlying topology. We aim at adapting TDA algorithms to work on networks and overcoming the scalability issues that arise while working on large networks. In this talk, I will outline our three alternative approaches in applying Persistent Homology and TDAMapper based Topological Data Analysis algorithms to Blockchain networks.
          <br>
          see more from the following papers: <br>
          <a href="https://www.ijcai.org/Proceedings/2020/612">BitcoinHeist: Topological Data Analysis for Ransomware Prediction on the Bitcoin Blockchain</a> <br>
          <a href="https://par.nsf.gov/servlets/purl/10113270">ChainNet: Learning on Blockchain Graphs with Topological Features</a> <br>
          <a href="https://epubs.siam.org/doi/10.1137/1.9781611976236.59">Dissecting Ethereum Blockchain Analytics: What We Learn from Topology and Geometry of the Ethereum Graph?</a> <br>
        </div>
      </li>



      <h4>[June 22nd, 2023]</h4>
        <li>
          <b>
              <a href="https://neclab.eu/fileadmin/user_upload/On_the_Evaluation_of_Methods_for_Temporal_Knowledge_Graph_Forecasting.pdf"> Comparing Apples and Oranges? On the Evaluation of Methods for Temporal Knowledge Graph Forecasting  </a> ECML 2023 and NeurIPS 2022 TGL workshop 
          </b>
          <br> Presenter: <u>Julia Gastinger</u> NEC Laboratories Europe and Data and Web Science Group at University of Mannheim
          <a class="btn btn-info btn-xs" data-toggle="collapse" href="#june22bio" role="button" aria-expanded="false" aria-controls="collapseExample">
            Speaker Bio
          </a>
          <div class="collapse" id="june22bio">
            <div class="card card-body">
              <u>Julia Gastinger</u> is a research scientist at NEC Laboratories Europe and a second year Ph.D. student in the Data and Web Science Group at University of Mannheim, supervised by Professor Heiner Stuckenschmidt. Her research primarily focuses on Temporal Knowledge Graphs – Specifically, she is interested in Temporal Knowledge Graph Forecasting and the evaluation of methods in this research field. Julia actively contributes to the research community as a co-organizer of the temporal graph learning reading group.
            </div>
          </div>
          <br> 
          <a href="https://youtu.be/q8CC1ekBWvc"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a>
          <a href="https://neclab.eu/fileadmin/user_upload/On_the_Evaluation_of_Methods_for_Temporal_Knowledge_Graph_Forecasting.pdf"><img src="https://img.shields.io/badge/Paper-link-important"></a> 
          <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#june22" role="button" aria-expanded="false" aria-controls="collapseExample">
              Abstract
            </a>
        <div class="collapse" id="june22">
        <div class="card card-body">
          Due to its ability to incorporate and leverage time information in relational data, Temporal Knowledge Graph (TKG) learning has become an increasingly studied research field. To predict the future based on TKG, researchers have presented innovative methods for Temporal Knowledge Graph Forecasting. However, the experimental procedures employed in this research area exhibit inconsistencies that significantly impact empirical results, leading to distorted comparisons among models. This paper focuses on the evaluation of TKG Forecasting models: We examine the evaluation settings commonly used in this research area and highlight the issues that arise. To make different approaches to TKG Forecasting more comparable, we propose a unified evaluation protocol and apply it to re-evaluate state-of-the-art models on the most commonly used datasets. Ultimately, we demonstrate the significant difference in results caused by different evaluation settings. We believe this work provides a solid foundation for future evaluations of TKG Forecasting models, thereby contributing to advancing this growing research area.
        </div>
      </li>

    </div>
  </div>
</section>



<section id="winter2023" class="some-section">
  <div class="container">
    <div class="row">
      <div class="col-sm-2"></div>
      <div class="col-sm-8">
        <div class="listing" style="clear:both;">
        <div class="left">

      <h3 style="text-align:center">Past Talks, Winter 2023</h3>
        <h4>[Feb. 16th, 2023]</h4>
        <li>
            <b><a href="https://openreview.net/forum?id=EPUtNe7a9ta"> Neighborhood-aware Scalable Temporal Network Representation Learning </a>, LOG 2022 Conference Best Paper</b>
            <br> Presenter: <u>Yuhong Luo</u>, University of Massachusetts  
            <a class="btn btn-info btn-xs" data-toggle="collapse" href="#feb16bio" role="button" aria-expanded="false" aria-controls="collapseExample">
              Speaker Bio
            </a>
            <div class="collapse" id="feb16bio">
            <div class="card card-body">
                Yuhong Luo is a first year master student at UMass Amherst. Prior to that, he worked as a software engineer at Airbnb and worked with professor Pan Li of Purdue University as a research intern. His research interest includes ML, graph representation learning, ML fairness, etc.
            </div>
            </div>

            <br> 
            <a href="https://youtu.be/S9izBSTkk9Q"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a>
            <a href="https://openreview.net/forum?id=EPUtNe7a9ta"><img src="https://img.shields.io/badge/LOG%20-OpenReview-red"></a>
            <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#feb16" role="button" aria-expanded="false" aria-controls="collapseExample">
              Abstract
            </a>
            <div class="collapse" id="feb16">
            <div class="card card-body">
                Temporal networks have been widely used to model real-world complex systems such as financial systems and e-commerce systems. In a temporal network, the joint neighborhood of a set of nodes often provides crucial structural information useful for predicting whether they may interact at a certain time. However, recent represen- tation learning methods for temporal networks often fail to extract such information or depend on online construction of structural features, which is time-consuming. To address the issue, this work proposes Neighborhood-Aware Temporal network model (NAT). For each node in the network, NAT abandons the commonly-used one-single-vector-based representation while adopting a novel dictionary-type neighborhood representation. Such a dictionary representation records a down- sampled set of the neighboring nodes as keys, and allows fast construction of struc- tural features for a joint neighborhood of multiple nodes. We also design a dedicated data structure termed N-cache to support parallel access and update of those dic- tionary representations on GPUs. NAT gets evaluated over seven real-world large- scale temporal networks. NAT not only outperforms all cutting-edge baselines by averaged 1.2%↑ and 4.2%↑ in transductive and inductive link prediction accuracy, respectively, but also keeps scalable by achieving a speed-up of 4.1-76.7× against the baselines that adopt joint structural features and achieves a speed-up of 1.6-4.0× against the baselines that cannot adopt those features. The link to the code: https: //github.com/Graph-COM/Neighborhood-Aware-Temporal-Network.
            </div>
            </div>
        </li>


        <h4>[Feb. 23rd, 2023]</h4>
        <li>
          <b><a href="https://openreview.net/forum?id=Qamz7Q_Ta1k"> Direct Embedding of Temporal Network Edges via Time-Decayed Line Graphs </a>, ICLR 2023 </b>
            <br> Presenter: <u>Sudhanshu (Dan) Chanpuriya</u>, University of Massachusetts, Amherst
            <a class="btn btn-info btn-xs" data-toggle="collapse" href="#feb23bio" role="button" aria-expanded="false" aria-controls="collapseExample">
              Speaker Bio
            </a>
            <div class="collapse" id="feb23bio">
            <div class="card card-body">
              <u>Sudhanshu Chanpuriya</u> is a PhD student at UMass Amherst's Theoretical Computer Science Group, where he is advised by Cameron Musco. His research interests lie at the intersection of machine learning and spectral graph theory. Prior to joining UMass, he studied computer science and engineering physics at Dartmouth College.
            </div>
            </div>

            <br> 
            <a href="https://youtu.be/yQpDb0m_1V4"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a>
            <a href="https://openreview.net/forum?id=Qamz7Q_Ta1k"><img src="https://img.shields.io/badge/ICLR%20-OpenReview-green"></a>
            <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#feb23" role="button" aria-expanded="false" aria-controls="collapseExample">
                  Abstract
                </a>
            <div class="collapse" id="feb23">
            <div class="card card-body">
              Temporal networks model a variety of important phenomena involving timed interactions between entities. Existing methods for machine learning on temporal networks generally exhibit at least one of two limitations. First, time is assumed to be discretized, so if the time data is continuous, the user must determine the discretization and discard precise time information. Second, edge representations can only be calculated indirectly from the nodes, which may be suboptimal for tasks like edge classification. We present a simple method that avoids both shortcomings: construct the line graph of the network, which includes a node for each interaction, and weigh the edges of this graph based on the difference in time between interactions. From this derived graph, edge representations for the original network can be computed with efficient classical methods. The simplicity of this approach facilitates explicit theoretical analysis: we can constructively show the effectiveness of our method's representations for a natural synthetic model of temporal networks. Empirical results on real-world networks demonstrate our method's efficacy and efficiency on both edge classification and temporal link prediction.
            </div>
            </div>
        </li>

        <h4>[March 2nd, 2023] </h4>
        <li>
            <b>
                <a href="https://openreview.net/forum?id=NqbktPUkZf7"> Neural Temporal Walks: Motif-Aware Representation Learning on Continuous-Time Dynamic Graphs</a>, NeurIPS 2022
            </b>
            <br> Presenter: <u>Ming Jin</u>, Monash University
            <a class="btn btn-info btn-xs" data-toggle="collapse" href="#mar2bio" role="button" aria-expanded="false" aria-controls="collapseExample">
              Speaker Bio
            </a>
            <div class="collapse" id="mar2bio">
              <div class="card card-body">
                <u>Ming Jin</u> is a Ph.D. Candidate in Computer Science at Monash University, where he is currently being supervised by Prof. Shirui Pan and A/Prof. Yuan-Fang Li. He is also a Research Staff at Metso Outotec and a Research Assistant at Monash University. Ming completed his Bachelor's and Master's degrees at Hebei University of Technology and The University of Melbourne in 2017 and 2019, respectively. He has published over ten top-ranked conference and journal papers and regularly served as a PC member and reviewer of major AI/ML/DM conferences and journals, including IJCAI, PAKDD, TNNLS, TKDE, and more. Ming's research interests mainly focus on graph neural networks and geometric deep learning, with a particular emphasis on temporal settings such as dynamic graph neural networks. He is particularly passionate about applying these techniques to tackle practical challenges such as time series forecasting, industrial process modeling, and anomaly detection.
              </div>
            </div>

            <br> 
            <a href="https://youtu.be/i4HziTsAgWo"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a>
            <a href="https://openreview.net/forum?id=NqbktPUkZf7"><img src="https://img.shields.io/badge/NeurIPS-OpenReview-red"></a>
            <a href="https://drive.google.com/file/d/1Pq3zgiHB7-NJQcpDzQYi8QWsHY0UofBO/view?usp=sharing"> <img src="https://img.shields.io/badge/Talk%20-Slides-blue"></a>  
            <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#mar2nd" role="button" aria-expanded="false" aria-controls="collapseExample">
                Abstract
              </a>
          <div class="collapse" id="mar2nd">
          <div class="card card-body">
            Continuous-time dynamic graphs naturally abstract many real-world systems, such as social and transactional networks. While the research on continuous-time dynamic graph representation learning has made significant advances recently, neither graph topological properties nor temporal dependencies have been well-considered and explicitly modeled in capturing dynamic patterns. In this paper, we introduce a new approach, Neural Temporal Walks (NeurTWs), for representation learning on continuous-time dynamic graphs. By considering not only time constraints but also structural and tree traversal properties, our method conducts spatiotemporal-biased random walks to retrieve a set of representative motifs, enabling temporal nodes to be characterized effectively. With a component based on neural ordinary differential equations, the extracted motifs allow for irregularly-sampled temporal nodes to be embedded explicitly over multiple different interaction time intervals, enabling the effective capture of the underlying spatiotemporal dynamics. To enrich supervision signals, we further design a harder contrastive pretext task for model optimization. Our method demonstrates overwhelming superiority under both transductive and inductive settings on six real-world datasets.
          </div>
        </li>


        <h4>[March 9th, 2023]</h4>
        <li>
            <b>
                <a href="https://arxiv.org/abs/2211.11979"> Learnable Spectral Wavelets on Dynamic Graphs to Capture Global Interactions </a>, AAAI 2023
            </b>
            <br> Presenter: <u>Anson Bastos</u>, Indian Institue of Technology, Hyderabad (IITH, India) and <u>Abhishek Nadgeri</u>, RWTH Aachen, Germany
            <a class="btn btn-info btn-xs" data-toggle="collapse" href="#mar9bio" role="button" aria-expanded="false" aria-controls="collapseExample">
              Speakers' Bio
            </a>
            <div class="collapse" id="mar9bio">
              <div class="card card-body">
                <u>Anson Basto</u> is a PhD student at the Indian Institue of Technology, Hyderabad (IITH, India) under the supervision of Dr Manish Singh (IITH, India) and Dr Toyotaro Suzamura (The University of Tokyo, Japan). His research interests/works are in the areas of Geometric machine learning, Graph Signal Processing, Topology, Knowledge graphs etc.
                <br>
                <u>Abhishek Nadgeri</u> is currently pursuing his master’s at RWTH Aachen, Germany, his research interests are Graph ML, time series and NLP.
              </div>
            </div>

            <br> 
            <a href="https://youtu.be/rucv3-YbPow"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a>
            <a href="https://arxiv.org/abs/2211.11979"><img src="https://img.shields.io/badge/arXiv-pdf-yellowgreen"></a>
            <a href="https://drive.google.com/file/d/1Jjo0JRbYFUSeYUjAZQLSpJbFP1eVmZnJ/view?usp=sharing"> <img src="https://img.shields.io/badge/Talk%20-Slides-blue"></a>
            <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#mar9th" role="button" aria-expanded="false" aria-controls="collapseExample">
                Abstract
              </a>
          <div class="collapse" id="mar9th">
          <div class="card card-body">
            Learning on evolving(dynamic) graphs has caught the attention of researchers as static methods exhibit limited performance in this setting. The existing methods for dynamic graphs learn spatial features by local neighborhood aggregation, which essentially only captures the low pass signals and local interactions. In this work, we go beyond current approaches to incorporate global features for effectively learning representations of a dynamically evolving graph. We propose to do so by capturing the spectrum of the dynamic graph. Since static methods to learn the graph spectrum would not consider the history of the evolution of the spectrum as the graph evolves with time, we propose a novel approach to learn the graph wavelets to capture this evolving spectra. Further, we propose a framework that integrates the dynamically captured spectra in the form of these learnable wavelets into spatial features for incorporating local and global interactions. Experiments on eight standard datasets show that our method significantly outperforms related methods on various tasks for dynamic graphs.
          </div>
        </li>

        <h4>[March 16th, 2023]</h4>
        <li>
            <b>
                <a href="https://openreview.net/forum?id=ayPPc0SyLv1"> Do We Really Need Complicated Model Architectures For Temporal Networks?  </a>, ICLR 2023
            </b>
            <br> Presenter: <u>Weilin Cong</u>, Pennsylvania State University
            <a class="btn btn-info btn-xs" data-toggle="collapse" href="#mar16bio" role="button" aria-expanded="false" aria-controls="collapseExample">
              Speaker Bio
            </a>
            <div class="collapse" id="mar16bio">
              <div class="card card-body">
                <u>Weilin Cong</u> is a 4th year Ph.D. candidate at Penn State University. His research focuses on both the fundamental problems in graph representation learning, including optimization, generalization, expressive power, and model architecture design. He has published as the first author in AI conferences NeurIPS, ICLR, AISTATS, KDD and SDM on graph representation learning.
              </div>
            </div>
            <br> 
            <a href="https://youtu.be/61edyzoCT1I"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a>
            <a href="https://openreview.net/forum?id=ayPPc0SyLv1"><img src="https://img.shields.io/badge/ICLR%20-OpenReview-green"></a>
            <a href="https://drive.google.com/file/d/18vlfRm3xmoU6-rIU78KUzYHFAMh5sx1N/view?usp=sharing"> <img src="https://img.shields.io/badge/Talk%20-Slides-blue"></a>  
            <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#mar16th" role="button" aria-expanded="false" aria-controls="collapseExample">
                Abstract
              </a>
          <div class="collapse" id="mar16th">
          <div class="card card-body">
            Recurrent neural network (RNN) and self-attention mechanism (SAM) are the de facto methods to extract spatial-temporal information for temporal graph learning. Interestingly, we found that although both RNN and SAM could lead to a good per-formance, in practice neither of them is always necessary. In this paper, we propose GraphMixer , a conceptually and technically simple architecture that consists of three components: 1 a link-encoder that is only based on multi-layer perceptrons (MLP) to summarize the information from temporal links, 2 a node-encoder that is only based on neighbor mean-pooling to summarize node information, and 3 an MLP-based link classifier that performs link prediction based on the outputs of the encoders. Despite its simplicity, GraphMixer attains an outstanding performance on temporal link prediction benchmarks with faster convergence and better generalization performance. These results motivate us to rethink the importance of simpler model architecture. Code is in the supplementary.
          </div>
        </li>

        <h4>[March 23rd, 2023]</h4>
        <li>
            <b>
                <a href="https://arxiv.org/pdf/2207.03408.pdf">Representation Learning in Continuous-Time Dynamic Signed Networks</a>, CIKM 2023
            </b>
            <br> Presenter: <u>Kartik Sharma</u>, Georgia Institute of Technology
            <a class="btn btn-info btn-xs" data-toggle="collapse" href="#mar23bio" role="button" aria-expanded="false" aria-controls="collapseExample">
              Speaker Bio
            </a>
            <div class="collapse" id="mar23bio">
              <div class="card card-body">
                <u>Kartik Sharma</u> is a 2nd year PhD student advised by Prof. Srijan Kumar at Georgia Techology advised by Prof. Srijan Kumar. Before joining there, Kartik graduated from IIT-Delhi in 2021, where he was fortunate to be advised by Prof. Sayan Ranu.
                His research focuses on learning and optimization for graph-structured data. Through his research, his goal is to (1) study the effectiveness of these models in difficult and practical (for eg., adversarial, constrained, dynamic) scenarios, and (2) develop new models that can circumvent these problems with a theoretical grounding.
              </div>
            </div>
            <br> 
            <a href="https://youtu.be/AOwd9H8qYEU"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a>
            <a href="https://arxiv.org/pdf/2207.03408.pdf"><img src="https://img.shields.io/badge/arXiv-pdf-yellowgreen"></a>
            <a href="https://drive.google.com/file/d/1L34ldA7CpHV_q2YB3EXzJDYuVgRIBIby/view?usp=sharing"> <img src="https://img.shields.io/badge/Talk%20-Slides-blue"></a>  
            <a href="https://github.com/claws-lab/semba"><img src="https://img.shields.io/badge/Github-link-lightgrey"></a>
            <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#mar23" role="button" aria-expanded="false" aria-controls="collapseExample">
                Abstract
              </a>
          <div class="collapse" id="mar23">
          <div class="card card-body">
            Signed networks allow us to model conflicting relationships and in- teractions, such as friend/enemy and support/oppose. These signed interactions happen in real time. Modeling such dynamics of signed networks is crucial to understanding the evolution of polarization in the network and enabling effective prediction of the signed struc- ture (i.e., link signs and signed weights) in the future. However, exist- ing works have modeled either (static) signed networks or dynamic (unsigned) networks but not dynamic signed networks. Since both sign and dynamics inform the graph structure in different ways, it is non-trivial to model how to combine the two features. In this work, we propose a new Graph Neural Network (GNN)-based ap- proach to model dynamic signed networks, named SEMBA: Signed link’s Evolution using Memory modules and Balanced Aggregation. Here, the idea is to incorporate the signs of temporal interactions using separate modules guided by balance theory and to evolve the embeddings from a higher-order neighborhood. Experiments on 4 real-world datasets and 4 different tasks demonstrate that SEMBA consistently and significantly outperforms the baselines by up to 80% on the tasks of predicting signs of future links while matching the state-of-the-art performance on predicting existence of these links in the future. We find that this improvement is due specifically to superior performance of SEMBA on the minority negative class.
          </div>
        </li>

        <h4>[March 30th, 2023]</h4>
        <li>
            <b>
                <a href="https://openreview.net/forum?id=1GVpwr2Tfdg">Towards Better Evaluation for Dynamic Link Prediction</a> (NeurIPS 2022 Datasets and Benchmarks Track)
            </b>
            <br> Presenter: <u>Farimah Poursafaei</u>, McGill University, Mila
            <a class="btn btn-info btn-xs" data-toggle="collapse" href="#mar30bio" role="button" aria-expanded="false" aria-controls="collapseExample">
              Speaker Bio
            </a>
            <div class="collapse" id="mar30bio">
              <div class="card card-body">
                <u>Farimah Poursafaei</u> (she/her)  is a PostDoc at McGill University and Mila. She conducts research on dynamic graph neural networks, and temporal graphs. She completed her PhD at McGill University in Computer Engineering. During her PhD, she was working on anomaly detection on cryptocurrency transactions networks. She served as the Reviewing Chair in Temporal Graph Learning Workshop @ NeurIPS 2022.
              </div>
            </div>
            <br> 
            <a href="https://youtu.be/LvOEvGlVlUU"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a>
            <a href="https://openreview.net/forum?id=1GVpwr2Tfdg"><img src="https://img.shields.io/badge/NeurIPS-OpenReview-red"></a>
            <a href="https://drive.google.com/file/d/1s_v2EJyuEXYuKfabDMlRQCP2hfanXmiX/view?usp=sharing"> <img src="https://img.shields.io/badge/Talk%20-Slides-blue"></a>  
            <a href="https://github.com/fpour/DGB.git"><img src="https://img.shields.io/badge/Github-link-lightgrey"></a>
            <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#mar30" role="button" aria-expanded="false" aria-controls="collapseExample">
                Abstract
              </a>
          <div class="collapse" id="mar30">
          <div class="card card-body">
            Despite the prevalence of recent success in learning from static graphs, learning from time-evolving graphs remains an open challenge. In this work, we design new, more stringent evaluation procedures for link prediction specific to dynamic graphs, which reflect real-world considerations, to better compare the strengths and weaknesses of methods. First, we create two visualization techniques to understand the reoccurring patterns of edges over time and show that many edges reoccur at later time steps. Based on this observation, we propose a pure memorization-based baseline called EdgeBank. EdgeBank achieves surprisingly strong performance across multiple settings which highlights that the negative edges used in the current evaluation are easy. To sample more challenging negative edges, we introduce two novel negative sampling strategies that improve robustness and better match real-world applications. Lastly, we introduce six new dynamic graph datasets from a diverse set of domains missing from current benchmarks, providing new challenges and opportunities for future research. Our code repository is accessible at <a href="https://github.com/fpour/DGB.git">github</a>
          </div>
        </li>


        <h4>[April 6th, 2023]</h4>
        <li>
            <b>
                <a href="https://arxiv.org/abs/2209.06520">Scalable Spatiotemporal Graph Neural Networks</a>  AAAI 2023 ( also NeurIPS 2022 Temporal Graph Learning Workshop best paper)
            </b>
            <br> Presenter: <u>Andrea Cini</u> and <u>Ivan Marisca</u>, IDSIA, Università della Svizzera italiana 
            <a class="btn btn-info btn-xs" data-toggle="collapse" href="#apr6bio" role="button" aria-expanded="false" aria-controls="collapseExample">
              Speaker Bio
            </a>
            <div class="collapse" id="apr6bio">
              <div class="card card-body">
                <u>Andrea Cini</u> is a Ph.D. student at IDSIA and a visiting researcher at Imperial College London. Previously, he worked as machine learning engineer in the aerospace industry and obtained his MSc and BSc in Computer Science at Politecnico di Milano. Andrea’s research has been published in top-tier machine-learning venues such as JMLR, NeurIPS, ICLR and AAAI. His main research interests are in methods to process spatiotemporal data by exploiting graph representations and graph deep learning; applications are in time series analysis, with a focus on spatiotemporal forecasting. 
                Personal website:  <a href="https://andreacini.github.io/">https://andreacini.github.io/</a> 
                <br>
                <u>Ivan Marisca</u> is a Ph.D. student at the Graph Machine Learning Group within the Swiss AI lab IDSIA at Università della Svizzera italiana (USI), under the supervision of Prof. Cesare Alippi. He received his BSc (2017) and MSc (2020) degrees in Computer Science and Engineering from Politecnico di Milano.Ivan's research focuses on graph-based learning from irregular spatiotemporal data, with applications in prediction, imputation, and control on sensor networks. His works have been published in top-tier conferences such as NeurIPS, ICLR, and AAAI. In addition to his research, Ivan is an enthusiastic teaching assistant and lecturer in machine learning courses for MSc students at USI.
                Personal website: <a href="https://marshka.github.io/">https://marshka.github.io/</a> 
              </div>
            </div>
            <br> 
            <a href="https://arxiv.org/abs/2209.06520"><img src="https://img.shields.io/badge/arXiv-pdf-yellowgreen"></a>
            <a href="https://drive.google.com/file/d/1Gy106tNUuxID_Enj6ry3Paaxtcsao51E/view?usp=sharing"> <img src="https://img.shields.io/badge/Talk%20-Slides-blue"></a>
            <a href="https://neurips.cc/virtual/2022/workshop/49999">Slidelive video recording from NeurIPS 2022 TGL workshop</a>
            <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#apr6" role="button" aria-expanded="false" aria-controls="collapseExample">
                Abstract
              </a>
          <div class="collapse" id="apr6">
          <div class="card card-body">
            Neural forecasting of spatiotemporal time series drives both research and industrial innovation in several relevant application domains. Graph neural networks (GNNs) are often the core component of the forecasting architecture. However, in most spatiotemporal GNNs, the computational complexity scales up to a quadratic factor with the length of the sequence times the number of links in the graph, hence hindering the application of these models to large graphs and long temporal sequences. While methods to improve scalability have been proposed in the context of static graphs, few research efforts have been devoted to the spatiotemporal case. To fill this gap, we propose a scalable architecture that exploits an efficient encoding of both temporal and spatial dynamics. In particular, we use a randomized recurrent neural network to embed the history of the input time series into high-dimensional state representations encompassing multi-scale temporal dynamics. Such representations are then propagated along the spatial dimension using different powers of the graph adjacency matrix to generate node embeddings characterized by a rich pool of spatiotemporal features. The resulting node embeddings can be efficiently pre-computed in an unsupervised manner, before being fed to a feed-forward decoder that learns to map the multi-scale spatiotemporal representations to predictions. The training procedure can then be parallelized node-wise by sampling the node embeddings without breaking any dependency, thus enabling scalability to large networks. Empirical results on relevant datasets show that our approach achieves results competitive with the state of the art, while dramatically reducing the computational burden
          </div>
        </li>

        <h4>[April 13th, 2023]</h4>
        <li>
            <b>
                <a href="https://arxiv.org/abs/2211.14701"> Spatio-Temporal Meta-Graph Learning for Traffic Forecasting </a>, AAAI 2023
            </b>
            <br>
            <b>
              <a href="https://dl.acm.org/doi/abs/10.1145/3459637.3482000"> DL-Traff: Survey and Benchmark of Deep Learning Models for Urban Traffic Prediction </a>, CIKM 21 Best Resource Paper Runner-Up
            </b>
            <br> Presenter: <u>Renhe Jiang</u>, Center for Spatial Information Science, The University of Tokyo
            <a class="btn btn-info btn-xs" data-toggle="collapse" href="#apr13bio" role="button" aria-expanded="false" aria-controls="collapseExample">
              Speaker Bio
            </a>
            <div class="collapse" id="apr13bio">
              <div class="card card-body">
                <u>Renhe Jiang</u> is a full-time lecturer at Center for Spatial Information Science, The University of Tokyo. He received his B.S. degree in Software Engineering from Dalian University of Technology, China, in 2012, M.S. degree in Information Science from Nagoya University, Japan, in 2015, and Ph.D. degree in Civil Engineering from The University of Tokyo, Japan, in 2019. From 2019 to 2022, he was an assistant professor at Information Technology Center, The University of Tokyo. His research interests include data mining and machine learning, especially spatiotemporal data science, spatiotemporal AI, multivariate time series, urban computing, and intelligent transportation system. You can find his website <a href="https://www.renhejiang.com/">here</a>.
              </div>
            </div>
            <br> 
            <a href="https://youtu.be/odo8cNzi-Bw"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a>
            <a href="https://arxiv.org/abs/2211.14701"><img src="https://img.shields.io/badge/arXiv-pdf-yellowgreen"></a>
            <a href="https://dl.acm.org/doi/abs/10.1145/3459637.3482000"><img src="https://img.shields.io/badge/CIKM%20-2021-yellow"></a>
            <a href="https://drive.google.com/file/d/1VTyjn3LOgpjfmXkGGLYWsTkD8gqDjQuX/view?usp=sharing"> <img src="https://img.shields.io/badge/Talk%20-Slides-blue"></a>
            <a href="https://drive.google.com/file/d/1CwDOrlZ2jpZdWt4snrZ1XJHrdTzWK_iL/view?usp=sharing"> <img src="https://img.shields.io/badge/Talk%20-Slides-blue"></a>
            <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#apr13th" role="button" aria-expanded="false" aria-controls="collapseExample">
                Abstract
              </a>
            <div class="collapse" id="apr13th">
            <div class="card card-body">
              <u>Spatio-Temporal Meta-Graph Learning for Traffic Forecasting (AAAI 2023)</u>. Traffic forecasting as a canonical task of multivariate time series forecasting has been a significant research topic in AI community. To address the spatio-temporal heterogeneity and non-stationarity implied in the traffic stream, in this study, we propose Spatio-Temporal Meta-Graph Learning as a novel Graph Structure Learning mechanism on spatio-temporal data. Specifically, we implement this idea into Meta-Graph Convolutional Recurrent Network (MegaCRN) by plugging the Meta-Graph Learner powered by a Meta-Node Bank into GCRN encoder-decoder. We conduct a comprehensive evaluation on two benchmark datasets (i.e., METR-LA and PEMS-BAY) and a new large-scale traffic speed dataset called EXPY-TKY that covers 1843 expressway road links in Tokyo. Our model outperformed the state-of-the-arts on all three datasets. Besides, through a series of qualitative evaluations, we demonstrate that our model can explicitly disentangle the road links and time slots with different patterns and be robustly adaptive to any anomalous traffic situations. Codes and datasets are available at https://github.com/deepkashiwa20/MegaCRN.
            <br>
              <u>DL-Traff: Survey and Benchmark of Deep Learning Models for Urban Traffic Prediction (CIKM 2021)</u>. Nowadays, with the rapid development of IoT (Internet of Things) and CPS (Cyber-Physical Systems) technologies, big spatiotemporal data are being generated from mobile phones, car navigation systems, and traffic sensors. By leveraging state-of-the-art deep learning technologies on such data, urban traffic prediction has drawn a lot of attention in AI and Intelligent Transportation System community. The problem can be uniformly modeled with a 3D tensor (T, N, C), where T denotes the total time steps, N denotes the size of the spatial domain (i.e., mesh-grids or graph-nodes), and C denotes the channels of information. According to the specific modeling strategy, the state-of-the-art deep learning models can be divided into three categories: grid-based, graph-based, and multivariate time-series models. In this study, we first synthetically review the deep traffic models as well as the widely used datasets, then build a standard benchmark to comprehensively evaluate their performances with the same settings and metrics. Our study named DL-Traff is implemented with two most popular deep learning frameworks, i.e., TensorFlow and PyTorch, which is already publicly available as two GitHub repositories https://github.com/deepkashiwa20/DL-Traff-Grid and https://github.com/deepkashiwa20/DL-Traff-Graph. With DL-Traff, we hope to deliver a useful resource to researchers who are interested in spatiotemporal data analysis.

            </div>
        </li>


        <h4>[April 20th, 2023]</h4>
        <li>
            <b>
                <a href="https://openreview.net/forum?id=m1oqEOAozQU"> Graph Neural Networks for Link Prediction with Subgraph Sketching </a>, ICLR 2023 Notable top 5%
            </b>
            <br> Presenter: <u>Benjamin Paul Chamberlain</u> Charm Therapeutics and <u>Sergey Shirobokov</u> ShareChat
            <!-- and <u>Sergey Shirobokov</u> -->
            <a class="btn btn-info btn-xs" data-toggle="collapse" href="#apr20bio" role="button" aria-expanded="false" aria-controls="collapseExample">
              Speaker Bio
            </a>
            <div class="collapse" id="apr20bio">
              <div class="card card-body">
                Dr <u>Ben Chamberlain</u> is a Principal Scientist at Charm Therapeutics where he works on 3d machine learning to develop cancer drugs. He was previously a staff machine learning researcher within the graph ML group at Twitter and the Head of machine learning at ASOS.com. He did his PhD at Imperial College with Professor Marc Deisonroth on large scale graph ML.
                <br>
                Dr <u>Sergey Shirobokov</u> is a Senior Machine Learning scientist at ShareChat, where he works on improving the company's recommender algorithms. He was previously a Senior Machine Learning Researcher at Twitter Cortex team. He did his PhD at Imperial College London on simulator-based optimisation algorithms for high energy physics.
              </div>
            </div>

            <br> <a href="https://youtu.be/_foaVzrC2Ec"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a>
            <a href="https://openreview.net/forum?id=m1oqEOAozQU"><img src="https://img.shields.io/badge/ICLR%20-OpenReview-green"></a>
            <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#apr20th" role="button" aria-expanded="false" aria-controls="collapseExample">
                Abstract
              </a>
          <div class="collapse" id="apr20th">
          <div class="card card-body">
            Many Graph Neural Networks (GNNs) perform poorly compared to simple heuristics on Link Prediction (LP) tasks. This is due to limitations in expressive power such as the inability to count triangles (the backbone of most LP heuristics) and because they can not distinguish automorphic nodes (those having identical structural roles). Both expressiveness issues can be alleviated by learning link (rather than node) representations and incorporating structural features such as triangle counts. Since explicit link representations are often prohibitively expensive, recent works resorted to subgraph-based methods, which have achieved state-of-the-art performance for LP, but suffer from poor efficiency due to high levels of redundancy between subgraphs. We analyze the components of subgraph GNN (SGNN) methods for link prediction. Based on our analysis, we propose a novel full-graph GNN called ELPH (Efficient Link Prediction with Hashing) that passes subgraph sketches as messages to approximate the key components of SGNNs without explicit subgraph construction. ELPH is provably more expressive than Message Passing GNNs (MPNNs). It outperforms existing SGNN models on many standard LP benchmarks while being orders of magnitude faster. However, it shares the common GNN limitation that it is only efficient when the dataset fits in GPU memory. Accordingly, we develop a highly scalable model, called BUDDY, which uses feature precomputation to circumvent this limitation without sacrificing predictive performance. Our experiments show that BUDDY also outperforms SGNNs on standard LP benchmarks while being highly scalable and faster than ELPH.
          </div>
        </li>

        <h4>[April 27th, 2023]</h4>
        <li>
            <b>
                <a href="https://arxiv.org/abs/2211.10904"> Temporal Knowledge Graph Reasoning with Historical Contrastive Learning
                </a> AAAI 2023
            </b>
            <br> Presenter: <u>Yi Xu</u>, Shanghai Jiao Tong University
            <a class="btn btn-info btn-xs" data-toggle="collapse" href="#apr27bio" role="button" aria-expanded="false" aria-controls="collapseExample">
              Speaker Bio
            </a>
            <div class="collapse" id="apr27bio">
              <div class="card card-body">
                <u>Yi Xu</u> is a 3th year Ph.D. candidate at Shanghai Jiao Tong University under the supervision of Prof. Luoyi Fu and Prof. Xinbing Wang. His research interests include natural language processing, knowledge graphs and data mining. Specifically, He is devoted to the research of large language models and temporal knowledge graph.
              </div>
            </div>
            <br> 
            <a href="https://youtu.be/xqK6s8nDmpQ"><img src="https://img.shields.io/badge/Youtube-Recording-orange"></a>
            <a href="https://arxiv.org/pdf/2207.03408.pdf"><img src="https://img.shields.io/badge/arXiv-pdf-yellowgreen"></a>
            <a class="btn btn-primary btn-xs" data-toggle="collapse" href="#apr27" role="button" aria-expanded="false" aria-controls="collapseExample">
                Abstract
              </a>
          <div class="collapse" id="apr27">
          <div class="card card-body">
            Temporal knowledge graph, serving as an effective way to store and model dynamic relations, shows promising prospects in event forecasting. However, most temporal knowledge graph reasoning methods are highly dependent on the recurrence or periodicity of events, which brings challenges to inferring future events related to entities that lack historical interaction. In fact, the current moment is often the combined effect of a small part of historical information and those unobserved underlying factors. To this end, we propose a new event forecasting model called Contrastive Event Network (CENET), based on a novel training framework of historical contrastive learning. CENET learns both the historical and non-historical dependency to distinguish the most potential entities that can best match the given query. Simultaneously, it trains representations of queries to investigate whether the current moment depends more on historical or non-historical events by launching contrastive learning. The representations further help train a binary classifier whose output is a boolean mask to indicate related entities in the search space. During the inference process, CENET employs a mask-based strategy to generate the final results. We evaluate our proposed model on five benchmark graphs. The results demonstrate that CENET significantly outperforms all existing methods in most metrics, achieving at least 8.3% relative improvement of Hits@1 over previous state-of-the-art baselines on event-based datasets. 
          </div>
        </li>
  
      </div>
    </div>
  </section>



<section id="organizers" class="some-section">
    <div class="container">
      <div class="row">
    <div class="col-sm-2"></div>
    <div class="col-sm-8">
    <div class="listing" style="clear:both;">
      <div class="left">
        <h3 style="text-align:center"> Organizers</h3>
        <div class="container">
        <div class="row">

          <div class="col-sm-4">	
            <div class="ratio ratio-4x3">
                <!-- <img src="images/farimah.png" width="82.5%" alt="profile picture" class="img-responsive"/> -->
                <img src="images/farimah.png" width="85%" alt="profile picture" class="img-rounded"/>
                <div class="caption text-center"> <h4><a href="https://www.linkedin.com/in/farimah-poursafaei-133195167/">Farimah Poursafaei</a></div></h4>
                <p>
                  <u>Farimah Poursafaei</u> (she/her)  is a PostDoc at McGill University and Mila. She conducts research on dynamic graph neural networks, and temporal graphs. She completed her PhD at McGill University in Computer Engineering. 
                  During her PhD, she was working on anomaly detection on cryptocurrency transactions networks. She served as the Reviewing Chair in Temporal Graph Learning Workshop @ NeurIPS 2022.
                  <br> 
                  <a href="https://fpour.github.io/">Website</a>, <a href="https://scholar.google.ca/citations?user=gZ7HEsMAAAAJ&hl=en">Google Scholar</a>, <a href="https://www.linkedin.com/in/farimah-poursafaei-133195167/">Linkedin</a>
              </p>
            </div>
          </div>

          <div class="col-sm-4">	
            <div class="ratio ratio-4x3">
                <img src="images/Julia.jpg" width="90%" alt="profile picture" class="img-rounded"/>
                <div class="caption text-center"> 
                <h4><a href="https://scholar.google.com/citations?user=UgrQkB4AAAAJ&hl=en">Julia Gastinger</a></div></h4>
                 <p>
                      <u>Julia Gastinger</u> (she/her) is a Ph.D. student at Mannheim University, supervised by Professor Heiner Stuckenschmidt. Previously, she was a Research Scientist in the AI Innovations group at NEC Laboratories Europe. Her research primarily focuses on graph-based Machine Learning – she is interested in how to incorporate the time aspect in knowledge graph representations.
                      She served as a Reviewing Chair and Co-Organizer in Temporal Graph Learning Workshop @ NeurIPS 2023.
                      <br> 
                      <a href="https://juliagast.github.io/">Website</a>, <a href="https://scholar.google.com/citations?user=UgrQkB4AAAAJ&hl=en">Google Scholar</a>, <a href="https://de.linkedin.com/in/julia-gastinger-a6ab0b177">LinkedIn</a>
                      <br>
                      Most Recent Publication: <a href="https://openreview.net/pdf?id=J_SNklR-KR">On the Evaluation of Methods for Temporal Knowledge Graph Forecasting</a>   
                  </p>                  
            </div>
          </div>
          <div class="col-sm-4">
            <div class="ratio ratio-4x3">
                <img src="images/profile.jpg" width="77.5%" alt="profile picture" class="img-rounded"/>
                <div class="caption text-left"> <h4><a href="https://shenyanghuang.github.io/">Shenyang(Andy) Huang</a></div></h4>
                <p>
                  <u>Shenyang Huang</u> (he/him) is a postdoctoral scholar at University of Oxford. He obtained his PhD from McGill University and Mila, focusing on temporal graph learning (supervised by Prof. Reihaneh Rabbany and Prof. Guillaume Rabusseau). 
                  He is interested in representation learning on temporal graphs, anomaly detection and graph representation learning. He was the Organization Chair for the Temporal Graph Learning Workshop @ NeurIPS 2022.
                  His previous research includes change point detection on temporal graphs, COVID-19 disease modeling with temporal contact graphs and link prediction on temporal graphs. He also enjoys writing <a href="https://medium.com/@shenyanghuang1996">medium blog posts</a> about temporal graph learning. 
                  <br> 
                  <a href="https://shenyanghuang.github.io/">Website</a>, <a href="https://scholar.google.ca/citations?user=ljIXv6kAAAAJ&hl=en">Google Scholar</a>, <a href="https://twitter.com/shenyangHuang">Twitter</a>, <a href="https://www.linkedin.com/in/shenyang-huang/">Linkedin</a>
              </p>
            </div>
          </div>

          <div class="col-sm-4">
            <div class="ratio ratio-4x3">
                <img src="images/viktor.png" width="77.5%" alt="profile picture" class="img-rounded"/>
                <div class="caption text-left"> <h4><a href="https://vstenby.github.io/">Viktor Stenby</a></div></h4>
                <p>
                  <u>Viktor Stenby</u> (he/him)  is an Industrial PhD student jointly at the Technical University of Denmark and Vipps MobilePay, researching foundation models for payment networks.
                  He holds a master’s degree in Mathematical Modelling and Computation from DTU and spent two years as a machine learning engineer in industry before starting his PhD.
                  His work focuses on developing predictive models for large-scale, peer-to-peer financial transaction networks, with a particular emphasis on temporal graph-based methods.
                  <br> 
                  <a href="https://vstenby.github.io/">Website</a>, <a href="https://scholar.google.com/citations?user=isSZjaAAAAAJ&hl=da">Google Scholar</a>, <a href="https://www.linkedin.com/in/viktor-stenby/">LinkedIn</a>
              </p>
            </div>
          </div>


        </div>
      </div>
    </div>
</section>









<script src="js/jquery.js"></script>
<script src="js/bootstrap.min.js"></script>
<script src="js/jquery.easing.min.js"></script>
<script src="js/scrolling-nav.js"></script>
</body>

</html>
